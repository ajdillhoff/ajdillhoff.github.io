<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academia 4.3.1">
  <meta name="theme-name" content="academia-hugo"/>

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Alex Dillhoff">

  
  
  
    
  
  <meta name="description" content="
Table of Contents

Introduction
AdaBoost



Introduction
Combining predictions from multiple sources is usually preferred to a single source.
For example, a medical diagnosis would carry much more weight if it was the result of a consensus of several experts.
This idea of prediction by consensus is a powerful way to improve classification and regression models.
In fact, good performance of a committee of models can be achieved even if each individual model is conceptually very simple.">

  
  <link rel="alternate" hreflang="en-us" href="https://ajdillhoff.github.io/notes/boosting/">

  


  

  
  
  
  <meta name="theme-color" content="#fc6f5c">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Open+Sans|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academia.min.b246554d075350d61b44c126dfbcbe05.css">

  
    
    
    
    
      
    
    
    
    <link rel="stylesheet" href="/css/academia.a75a9b8a9a725a2157c0c5b929a3d18b.css">
  

  
  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-123456-78', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://ajdillhoff.github.io/notes/boosting/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Alex Dillhoff">
  <meta property="og:url" content="https://ajdillhoff.github.io/notes/boosting/">
  <meta property="og:title" content="Boosting | Alex Dillhoff">
  <meta property="og:description" content="
Table of Contents

Introduction
AdaBoost



Introduction
Combining predictions from multiple sources is usually preferred to a single source.
For example, a medical diagnosis would carry much more weight if it was the result of a consensus of several experts.
This idea of prediction by consensus is a powerful way to improve classification and regression models.
In fact, good performance of a committee of models can be achieved even if each individual model is conceptually very simple."><meta property="og:image" content="https://ajdillhoff.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://ajdillhoff.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2022-03-23T00:00:00-05:00">
  
  <meta property="article:modified_time" content="2022-03-23T00:00:00-05:00">
  

  


  





  <title>Boosting | Alex Dillhoff</title>

  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>



</head>


<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Alex Dillhoff</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation"><span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">
      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/notes/"><span>Brain Dump</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Courses</span></a>
        </li>

        
        

      

        

        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>
    </div>
  </div>
</nav>


  <article class="article py-5" itemscope itemtype="http://schema.org/Article">

  












    

    
    
    
    <div class="article-container py-3">
      <h1 itemprop="name">Boosting</h1>

      

      
      



<meta content="2022-03-23 00:00:00 -0500 CDT" itemprop="datePublished">
<meta content="2022-03-23 00:00:00 -0500 CDT" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/alex-dillhoff/">Alex Dillhoff</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>Mar 23, 2022</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min read
  </span>
  

  
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://ajdillhoff.github.io/notes/boosting/&amp;text=Boosting" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://ajdillhoff.github.io/notes/boosting/&amp;t=Boosting" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Boosting&amp;body=https://ajdillhoff.github.io/notes/boosting/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://ajdillhoff.github.io/notes/boosting/&amp;title=Boosting" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Boosting%20https://ajdillhoff.github.io/notes/boosting/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://ajdillhoff.github.io/notes/boosting/&amp;title=Boosting" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

      














      
      
    </div>
  </div>
</div>

  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      <div class="ox-hugo-toc toc">
<div class="heading">Table of Contents</div>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#adaboost">AdaBoost</a></li>
</ul>
</div>
<!--endtoc-->
<h2 id="introduction">Introduction</h2>
<p>Combining predictions from multiple sources is usually preferred to a single source.
For example, a medical diagnosis would carry much more weight if it was the result of a consensus of several experts.
This idea of prediction by consensus is a powerful way to improve classification and regression models.
In fact, good performance of a committee of models can be achieved even if each individual model is conceptually very simple.</p>
<p><strong>Boosting</strong> is one such way of building a committee of models for classification or regression and is popularly implemented by an algorithm called <strong>AdaBoost</strong>.</p>
<h2 id="adaboost">AdaBoost</h2>
<p>Given a dataset \(\{\mathbf{x}_i\}\) and target variables \(\{\mathbf{y}_i\}\), AdaBoost first initializes a set of weights corresponding to each data sample as \(w_i = \frac{1}{N}\).
At each step of the algorithm, a simple classifier, called a <strong>weak learner</strong> is fit to the data.
The weights for each sample are adjusted based on the individual classifier&rsquo;s performance.
If the sample was misclassified, the relative weight for that sample is increased.
After all classifiers have been fit, they are combined to form an ensemble model.</p>
<h3 id="the-algorithm">The Algorithm</h3>
<ol>
<li>
<p>Initialize data weights \({w_i}\) as \(w_i^{(1)} = \frac{1}{n}\) for \(i = 1, \dots, n\).</p>
</li>
<li>
<p>Fit each weak learner \(j\) to the training data by minimizing the misclassification cost:</p>
<p>\[
\sum_{i=1}^n w_i^{(j)} \mathbb{1}(f_j(\mathbf{x}_i) \neq \mathbf{y}_i)
\]</p>
</li>
<li>
<p>Compute a weighted error rate</p>
<p>\[
\epsilon_j = \frac{\sum_{i=1}^n w_i^{(j)} \mathbb{1}(f_j(\mathbf{x}_i) \neq \mathbf{y}_i)}{\sum_{i=1}^n w_i^{(j)}}
\]</p>
</li>
<li>
<p>Use the weighted error rate to compute a weight for each classifier such that misclassified samples are given higher weight:</p>
<p>\[
\alpha_j = \ln \bigg\{\frac{1 - \epsilon_j}{\epsilon_j}\bigg\}.
\]</p>
</li>
<li>
<p>Update the data weights for the next model in the sequence:</p>
<p>\[
w_i^{j+1} = w_i^{j} \exp\{\alpha_j \mathbb{1}(f_j(\mathbf{x}_i \neq \mathbf{y}_i)\}.
\]</p>
</li>
</ol>
<p>Once all weak learners are trained, the final model predictions are given by</p>
<p>\[
Y_M(\mathbf{x}) = \text{sign} \Bigg(\sum_{j=1}^M \alpha_j f_j(\mathbf{x})\Bigg).
\]</p>
<h3 id="weak-learners">Weak Learners</h3>
<p>The weak learners can be any classification or regression model.
However, they are typically chosen to be very simple to account for training time.
For example, a complex deep learning model would be a poor choice for a weak learner.</p>
<p>One example of a weak learner is a simple linear model like a <a href="/notes/perceptron/">Perceptron</a> or decision stump.
A standard implementation of AdaBoost uses a decision tree with depth 1, as observed in <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html?highlight=boost#sklearn.ensemble.AdaBoostClassifier" target="_blank" rel="noopener noreferrer">sklearn&rsquo;s implementation.</a></p>
<h3 id="example">Example</h3>
<p>Let&rsquo;s put this together and walk through the first few steps of training an AdaBoost model using a decision stump as the weak learner. We will use a very simple dataset to keep the values easy to compute by hand.</p>
<p><strong>Initial Data</strong></p>
<table>
  <thead>
      <tr>
          <th>x1</th>
          <th>x2</th>
          <th>y</th>
          <th>weight</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>5</td>
          <td>0</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>2</td>
          <td>6</td>
          <td>1</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>3</td>
          <td>7</td>
          <td>0</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>4</td>
          <td>8</td>
          <td>1</td>
          <td>0.2</td>
      </tr>
      <tr>
          <td>5</td>
          <td>9</td>
          <td>1</td>
          <td>0.2</td>
      </tr>
  </tbody>
</table>
<p><strong>Weak Learner 1</strong></p>
<p>The first learner is trained on the initial data and picks \(x_1 = 2.5\) as the split threshold.
Input where \(x_1 \leq 2.5\) is assigned to class 0 and all other samples are assigned class 1.
The data with this learner&rsquo;s predictions are shown below.</p>
<table>
  <thead>
      <tr>
          <th>x1</th>
          <th>x2</th>
          <th>y</th>
          <th>weight</th>
          <th>prediction</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>5</td>
          <td>0</td>
          <td>0.2</td>
          <td>0</td>
      </tr>
      <tr>
          <td>2</td>
          <td>6</td>
          <td>1</td>
          <td>0.2</td>
          <td>0</td>
      </tr>
      <tr>
          <td>3</td>
          <td>7</td>
          <td>0</td>
          <td>0.2</td>
          <td>1</td>
      </tr>
      <tr>
          <td>4</td>
          <td>8</td>
          <td>1</td>
          <td>0.2</td>
          <td>1</td>
      </tr>
      <tr>
          <td>5</td>
          <td>9</td>
          <td>1</td>
          <td>0.2</td>
          <td>1</td>
      </tr>
  </tbody>
</table>
<p><strong>Error and weight</strong></p>
<p>The error is simple enough to compute as all samples are currently weighted equally. Since two of the samples were misclassified, the error is the sum of their weights.</p>
<p><strong>Total error</strong></p>
<p>\(e_1 = 0.2 + 0.2 = 0.4\).</p>
<p>The weight of the classifier can then be computed.</p>
<p><strong>Classifier weight</strong></p>
<p>\(\alpha_1 = \frac{1}{2} \ln \big(\frac{1 - e_1}{e_1}\big) = 0.2027\).</p>
<p>The weights of our data can now be updated using this value of \(\alpha_1\).
The weight of each example is updated by multiplying each correctly classifed sample by \(\exp\{-\alpha_1\}\) and each incorrectly classified sample by \(\exp\{\alpha\}\):</p>
<p>\[
w_i^{j+1} = w_i^{j} \exp\{\alpha_j \mathbb{1}(f_j(\mathbf{x}_i \neq \mathbf{y}_i)\}.
\]</p>
<p><strong>NOTE:</strong> You will notice that the equation above is different from the actual update rule that was applied to the weights in this example. In the original publication <strong>(TODO: reference Fruend)</strong>, the weights are renormalized at the end of the loop. In this example, the normalization is combined with the update. In either case, the updated weights are shown below.</p>
<table>
  <thead>
      <tr>
          <th>x1</th>
          <th>x2</th>
          <th>y</th>
          <th>weight</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>5</td>
          <td>0</td>
          <td>0.167</td>
      </tr>
      <tr>
          <td>2</td>
          <td>6</td>
          <td>1</td>
          <td>0.250</td>
      </tr>
      <tr>
          <td>3</td>
          <td>7</td>
          <td>0</td>
          <td>0.250</td>
      </tr>
      <tr>
          <td>4</td>
          <td>8</td>
          <td>1</td>
          <td>0.167</td>
      </tr>
      <tr>
          <td>5</td>
          <td>9</td>
          <td>1</td>
          <td>0.167</td>
      </tr>
  </tbody>
</table>
<p><strong>Weak Learner 2</strong></p>
<p>The algorithm now moves to the next weak learner, which classifies the data given a threshold of \(x_1 = 3.5\). Its predictions are shown below.</p>
<table>
  <thead>
      <tr>
          <th>x1</th>
          <th>x2</th>
          <th>y</th>
          <th>weight</th>
          <th>prediction</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>5</td>
          <td>0</td>
          <td>0.167</td>
          <td>0</td>
      </tr>
      <tr>
          <td>2</td>
          <td>6</td>
          <td>1</td>
          <td>0.250</td>
          <td>0</td>
      </tr>
      <tr>
          <td>3</td>
          <td>7</td>
          <td>0</td>
          <td>0.250</td>
          <td>0</td>
      </tr>
      <tr>
          <td>4</td>
          <td>8</td>
          <td>1</td>
          <td>0.167</td>
          <td>1</td>
      </tr>
      <tr>
          <td>5</td>
          <td>9</td>
          <td>1</td>
          <td>0.167</td>
          <td>1</td>
      </tr>
  </tbody>
</table>
<p>Only a single sample is misclassified, and the error is computed as before.</p>
<p><strong>Total error</strong></p>
<p>\(e_2 = 0.250\)</p>
<p><strong>Classifier weight</strong></p>
<p>\(\alpha_2 = \frac{1}{2} \ln \big(\frac{1 - e_2}{e_2}\big) = 0.5493\)</p>
<p>The weights are updated for each sample, yielding the following data:</p>
<table>
  <thead>
      <tr>
          <th>x1</th>
          <th>x2</th>
          <th>y</th>
          <th>weight</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>5</td>
          <td>0</td>
          <td>0.111</td>
      </tr>
      <tr>
          <td>2</td>
          <td>6</td>
          <td>1</td>
          <td>0.500</td>
      </tr>
      <tr>
          <td>3</td>
          <td>7</td>
          <td>0</td>
          <td>0.167</td>
      </tr>
      <tr>
          <td>4</td>
          <td>8</td>
          <td>1</td>
          <td>0.111</td>
      </tr>
      <tr>
          <td>5</td>
          <td>9</td>
          <td>1</td>
          <td>0.111</td>
      </tr>
  </tbody>
</table>
<p>The second sample has been misclassified twice at this point, leading to a relatively high weight. This will hopefully be addressed by the third learner.</p>
<p><strong>Weak Learner 3</strong></p>
<p>The final weak learner splits the data on \(x_2 = 6.5\), yielding the following output for each sample.</p>
<table>
  <thead>
      <tr>
          <th>x1</th>
          <th>x2</th>
          <th>y</th>
          <th>weight</th>
          <th>prediction</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>5</td>
          <td>0</td>
          <td>0.111</td>
          <td>0</td>
      </tr>
      <tr>
          <td>2</td>
          <td>6</td>
          <td>1</td>
          <td>0.500</td>
          <td>0</td>
      </tr>
      <tr>
          <td>3</td>
          <td>7</td>
          <td>0</td>
          <td>0.167</td>
          <td>1</td>
      </tr>
      <tr>
          <td>4</td>
          <td>8</td>
          <td>1</td>
          <td>0.111</td>
          <td>1</td>
      </tr>
      <tr>
          <td>5</td>
          <td>9</td>
          <td>1</td>
          <td>0.111</td>
          <td>1</td>
      </tr>
  </tbody>
</table>
<p>Unfortunately, sample 2 is too tricky for any of our weak learners. The total error is shown below. Since this is a binary classification problem, the error suggests that our weak learner performs worse than random guessing.</p>
<p><strong>Total error</strong></p>
<p>\(e_3 = 0.667\)</p>
<p><strong>Classifier weight</strong></p>
<p>\(\alpha_3 = \frac{1}{2} \ln \big(\frac{1 - e_3}{e_3}\big) = -0.3473\)</p>
<p>The negative value of the classifier weight suggests that its predictions will be reversed when evaluated. The updated weights of each data sample are given below.</p>
<table>
  <thead>
      <tr>
          <th>x1</th>
          <th>x2</th>
          <th>y</th>
          <th>weight</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>5</td>
          <td>0</td>
          <td>0.167</td>
      </tr>
      <tr>
          <td>2</td>
          <td>6</td>
          <td>1</td>
          <td>0.375</td>
      </tr>
      <tr>
          <td>3</td>
          <td>7</td>
          <td>0</td>
          <td>0.125</td>
      </tr>
      <tr>
          <td>4</td>
          <td>8</td>
          <td>1</td>
          <td>0.167</td>
      </tr>
      <tr>
          <td>5</td>
          <td>9</td>
          <td>1</td>
          <td>0.167</td>
      </tr>
  </tbody>
</table>
<p><strong>Final Classifier</strong></p>
<p>The final classifier is a weighted vote of the three weak learners, with the weights being the classifier weights we calculated (0.2027, 0.5493, and -0.3473). The negative weight means that the third learner&rsquo;s predictions are reversed.</p>

    </div>

    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/machine-learning/">machine learning</a>
  
</div>



    
      








  
  
    
  
  





  
  
  
    
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="https://ajdillhoff.github.io/">Alex Dillhoff</a></h5>
      <h6 class="card-subtitle">Senior Lecturer</h6>
      <p class="card-text" itemprop="description">&quot;If we understood the world, we would realize that there is a logic of harmony underlying its manifold apparent dissonances.&quot; - Jean Sibelius</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="/#contact" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://scholar.google.co.uk/citations?user=UlLhCtkAAAAJ" target="_blank" rel="noopener">
              <i class="ai ai-google-scholar"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/ajdillhoff" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/notes/decision_trees/">Decision Trees</a></li>
          
          <li><a href="/notes/camera_models/">Camera Models</a></li>
          
          <li><a href="/notes/hidden_markov_models/">Hidden Markov Models</a></li>
          
          <li><a href="/notes/random_sample_consensus/">RANdom SAmple Consensus</a></li>
          
          <li><a href="/notes/kernels/">Kernels</a></li>
          
        </ul>
      </div>
      
    

    

    

  </div>
</article>

      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    

    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academia.min.6c2ba2801d406881b3c2277043cedd76.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  <div class="container">
    <div class="row align-items-center">
      <div class="col-md-6 mb-4 mb-md-0">
        
        <p class="mb-0">
          Copyright © 2024 &middot; 
          Powered by
          <a href="https://gethugothemes.com" target="_blank" rel="noopener">Gethugothemes</a>
        </p>
      </div>
      <div class="col-md-6">
        <ul class="list-inline network-icon text-right mb-0">
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="list-inline-item">
            <a href="https://github.com/ajdillhoff" target="_blank" rel="noopener" title="My GitHub"><i class="fab fa-github" aria-hidden="true"></i></a>
          </li>
          
          
          
          
          
          
          
          
          
          
          <li class="list-inline-item">
            <a href="https://github.com/ajdillhoff" target="_blank" rel="noopener" title="My GitHub"><i class="ai ai-google-scholar" aria-hidden="true"></i></a>
          </li>
          
        </ul>
      </div>
    </div>
  </div>
</footer>
  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
