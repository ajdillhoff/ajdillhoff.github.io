<!DOCTYPE html>
<html lang="en-us">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academia 4.3.1">
  <meta name="theme-name" content="academia-hugo"/>

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Alex Dillhoff">

  
  
  
    
  
  <meta name="description" content="
Table of Contents

Topics
Introduction
Definition
Markov Decision Processes
RL vs. MDP
Passive RL
Resources



Topics

What is reinforcement learning?
Examples
Finite Markov Decision Processes
Passive vs. Active Methods
Adaptive Dynamic Programming
Monte Carlo Methods
Temporal-Different Learning
Q-Learning
Function Approximation
Deep Q-Learning
Policy and Value Iteration
Case Studies

Introduction
When placed in a new environment, we orient and learn about it by interacting with it.
When given a novel task, we may not be able to explicitly describe the task or even perform well at it, but we can learn a lot about it through trial and error.">

  
  <link rel="alternate" hreflang="en-us" href="http://localhost:1313/notes/reinforcement_learning/">

  


  

  
  
  
  <meta name="theme-color" content="#fc6f5c">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Open+Sans|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academia.min.b246554d075350d61b44c126dfbcbe05.css">

  
    
    
    
    
      
    
    
    
    <link rel="stylesheet" href="/css/academia.a75a9b8a9a725a2157c0c5b929a3d18b.css">
  

  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="http://localhost:1313/notes/reinforcement_learning/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Alex Dillhoff">
  <meta property="og:url" content="http://localhost:1313/notes/reinforcement_learning/">
  <meta property="og:title" content="Reinforcement Learning | Alex Dillhoff">
  <meta property="og:description" content="
Table of Contents

Topics
Introduction
Definition
Markov Decision Processes
RL vs. MDP
Passive RL
Resources



Topics

What is reinforcement learning?
Examples
Finite Markov Decision Processes
Passive vs. Active Methods
Adaptive Dynamic Programming
Monte Carlo Methods
Temporal-Different Learning
Q-Learning
Function Approximation
Deep Q-Learning
Policy and Value Iteration
Case Studies

Introduction
When placed in a new environment, we orient and learn about it by interacting with it.
When given a novel task, we may not be able to explicitly describe the task or even perform well at it, but we can learn a lot about it through trial and error."><meta property="og:image" content="http://localhost:1313/img/icon-192.png">
  <meta property="twitter:image" content="http://localhost:1313/img/icon-192.png"><meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2023-07-12T00:00:00-05:00">
  
  <meta property="article:modified_time" content="2023-07-12T00:00:00-05:00">
  

  


  





  <title>Reinforcement Learning | Alex Dillhoff</title>

  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>



</head>


<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Alex Dillhoff</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation"><span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">
      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/notes/"><span>Brain Dump</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Courses</span></a>
        </li>

        
        

      

        

        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>
    </div>
  </div>
</nav>


  <article class="article py-5" itemscope itemtype="http://schema.org/Article">

  












    

    
    
    
    <div class="article-container py-3">
      <h1 itemprop="name">Reinforcement Learning</h1>

      

      
      



<meta content="2023-07-12 00:00:00 -0500 CDT" itemprop="datePublished">
<meta content="2023-07-12 00:00:00 -0500 CDT" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Jul 12, 2023</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 min read
  </span>
  

  
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=http://localhost:1313/notes/reinforcement_learning/&amp;text=Reinforcement%20Learning" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=http://localhost:1313/notes/reinforcement_learning/&amp;t=Reinforcement%20Learning" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Reinforcement%20Learning&amp;body=http://localhost:1313/notes/reinforcement_learning/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=http://localhost:1313/notes/reinforcement_learning/&amp;title=Reinforcement%20Learning" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Reinforcement%20Learning%20http://localhost:1313/notes/reinforcement_learning/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=http://localhost:1313/notes/reinforcement_learning/&amp;title=Reinforcement%20Learning" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

      














      
      
    </div>
  </div>
</div>

  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      <div class="ox-hugo-toc toc">
<div class="heading">Table of Contents</div>
<ul>
<li><a href="#topics">Topics</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#definition">Definition</a></li>
<li><a href="#markov-decision-processes">Markov Decision Processes</a></li>
<li><a href="#rl-vs-dot-mdp">RL vs. MDP</a></li>
<li><a href="#passive-rl">Passive RL</a></li>
<li><a href="#resources">Resources</a></li>
</ul>
</div>
<!--endtoc-->
<h2 id="topics">Topics</h2>
<ul>
<li>What is reinforcement learning?</li>
<li>Examples</li>
<li>Finite Markov Decision Processes</li>
<li>Passive vs. Active Methods</li>
<li>Adaptive Dynamic Programming</li>
<li>Monte Carlo Methods</li>
<li>Temporal-Different Learning</li>
<li>Q-Learning</li>
<li>Function Approximation</li>
<li>Deep Q-Learning</li>
<li>Policy and Value Iteration</li>
<li>Case Studies</li>
</ul>
<h2 id="introduction">Introduction</h2>
<p>When placed in a new environment, we orient and learn about it by interacting with it.
When given a novel task, we may not be able to explicitly describe the task or even perform well at it, but we can learn a lot about it through trial and error.</p>
<p>Image if you were to be thrown into an alien world teaming with unknown life forms.
You would not be able to identify these life forms, but you would be able to learn about their behaviors, shape, surface anatomy, and other attributes based on perception alone.
Simply learning about the structure of the environment is the task of unsupervised learning.</p>
<p>In supervised machine learning, there is typically some objective function that is minimized based on ground truth or target variables that are known ahead of time.
In settings like the ones depicted above, there is no form of supervision.
Instead, a representation of the environment is learned from one&rsquo;s experience and sensory input.</p>
<p>Reinforcement learning maps environment input to actions.
For example, an agent trained to play Chess will evaluate the current board and make a decision based on experience.
Whether or not that decision was beneficial may not immediately be known.
If it results in winning against an opponent, the model would strengthen its knowledge of that particular play.
The concept of trial-and-error and the fact that an agent may not know if the correct decision was made until later are two of the most important concepts of reinforcement learning.</p>
<p>There are many challenges present in reinforcement learning.
The agents consider the entire environment and attempt to maximize some reward value based on a well defined goal.
There is then a trade off between <strong>exploiting</strong> actions that are known to give a positive reward and <strong>exploring</strong> new actions that may lead to a better payoff.</p>
<p>Reinforcement learning is the study of goal-seeking agents that can sense some aspect of their environment and can perform actions that directly affect that environment. An agent is not always a robot, although it is a popular use case. Taking from recent popularity, agents such as <a href="https://www.deepmind.com/research/highlighted-research/alphago" target="_blank" rel="noopener noreferrer">AlphaGo</a> exist within a game playing environment where their goal is win.</p>
<h3 id="examples">Examples</h3>
<p><strong>Gaming:</strong> Agents for traditional board games such as Chess and <a href="https://www.deepmind.com/research/highlighted-research/alphago" target="_blank" rel="noopener noreferrer">Go</a> have been implemented, surpassing even the best players in the world. Video games are also a popular environment for constructing complex agents. Developers can use RL to construct sophisticated characters in the game that behave in complex way as well as react more realistically towards the player. DeepMind introduced a powerful agent for <a href="https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii" target="_blank" rel="noopener noreferrer">StarCaft II</a> which beat some of the best human players in the world. OpenAI debuted <a href="https://openai.com/research/openai-five-defeats-dota-2-world-champions" target="_blank" rel="noopener noreferrer">OpenAI Five</a> at the 2019 Dota 2 World Championships, defeating the championship team back-to-back.</p>
<p>OpenAI released OpenAI gym, now an open source project named <a href="https://github.com/Farama-Foundation/Gymnasium" target="_blank" rel="noopener noreferrer">Gymnasium</a>, which is a library for developing and comparing reinforcement learning algorithms. One of recent interest is <a href="https://www.twitch.tv/rlgym" target="_blank" rel="noopener noreferrer">RLGym</a>, a Rocket League agent.</p>
<h2 id="definition">Definition</h2>
<p>A reinforcement learning system is identified by the <strong>environment</strong> and an <strong>agent</strong> acting in that environment.
An agent&rsquo;s behavior in the environment is defined by a <strong>policy</strong>.
A policy usually describes a set of rules in response to the current state of the environment.</p>
<p>In order to improve on some task, a <strong>reward signal</strong> is defined.
Over time, an agent should maximize the reward.
In general, an action leading to a favorable outcome should present a high reward value.</p>
<p>A <strong>value function</strong> describes the estimated total reward over the long run given the agent&rsquo;s current state.
Taking an action that results in an immediate reward may lead to a lower payoff in the long run.
This can be predicted from the value function.</p>
<p>Additionally, a <strong>model</strong> of the environment will include prior knowledge about that environment.
This allows the agent to act optimally over a longer sequence of states.</p>
<h2 id="markov-decision-processes">Markov Decision Processes</h2>
<h2 id="rl-vs-dot-mdp">RL vs. MDP</h2>
<p>Reinforcement learning does not assume the <strong>transition model</strong> or the <strong>reward function</strong>.</p>
<h2 id="passive-rl">Passive RL</h2>
<p>The policy is fixed while the transition model and reward function are learned over time.
The goal is to compute the utility of each state.</p>
<h3 id="adaptive-dynamic-programming">Adaptive Dynamic Programming</h3>
<p>\(R(s)\) and \(p(s&rsquo;|s,a)\) can be updated at each step based solely on the observations.
Using these observations, the utility of each state can be estimated following policy evaluation (TODO: link algorithm for policy evaluation).</p>
<h2 id="resources">Resources</h2>
<ul>
<li><a href="https://web.stanford.edu/class/cs234/modules.html" target="_blank" rel="noopener noreferrer">https://web.stanford.edu/class/cs234/modules.html</a></li>
<li><a href="https://lilianweng.github.io/posts/2018-02-19-rl-overview/" target="_blank" rel="noopener noreferrer">https://lilianweng.github.io/posts/2018-02-19-rl-overview/</a></li>
</ul>

    </div>

    



    
      








  





  
  
  
    
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="http://localhost:1313/">Alex Dillhoff</a></h5>
      <h6 class="card-subtitle">Senior Lecturer</h6>
      <p class="card-text" itemprop="description">&quot;If we understood the world, we would realize that there is a logic of harmony underlying its manifold apparent dissonances.&quot; - Jean Sibelius</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="/#contact" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://scholar.google.co.uk/citations?user=UlLhCtkAAAAJ" target="_blank" rel="noopener">
              <i class="ai ai-google-scholar"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/ajdillhoff" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
    

    

    

  </div>
</article>

      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    

    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academia.min.6c2ba2801d406881b3c2277043cedd76.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  <div class="container">
    <div class="row align-items-center">
      <div class="col-md-6 mb-4 mb-md-0">
        
        <p class="powered-by">
          <a href="/privacy/">Privacy Policy</a>
        </p>
        
        <p class="mb-0">
          Copyright © 2025 &middot; 
          Powered by
          <a href="https://gethugothemes.com" target="_blank" rel="noopener">Gethugothemes</a>
        </p>
      </div>
      <div class="col-md-6">
        <ul class="list-inline network-icon text-right mb-0">
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="list-inline-item">
            <a href="https://github.com/ajdillhoff" target="_blank" rel="noopener" title="My GitHub"><i class="fab fa-github" aria-hidden="true"></i></a>
          </li>
          
          
          
          
          
          
          
          
          
          
          <li class="list-inline-item">
            <a href="https://github.com/ajdillhoff" target="_blank" rel="noopener" title="My GitHub"><i class="ai ai-google-scholar" aria-hidden="true"></i></a>
          </li>
          
        </ul>
      </div>
    </div>
  </div>
</footer>
  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
