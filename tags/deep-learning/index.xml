<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Alex Dillhoff</title>
    <link>https://ajdillhoff.github.io/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on Alex Dillhoff</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Tue, 21 Jan 2025 00:00:00 -0500</lastBuildDate>
    <atom:link href="https://ajdillhoff.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Low Rank Adaptation</title>
      <link>https://ajdillhoff.github.io/notes/low_rank_adaptation/</link>
      <pubDate>Sat, 08 Jun 2024 13:03:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/low_rank_adaptation/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#key-concepts&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Key Concepts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts&lt;/h2&gt;&#xA;&lt;h3 id=&#34;traditional-fine-tuning&#34;&gt;Traditional Fine-Tuning&lt;/h3&gt;&#xA;&lt;p&gt;Fine-tuning a model for a specific task can be expensive if the entire weight matrix is updated. LLMs range from billions to trillions of parameters, making fine-tuning infeasible for many applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Patch Extraction</title>
      <link>https://ajdillhoff.github.io/notes/patch_extraction/</link>
      <pubDate>Thu, 06 Jun 2024 17:57:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/patch_extraction/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#native-patch-extraction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Native Patch Extraction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#changing-perspective&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Changing Perspective&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-mechanics-of-as-strided&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Mechanics of &lt;code&gt;as_strided&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-about-rgb&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What about RGB?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;This post is a recreation of &lt;a href=&#34;https://x.com/MishaLaskin/status/1478500251376009220&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Misha Laskin&amp;rsquo;s Twitter post&lt;/a&gt; about patch extraction in &lt;code&gt;numpy&lt;/code&gt;. I wanted to provide a version of it that can be accessed without requiring a Twitter account.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using the cuDNN Library</title>
      <link>https://ajdillhoff.github.io/notes/using_the_cudnn_library/</link>
      <pubDate>Mon, 15 Apr 2024 20:14:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/using_the_cudnn_library/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-is-cudnn&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What is cuDNN?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#setting-up-cudnn&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Setting up cuDNN&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#handling-errors&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Handling Errors&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#representing-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Representing Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dense-layers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dense Layers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#activation-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Activation Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#loss-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Loss Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#convolutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Convolutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#pooling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Pooling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;what-is-cudnn&#34;&gt;What is cuDNN?&lt;/h2&gt;&#xA;&lt;p&gt;NVIDIA cuDNN provides optimized implementations of core operations used in deep learning. It is designed to be integrated into higher-level machine learning frameworks, such as TensorFlow, PyTorch, and Caffe.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Natural Language Processing</title>
      <link>https://ajdillhoff.github.io/notes/natural_language_processing/</link>
      <pubDate>Sun, 23 Apr 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/natural_language_processing/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#text-preprocessing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Text Preprocessing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tasks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tasks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#models&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#perplexity&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Perplexity&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Text Preprocessing&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Character-level tokenization&lt;/li&gt;&#xA;&lt;li&gt;Word-level tokenization&lt;/li&gt;&#xA;&lt;li&gt;Subword tokenization&lt;/li&gt;&#xA;&lt;li&gt;Stopwords&lt;/li&gt;&#xA;&lt;li&gt;Batching&lt;/li&gt;&#xA;&lt;li&gt;Padding&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Unsupervised Pre-Training&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Autoregression&lt;/li&gt;&#xA;&lt;li&gt;BERT loss&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Tasks&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Text Classification&lt;/li&gt;&#xA;&lt;li&gt;Named Entity Recognition&lt;/li&gt;&#xA;&lt;li&gt;Question Answering&lt;/li&gt;&#xA;&lt;li&gt;Summarization&lt;/li&gt;&#xA;&lt;li&gt;Translation&lt;/li&gt;&#xA;&lt;li&gt;Text Generation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;text-preprocessing&#34;&gt;Text Preprocessing&lt;/h2&gt;&#xA;&lt;p&gt;Text preprocessing is an essential step in NLP that involves cleaning and transforming unstructured text data to prepare it for analysis. Some common text preprocessing techniques include:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformers</title>
      <link>https://ajdillhoff.github.io/notes/transformers/</link>
      <pubDate>Sun, 06 Nov 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/transformers/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#attention&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Attention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#key-value-store&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Key-value Store&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#scaled-dot-product-attention&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Scaled Dot Product Attention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multi-head-attention&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multi-Head Attention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#encoder-decoder-architecture&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Encoder-Decoder Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#encoder&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Encoder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#decoder&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Decoder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#usage&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Usage&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The story of Transformers begins with &amp;ldquo;Attention Is All You Need&amp;rdquo; (Vaswani et al., n.d.). In this seminal work, the authors describe the current landscape of sequential models, their shortcomings, and the novel ideas that result in their successful application.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Long Short-Term Memory</title>
      <link>https://ajdillhoff.github.io/notes/long_short_term_memory/</link>
      <pubDate>Tue, 12 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/long_short_term_memory/</guid>
      <description>&lt;p&gt;The recurrent nature of RNNs means that gradients get smaller and smaller as the timesteps increase.&#xA;This is known as the &lt;strong&gt;vanishing gradient problem&lt;/strong&gt;.&#xA;One of the first popular solutions to this problem is called &lt;strong&gt;Long Short-Term Memory&lt;/strong&gt;, a recurrent network architecture by Hochreiter and Schmidhuber.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Recurrent Neural Networks</title>
      <link>https://ajdillhoff.github.io/notes/recurrent_neural_networks/</link>
      <pubDate>Sun, 10 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/recurrent_neural_networks/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bidirectional-recurrent-neural-networks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bidirectional Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#references&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Neural networks are an effective tool for regression and classification tasks, but they do not consider the dependencies of information over time.&#xA;Many tasks have implicit information that is dependent on input that may have already been processed or may not be seen until the future.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimization for Deep Learning</title>
      <link>https://ajdillhoff.github.io/notes/optimization_for_deep_learning/</link>
      <pubDate>Thu, 07 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/optimization_for_deep_learning/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gradient-descent-and-its-variants&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Gradient Descent and its Variants&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#adaptive-learning-rate-methods&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Adaptive Learning Rate Methods&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#parameter-initialization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Parameter Initialization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ruder.io/optimizing-gradient-descent/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://ruder.io/optimizing-gradient-descent/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.deeplearningbook.org/contents/optimization.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://www.deeplearningbook.org/contents/optimization.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;empirical risk minimization&lt;/strong&gt; - minimizing over an empirical distribution. Differs from risk minimization which is minimizing over the true distribution. We typically do not know the true distribution.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Convolutional Neural Networks</title>
      <link>https://ajdillhoff.github.io/notes/convolutional_neural_networks/</link>
      <pubDate>Sat, 02 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/convolutional_neural_networks/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#convolution-operator&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Convolution Operator&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#properties-of-convolutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Properties of Convolutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#parameter-sharing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Parameter Sharing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#pooling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Pooling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#backwards-pass&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Backwards Pass&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#neural-networks-for-image-classification&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Neural Networks for Image Classification&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#useful-resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Useful Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;&lt;strong&gt;Key Concepts&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deep Learning</title>
      <link>https://ajdillhoff.github.io/notes/deep_learning/</link>
      <pubDate>Tue, 29 Mar 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/deep_learning/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-makes-a-model-deep&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What makes a model deep?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#deep-networks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Deep Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#deep-vs-dot-shallow-networks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Deep vs. Shallow Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#high-dimensional-structured-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;High Dimensional Structured Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#activation-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Activation Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#loss-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Loss Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#a-typical-training-pipeline&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;A Typical Training Pipeline&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#useful-links&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Useful Links&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Deep learning is a term that you&amp;rsquo;ve probably heard of a million times by now in different contexts. It is an umbrella term that encompasses techniques for computer vision, bioinformatics, natural language processing, and much more. It almost always involves a neural network of some kind that was trained on a large corpus of data.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
