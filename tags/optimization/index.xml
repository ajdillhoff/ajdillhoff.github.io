<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Optimization on Alex Dillhoff</title>
    <link>https://ajdillhoff.github.io/tags/optimization/</link>
    <description>Recent content in Optimization on Alex Dillhoff</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; {year}</copyright>
    <lastBuildDate>Sat, 05 Feb 2022 00:00:00 -0600</lastBuildDate>
    
	    <atom:link href="https://ajdillhoff.github.io/tags/optimization/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Lagrangian Multipliers</title>
      <link>https://ajdillhoff.github.io/notes/lagrangian_multipliers/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/lagrangian_multipliers/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s take a simple constrained problem (from Nocedal and Wright).&lt;/p&gt;
&lt;p&gt;\begin{align*}
\min \quad &amp;amp; x_1 + x_2\\
\textrm{s.t.} \quad &amp;amp; x_1^2 + x_2^2 - 2 = 0
\end{align*}&lt;/p&gt;
&lt;p&gt;The set of possible solutions to this problem lie on the boundary of the circle defined by the constraint:&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2021-12-01_18-06-50_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Source: Nocedal and Wright&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Source: Nocedal and Wright
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;If we let \(g(\mathbf{x}) = x_1^2 + x_2^2 - 2\), then the gradient vector is \((2x_1, 2x_2)\)&lt;/p&gt;
&lt;p&gt;Our original function \(f(\mathbf{x}) = x_1 + x_2\) has a gradient vector of \((1, 1)\).&lt;/p&gt;
&lt;p&gt;The figure above visualizes these vectors at different points on the constraint boundary.&lt;/p&gt;
&lt;p&gt;Notice that the optimal solution \(\mathbf{x}^* = (-1, -1)\) is at a point where \(\nabla g(\mathbf{x}^*)\) is parallel to \(\nabla f(\mathbf{x}^*)\). However, the gradients of the vectors are not equal. So there must be some scalar \(\lambda\) such that \(\nabla f(\mathbf{x}^*) = \lambda \nabla g(\mathbf{x}^*)\).&lt;/p&gt;
&lt;p&gt;This scalar \(\lambda\) is called a Lagrangian multiplier. We use this and introduce the Lagrangian function:&lt;/p&gt;
&lt;p&gt;\begin{equation*}
\mathcal{L}(\mathbf{x}, \lambda) = f(\mathbf{x}) - \lambda g(\mathbf{x})
\end{equation*}&lt;/p&gt;
&lt;p&gt;This yields a form for which we can analytically calculate the stationary points. That is,&lt;/p&gt;
&lt;p&gt;\begin{equation*}
\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}^*, \lambda^*) = 0.
\end{equation*}&lt;/p&gt;
&lt;h2 id=&#34;lagrangian-duality&#34;&gt;Lagrangian Duality&lt;/h2&gt;
&lt;p&gt;In general, the primal optimization problem is formulated as&lt;/p&gt;
&lt;p&gt;\begin{align*}
\min_{w} \quad &amp;amp; f(w)\\
\textrm{s.t.} \quad &amp;amp; g_i(w) \leq 0, \quad i = 1, \dots, k\\
&amp;amp; h_i(w) = 0, \quad i = 1, \dots, l.
\end{align*}&lt;/p&gt;
&lt;p&gt;The Lagrangian function is then&lt;/p&gt;
&lt;p&gt;\[
L(w, \alpha, \beta) = f(w) + \sum_{i=1}^k\alpha_i g_i(w) + \sum_{i=1}^l \beta_i h_i(w).
\]&lt;/p&gt;
&lt;h2 id=&#34;additional-resources&#34;&gt;Additional Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cs229.stanford.edu/notes2021fall/cs229-notes3.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://cs229.stanford.edu/notes2021fall/cs229-notes3.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
