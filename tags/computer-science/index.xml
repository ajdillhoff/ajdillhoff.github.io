<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Science on Alex Dillhoff</title>
    <link>https://ajdillhoff.github.io/tags/computer-science/</link>
    <description>Recent content in Computer Science on Alex Dillhoff</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; {year}</copyright>
    <lastBuildDate>Tue, 27 Feb 2024 19:12:00 -0600</lastBuildDate>
    
	    <atom:link href="https://ajdillhoff.github.io/tags/computer-science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Substitution Method</title>
      <link>https://ajdillhoff.github.io/notes/substitution_method/</link>
      <pubDate>Tue, 27 Feb 2024 19:12:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/substitution_method/</guid>
      <description>&lt;p&gt;The &lt;strong&gt;substitution method&lt;/strong&gt; is a technique for solving recurrences. It works in two steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Guess the solution&lt;/li&gt;
&lt;li&gt;Use mathematical induction to verify the guess&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This can work very well, especially if we already have some intuition about the problem. Let&amp;rsquo;s start with a simple example: The Tower of Hanoi. In this classic puzzle, we have three pegs and a number of disks of different sizes which can slide onto any peg. The puzzle starts with the disks in a neat stack in ascending order of size on one peg, with the smallest disk on top. The objective is to move the entire stack to another peg, obeying the following rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Only one disk can be moved at a time&lt;/li&gt;
&lt;li&gt;Each move consists of taking the top disk from one of the stacks and placing it on top of another stack&lt;/li&gt;
&lt;li&gt;No disk may be placed on top of a smaller disk&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The number of moves required to solve the Tower of Hanoi puzzle is given by the recurrence relation \(T(n) = 2T(n-1) + 1\) with the initial condition \(T(1) = 1\). We can solve this recurrence using the substitution method.&lt;/p&gt;
&lt;p&gt;Our hypothesis might be that \(T(n) \leq c2^n\) for all \(n \geq n_0\), where \(c &amp;gt; 0\) and \(n_0 &amp;gt; 0\). For the base case, we have \(T(1) = c * 2^1 = 1\), so \(c = 1/2\). Now we need to show that \(T(n) \leq c2^n\) for all \(n \geq n_0\). We assume that \(T(k) \leq c2^k\) for all \(k &amp;lt; n\). Then we have:&lt;/p&gt;
&lt;p&gt;\begin{align*}
T(n) &amp;amp;\leq 2T(n-1) + 1 \\
&amp;amp;\leq 2\left(\frac{2^{n-1}}{2}\right) + 1 \\
&amp;amp;= 2^n - 1 \\
\end{align*}&lt;/p&gt;
&lt;p&gt;What if we made a bad guess? Let&amp;rsquo;s try \(T(n) \leq cn\) for all \(n \geq n_0\). We have \(T(1) = c = 1\), so \(c = 1\). Now we need to show that \(T(n) \leq cn\) for all \(n \geq n_0\). We assume that \(T(k) \leq ck\) for all \(k &amp;lt; n\). Then we have:&lt;/p&gt;
&lt;p&gt;\begin{align*}
T(n) &amp;amp;\leq 2T(n-1) + 1 \\
&amp;amp;\leq 2c(n-1) + 1 \\
&amp;amp;= 2cn - 2c + 1 \\
\end{align*}&lt;/p&gt;
&lt;p&gt;This does not work because \(2cn - 2c + 1 &amp;gt; cn\) for all \(c &amp;gt; 1\). Therefore, our guess was wrong.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Quicksort</title>
      <link>https://ajdillhoff.github.io/notes/quicksort/</link>
      <pubDate>Sun, 25 Feb 2024 17:24:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/quicksort/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#basic-quicksort&#34;&gt;Basic Quicksort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#performance&#34;&gt;Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#randomized-quicksort&#34;&gt;Randomized Quicksort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#paranoid-quicksort&#34;&gt;Paranoid Quicksort&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;Quicksort is a popular sorting algorithm implemented in many language libraries that has a worst-case running time of \(\Theta(n^2)\). &lt;strong&gt;Why would anyone choose this as the default sorting algorithm if one like mergesort has better worst-case performance?&lt;/strong&gt; As you will see, the devil is in the details. Quicksort is often faster in practice. It also has a small memory footprint and is easy to implement.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TODO: Discuss distinct values and the impact on quicksort&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;basic-quicksort&#34;&gt;Basic Quicksort&lt;/h2&gt;
&lt;p&gt;Quicksort follows a divide-and-conquer approach to sorting. Given an input array of \(n\) elements, it selects a pivot element and partitions the array into two sub-arrays: one with elements less than the pivot and one with elements greater than the pivot. It then recursively sorts the sub-arrays. Since the subarrays are recursively sorted, there is no need for a merge step as in mergesort.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;quicksort&lt;/span&gt;(arr, p, r):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    q &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; partition(arr, p, r)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    quicksort(arr, p, q &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    quicksort(arr, q &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, r)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This algorithm looks deceptively simple. The complexity is hidden in the partitioning step. This procedure will rearrange the elements in the array such that the pivot element is in its final position and all elements less than the pivot are to the left of it and all elements greater than the pivot are to the right of it.&lt;/p&gt;
&lt;h3 id=&#34;partitioning&#34;&gt;Partitioning&lt;/h3&gt;
&lt;p&gt;For basic quicksort, the first or last element is chosen as the pivot. Picking it this way yields a fairly obvious recurrence of \(T(n) = T(n-1) + O(n)\), which is \(\Theta(n^2)\). As mentioned before, this algorithm is executed in-place, meaning there is no need for additional memory to store the sub-arrays. It is done through a clever use of indices.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;partition&lt;/span&gt;(arr, p, r):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; arr[r]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(p, r):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; arr[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; x:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            i &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            arr[i], arr[j] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; arr[j], arr[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    arr[i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], arr[r] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; arr[r], arr[i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The indices are used to define the following loop invariant.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Left:&lt;/strong&gt; if \(p \leq k \leq i\), then \(A[k] \leq x\)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Middle:&lt;/strong&gt; if \(i + 1 \leq k \leq j - 1\), then \(A[k] &amp;gt; x\)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Right:&lt;/strong&gt; if \(k = r\), then \(A[k] = x\)&lt;/li&gt;
&lt;/ol&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-02-25_19-18-19_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Operation of partition (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Cormen et al. 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Operation of partition (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The figure above is from CRLS which shows an example run of the partitioning algorithm. It starts with \(i, p, j\) on the left and \(r\) on the right. Since the value at \(j\) is less than the pivot, \(i\) is incremented and the values at \(i\) and \(j\) are swapped. In the next iteration, the value at \(j\) is greater than the pivot, so nothing is done. This continues until \(j\) reaches \(r\). At this point, the pivot is swapped with the value at \(i + 1\).&lt;/p&gt;
&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-02-26_16-34-22_Quicksort%20Example.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Example of Quicksort.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Example of Quicksort.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The example above starts with an unsorted array. The second row shows the array after the first call to &lt;code&gt;partition&lt;/code&gt;. The left and right subarrays are called recursively. The first subarray in row 3 has a pivot 3 and is already partitioned. The right subarray follows the same convenience.&lt;/p&gt;
&lt;p&gt;On row 4, the left subarray is modified by swapping the pivot of 2 with 1. The right subarray first swaps 5 and 7 before swapping 6 and 7. The final array is sorted as shown on the last row.&lt;/p&gt;
&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;
&lt;p&gt;The performance of quicksort is dependent on the pivot. If the subarrays on either side of the pivot are balanced, the running time is asymptotically similar to mergesort. In the worst case, it will run in quadratic time.&lt;/p&gt;
&lt;p&gt;The worst partitioning occurs when the pivot is the smallest or largest element in the array. This creates a subarray of size \(n - 1\) and another of size 0. The partitioning itself takes \(\Theta(n)\) time, yielding a recurrence of \(T(n) = T(n - 1) + \Theta(n)\). We can use the substitution method to solve this recurrence and find that the worst-case running time is \(\Theta(n^2)\). This can happen even if the input is already sorted before hand.&lt;/p&gt;
&lt;p&gt;Cormen et al. present a recursive analysis of the running time where, at each level, the partition produces a 9-to-1 split. This is visualized in the sketch below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-02-26_18-20-51_Quicksort%20Recursion%2001%20Artboard%201%20%282%29.jpg&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Recursion tree for quicksort.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Recursion tree for quicksort.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The subtree for the \(\frac{1}{10}\) split eventually bottoms out after being called \(\log_{10} n\) times. Until this happens, the cost of each level of the tree is \(n\). After the left-tree bottoms out, the right tree continues with an upper bound of \(\leq n\). The right tree completes after \(\log_{10/9} n = \Theta(\lg n)\) levels. Since each level of the tree cost no more than \(n\), the total cost is \(\Theta(n \lg n)\).&lt;/p&gt;
&lt;h3 id=&#34;best-case&#34;&gt;Best Case&lt;/h3&gt;
&lt;p&gt;In the best-case, the pivot is the median of the array and two balanced subarrays are created: one of size \(n/2\) and another of size \(\lfloor (n-1)/2 \rfloor\). The recurrence is \(T(n) = 2T(n/2) + \Theta(n)\), which is \(\Theta(n \log n)\).&lt;/p&gt;
&lt;p&gt;Using the substitution method, we can show the best-case running time. We start with the fact that the partitioning produces two subproblems with a total size of \(n-1\). This gives the following recurrence:&lt;/p&gt;
&lt;p&gt;\[
T(n) = \min_{0 \leq q \leq n-1} \{T(q) + T(n - q - 1)\} + \Theta(n).
\]&lt;/p&gt;
&lt;p&gt;The minimum function accounts for the minimum time taken to sort any partition of the array, where \(q\) represents the pivot element&amp;rsquo;s position.&lt;/p&gt;
&lt;p&gt;Our &lt;strong&gt;hypothesis&lt;/strong&gt; will be that&lt;/p&gt;
&lt;p&gt;\[
T(n) \geq cn \lg n = \Omega(n \lg n).
\]&lt;/p&gt;
&lt;p&gt;Plugging in our hypothesis, we get&lt;/p&gt;
&lt;p&gt;\begin{align*}
T(n) &amp;amp;\geq \min_{0 \leq q \leq n-1} \{cq \lg q + c(n - q - 1) \lg (n - q - 1)\} + \Theta(n) \\
&amp;amp; c \min_{0 \leq q \leq n-1} \{q \lg q + (n - q - 1) \lg (n - q - 1)\} + \Theta(n).
\end{align*}&lt;/p&gt;
&lt;p&gt;If we take the derivative of the function inside the minimum with respect to \(q\), we get&lt;/p&gt;
&lt;p&gt;\[
\frac{d}{dq} \{q \lg q + (n - q - 1) \lg (n - q - 1)\} = c\{\frac{q}{q} + \lg q - \lg (n - q - 1) - \frac{(n - q - 1)}{(n - q - 1)}\}.
\]&lt;/p&gt;
&lt;p&gt;Setting this equal to zero and solving for \(q\) yields&lt;/p&gt;
&lt;p&gt;\[
q = \frac{n - 1}{2}.
\]&lt;/p&gt;
&lt;p&gt;We can then plug this value of \(q\) into the original function to get&lt;/p&gt;
&lt;p&gt;\begin{align*}
T(n) &amp;amp;\geq c \frac{n - 1}{2} \lg \frac{n - 1}{2} + c \frac{n - 1}{2} \lg \frac{n - 1}{2} + \Theta(n) \\
&amp;amp;= cn \lg (n - 1) + c (n - 1) + \Theta(n) \\
&amp;amp;= cn \lg (n - 1) + \Theta(n) \\
&amp;amp;\geq cn \lg n \\
&amp;amp;= \Omega(n \lg n).
\end{align*}&lt;/p&gt;
&lt;h3 id=&#34;average-case&#34;&gt;Average Case&lt;/h3&gt;
&lt;p&gt;As it turns out, the average-case running time is \(\Theta(n \log n)\) (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;). Quicksort is highly dependent on the relative ordering of the input. Consider the case of a randomly ordered array. The cost of partitioning the original input is \(O(n)\). Let&amp;rsquo;s say that the pivot was the last element, yielding a split of 0 and \(n - 1\). Now, let&amp;rsquo;s say we get lucky on the next iteration and get a balanced split. Even if the rest of the algorithm splits between the median and the last element, the upper bound on the running time is \(\Theta(n \log n)\). It is highly unlikely that the split will be unbalanced on every iteration given a random initial ordering.&lt;/p&gt;
&lt;p&gt;We can make this a tad more formal by defining a lucky \(L(n) = 2U(n/2) + \Theta(n)\) and an unlucky split \(U(n) = L(n-1) + \Theta(n)\). We can solve for \(L(n)\) by plugging in the definition of \(U(n)\).&lt;/p&gt;
&lt;p&gt;\begin{align*}
L(n) &amp;amp;= 2U(n/2) + \Theta(n) \\
&amp;amp;= 2(L(n/2 - 1) + \Theta(n/2)) + \Theta(n) \\
&amp;amp;= 2L(n/2 - 1) + \Theta(n) \\
&amp;amp;= \Theta(n \log n)
\end{align*}&lt;/p&gt;
&lt;h2 id=&#34;randomized-quicksort&#34;&gt;Randomized Quicksort&lt;/h2&gt;
&lt;p&gt;The intuition of the crude analysis above is that we would have to be extremely unlucky to get a quadratic running time if the input is randomly ordered. Randomized quicksort builds on this intuition by selection a random pivot on each iteration. This is done by swapping the pivot with a random element before partitioning.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randomized_partition&lt;/span&gt;(arr, p, r):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(p, r)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    arr[i], arr[r] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; arr[r], arr[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; partition(arr, p, r)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randomized_quicksort&lt;/span&gt;(arr, p, r):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; p &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; r:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        q &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; randomized_partition(arr, p, r)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        randomized_quicksort(arr, p, q &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        randomized_quicksort(arr, q &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, r)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;The lightweight analysis above reasoned that, as long as each split puts a constant amount of elements to one side of the split, then the running time is \(\Theta(n \log n)\).&lt;/p&gt;
&lt;p&gt;We can understand this analysis simply by asking the right questions. First, our primary question: &lt;strong&gt;What is the running time of Quicksort dependent on?&lt;/strong&gt; The biggest bottleneck is the partitioning function. At most, we get really unlucky and the first pivot is picked every time. This means it is called \(n\) times yielding \(O(n)\). The variable part of this is figuring out how many element comparisons are made. The running time is then \(O(n + X)\).&lt;/p&gt;
&lt;h4 id=&#34;the-expected-value-of-x&#34;&gt;The Expected Value of \(X\)&lt;/h4&gt;
&lt;p&gt;The number of comparisons can be expressed as&lt;/p&gt;
&lt;p&gt;\[
X = \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} X_{ij},
\]&lt;/p&gt;
&lt;p&gt;where \(X_{ij}\) is the indicator random variable that is 1 if \(A[i]\) and \(A[j]\) are compared and 0 otherwise. This works with our worst case analysis. If we always get a split of 0 and \(n - 1\), then the indicator random variable is 1 for every comparison, yielding \(O(n^2)\). Taking the expectation of both sides:&lt;/p&gt;
&lt;p&gt;\begin{align*}
E[X] &amp;amp;= E\left[\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} X_{ij}\right] \\
&amp;amp;= \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} E[X_{ij}] \\
&amp;amp;= \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} P(X_{ij} = 1).
\end{align*}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is P(X&lt;sub&gt;ij&lt;/sub&gt; = 1)?&lt;/strong&gt; Let \(z_i, \dots, z_j\) be the indices of elements in a sorted version of the array. Under this assumption, \(z_i\) is compared to \(z_j\) only if \(z_i\) or \(z_j\) is the first pivot chosen from the subarray \(A[i \dots j]\). In a set of distinct elements, the probability of picking any pivot from the array from \(i\) to \(j\) is \(\frac{1}{j - i + 1}\). This means that the probability of comparing \(z_i\) and \(z_j\) is \(\frac{2}{j - i + 1}\). We can now finish the calculation.&lt;/p&gt;
&lt;p&gt;\begin{align*}
E[X] &amp;amp;= \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} \frac{2}{j - i + 1} \\
&amp;amp;= \sum_{i=1}^{n-1} \sum_{k=1}^{n-i} \frac{2}{k + 1} \\
&amp;amp;&amp;lt; \sum_{i=1}^{n-1} \sum_{k=1}^{n-i} \frac{2}{k} \\
&amp;amp;= \sum_{i=1}^{n-1} O(\log n) \\
&amp;amp;= O(n \log n).
\end{align*}&lt;/p&gt;
&lt;h2 id=&#34;paranoid-quicksort&#34;&gt;Paranoid Quicksort&lt;/h2&gt;
&lt;p&gt;Repeat the following until the partitioning until the left or right subarray is less than or equal to \(\frac{3}{4}\) of the original array.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Choose a random pivot.&lt;/li&gt;
&lt;li&gt;Partition the array.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Cormen, Thomas H., Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 2022. &lt;i&gt;Introduction to Algorithms&lt;/i&gt;. 4th ed. MIT Press. &lt;a href=&#34;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&#34;&gt;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Priority Queues</title>
      <link>https://ajdillhoff.github.io/notes/priority_queues/</link>
      <pubDate>Sat, 24 Feb 2024 14:10:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/priority_queues/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#quick-facts&#34;&gt;Quick Facts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#implementation&#34;&gt;Implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exercises&#34;&gt;Exercises&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;quick-facts&#34;&gt;Quick Facts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Time Complexity&lt;/strong&gt;&lt;/strong&gt;: \(O(\lg n)\)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Space Complexity&lt;/strong&gt;&lt;/strong&gt;: \(O(n)\)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Besides being the primary data structure for &lt;a href=&#34;https://ajdillhoff.github.io/notes/heapsort/&#34;&gt;Heapsort&lt;/a&gt;, a heap is also used to implement a priority queue. A priority queue is a key-value data structure in which the keys are used to determine the priority of each element in the queue. There are two variants, maximum and minimum, and they support the following operations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Insert: Add a new element to the queue.&lt;/li&gt;
&lt;li&gt;Extract: Remove the element with the maximum/minimum key.&lt;/li&gt;
&lt;li&gt;Maximum/Minimum: Return the element with the maximum/minimum key without removing it.&lt;/li&gt;
&lt;li&gt;Increase/Decrease Key: Increase or decrease the key of a given element.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You could probably imagine a few use cases for such a queue. For example, a priority queue could be used to schedule tasks in a multitasking operating system. The tasks with the highest priority would be executed first. Another example would be a network router that uses a priority queue to schedule packets for transmission. The packets with the highest priority would be transmitted first. In high performance computing, a priority queue could be used to schedule jobs on a supercomputer. The jobs with the highest priority would be executed first. SLURM is an example of a job scheduler that uses a priority queue.&lt;/p&gt;
&lt;p&gt;For simple applications, you could reference your application object directly inside the heap. If the objects themselves are too complex, it is optimal to simply set the &lt;em&gt;value&lt;/em&gt; of the heap as a reference to the object. A &lt;strong&gt;handle&lt;/strong&gt; is a reference that is added to both the heap and the object; it requires little overhead. This requires that your priority queue update both its own index as well as the object&amp;rsquo;s index as changes are made.&lt;/p&gt;
&lt;p&gt;An alternative approach is to establish the map using a hash table. In this case, the priority queue is the only data structure that needs to be updated.&lt;/p&gt;
&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;
&lt;p&gt;Let us now consider the implementation and analysis of the require operations for a priority queue.&lt;/p&gt;
&lt;h3 id=&#34;extract&#34;&gt;Extract&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;keys&lt;/em&gt; in a priority queue represent the priority. The &lt;em&gt;values&lt;/em&gt; will need to be moved around with them as the priority queue is constructed. Getting the maximum or minimum value is a constant time operation and is executed by returning the first element in the array. To extract the item with the highest priority, the first element is removed and the heap is then heapified.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max_heap_maximum&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(A) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ValueError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Heap underflow&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; A[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max_heap_extract_max&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max_heap_maximum(A)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    A[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    A&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_heapify(A, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; max_val
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As we saw with &lt;a href=&#34;https://ajdillhoff.github.io/notes/heapsort/&#34;&gt;Heapsort&lt;/a&gt;, &lt;code&gt;max_heapify&lt;/code&gt; runs in \(O(\lg n)\) time. The call to &lt;code&gt;max_heap_extract_max&lt;/code&gt; only adds a few constant operations on top of that, so it runs in \(O(\lg n)\) time as well.&lt;/p&gt;
&lt;h3 id=&#34;increase&#34;&gt;Increase&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;max_heap_increase_key&lt;/code&gt; function is used to increase the key of a given element. The function first checks if the new key is less than the current key. If it is, an error is raised. The function then updates the key and then traverses up the heap to ensure that the heap property is maintained.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max_heap_increase_key&lt;/span&gt;(A, obj, key):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; key &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; obj&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ValueError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;New key is smaller than current key&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    obj&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index(obj) &lt;span style=&#34;color:#75715e&#34;&gt;# gets the index of the object&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; A[parent(i)]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; A[i]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[i], A[parent(i)] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[parent(i)], A[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; parent(i)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Moving through the height of the tree is done in \(O(\lg n)\) time. Depending on the how the index of the object is found, the complexity could be higher. In most cases, the index is found in constant time.&lt;/p&gt;
&lt;h3 id=&#34;insert&#34;&gt;Insert&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;max_heap_insert&lt;/code&gt; function is used to insert a new element into the heap. The function first appends the new element to the end of the array. It then sets the key of the new element to a very small value and then calls &lt;code&gt;max_heap_increase_key&lt;/code&gt; to update the key to the correct value.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max_heap_insert&lt;/span&gt;(A, obj, n):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(A) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; n:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ValueError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Heap overflow&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; float(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;-inf&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    obj&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    A&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(obj)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# map obj to the last index -- dependent on the implementation&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_heap_increase_key(A, obj, key)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The call to &lt;code&gt;max_heap_increase_key&lt;/code&gt; runs in \(O(\lg n)\) time, so the &lt;code&gt;max_heap_insert&lt;/code&gt; function also runs in \(O(\lg n)\) time in addition to the time it takes to map the object to its index.&lt;/p&gt;
&lt;h2 id=&#34;exercises&#34;&gt;Exercises&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Implement a minimum priority queue.&lt;/li&gt;
&lt;li&gt;Implement a decrease key function for a maximum priority queue.&lt;/li&gt;
&lt;li&gt;Simulate a job scheduler using a priority queue that considers the priority of the job and the time it was submitted.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Master Theorem</title>
      <link>https://ajdillhoff.github.io/notes/master_theorem/</link>
      <pubDate>Sun, 04 Feb 2024 17:49:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/master_theorem/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#example-merge-sort&#34;&gt;Example: Merge Sort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-matrix-multiplication&#34;&gt;Example: Matrix Multiplication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-median-finding&#34;&gt;Example: Median Finding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-cormen-et-al-dot-exercise-4-dot-5-2&#34;&gt;Example: Cormen et al. Exercise 4.5-2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;In the study of &lt;a href=&#34;https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/&#34;&gt;Divide and Conquer Algorithms&lt;/a&gt;, a recurrence tree can be used to determine the runtime complexity. These notes focus on the &lt;strong&gt;master theorem&lt;/strong&gt;, a blueprint for solving any recurrence of the form&lt;/p&gt;
&lt;p&gt;\[
T(n) = aT(n/b) + f(n).
\]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\(n\) is the size of the problem,&lt;/li&gt;
&lt;li&gt;\(a \geq 1\) is the number of subproblems,&lt;/li&gt;
&lt;li&gt;\(b &amp;gt; 1\) is the factor by which the problem size is reduced, and&lt;/li&gt;
&lt;li&gt;\(f(n)\) is the cost of the work done outside of the recursive calls.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each recurrence is solved in \(T(n/b)\) time, and \(f(n)\) would include the cost of dividing and recombining the problem. The full theorem as described in &lt;em&gt;Introduction to Algorithms&lt;/em&gt; is restated below (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Master Theorem&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let \(a &amp;gt; 0\) and \(b &amp;gt; 1\) be constants, and let \(f(n)\) be a driving function that is defined and nonnegative on all sufficiently large reals. Define the recurrence \(T(n)\) on \(n \in \mathbb{N}\) by&lt;/p&gt;
&lt;p&gt;\[
T(n) = aT(n/b) + f(n),
\]&lt;/p&gt;
&lt;p&gt;where \(aT(n/b)\) actually means \(a&amp;rsquo;T(\lfloor n/b \rfloor) + a{&amp;rsquo;&amp;rsquo;}T(\lceil n / b \rceil)\) for some constants \(a&amp;rsquo; \geq 0\) and \(a&amp;rsquo;&amp;rsquo; \geq 0\) such that \(a = a&amp;rsquo; + a&amp;rsquo;&amp;rsquo;\). Then \(T(n)\) has the following asymptotic bounds:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If \(f(n) = O(n^{\log_b a - \epsilon})\) for some constant \(\epsilon &amp;gt; 0\), then \(T(n) = \Theta(n^{\log_b a})\).&lt;/li&gt;
&lt;li&gt;If \(f(n) = \Theta(n^{\log_b a} \log^k n)\) for some constant \(k \geq 0\), then \(T(n) = \Theta(n^{\log_b a} \log^{k+1} n)\).&lt;/li&gt;
&lt;li&gt;If \(f(n) = \Omega(n^{\log_b a + \epsilon})\) for some constant \(\epsilon &amp;gt; 0\), and if \(a f(n/b) \leq k f(n)\) for some constant \(k &amp;lt; 1\) and all sufficiently large \(n\), then \(T(n) = \Theta(f(n))\).&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;theorem-breakdown&#34;&gt;Theorem Breakdown&lt;/h3&gt;
&lt;p&gt;The common function \(n^{\log_b a}\) is called the &lt;strong&gt;watershed function&lt;/strong&gt;. The driving function \(f(n)\) is compared to it to determine which case applies. If the watershed function grows at a faster rate than \(f(n)\), case 1 applies. If they grow at the same rate, case 2 applies. If \(f(n)\) grows at a faster rate, case 3 applies.&lt;/p&gt;
&lt;p&gt;In case 1, the watershed function should grow faster than \(f(n)\) by a factor of \(n^\epsilon\) for some \(\epsilon &amp;gt; 0\). In case 2, technically the watershed function should grow at least the same rate as \(f(n)\), if not faster. That is, it grows faster by a factor of \(\Theta(\log^k n)\), where \(k \geq 0\). You can think of the extra \(\log^k n\) as an augmentation to the watershed function to ensure that they grow at the same rate. In most cases, \(k = 0\) which results in \(T(n) = \Theta(n^{\log_b a} \log n)\).&lt;/p&gt;
&lt;p&gt;Since case 2 allows for the watershed function to grow faster than \(f(n)\), case 3 requires that it grow at least &lt;strong&gt;polynomially&lt;/strong&gt; faster. \(f(n)\) should grow faster by at least a factor of \(\Theta(n^\epsilon)\) for some \(\epsilon &amp;gt; 0\). Additionally, the driving function must satisfy the regularity condition \(a f(n/b) \leq k f(n)\) for some constant \(k &amp;lt; 1\) and all sufficiently large \(n\). This condition ensures that the cost of the work done outside of the recursive calls is not too large.&lt;/p&gt;
&lt;h3 id=&#34;application-of-the-master-method&#34;&gt;Application of the Master Method&lt;/h3&gt;
&lt;p&gt;In most cases, the master method can be applied by looking at the recurrence and applying the relevant case. If the driving and watershed functions are not immediately obvious, you can use a different method as discussed in &lt;a href=&#34;https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/&#34;&gt;Divide and Conquer Algorithms&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When this can be applied, it is much simpler than the other methods. Let&amp;rsquo;s revisit some of the main problems we&amp;rsquo;ve explored before discussing applications for which the master method could not be used.&lt;/p&gt;
&lt;h2 id=&#34;example-merge-sort&#34;&gt;Example: Merge Sort&lt;/h2&gt;
&lt;p&gt;Merge Sort has a recurrence of the form \(T(n) = 2T(n/2) + \Theta(n)\). The driving function is \(f(n) = \Theta(n)\). The constants \(a\) and \(b\) are both 2, so the watershed function is \(n^{\log^2 2}\), which is \(n\). Since \(f(n)\) grows at the same rate as the watershed function, case 2 applies. Therefore, \(T(n) = \Theta(n \log n)\).&lt;/p&gt;
&lt;h2 id=&#34;example-matrix-multiplication&#34;&gt;Example: Matrix Multiplication&lt;/h2&gt;
&lt;p&gt;The recurrence of the divide and conquer version of matrix multiplication for square matrices is \(T(n) = 8T(n/2) + \Theta(1)\). Given \(a = 8\) and \(b = 2\), we can see that the complexity is inherent in the recurrence, not the driving function. The watershed function is \(n^{\log_2 8}\), which is \(n^3\). This grows at a faster rate than \(\Theta(1)\), so case 1 applies. Therefore, \(T(n) = \Theta(n^3)\).&lt;/p&gt;
&lt;h2 id=&#34;example-median-finding&#34;&gt;Example: Median Finding&lt;/h2&gt;
&lt;p&gt;Median finding has a recurrence of the form \(T(n) = T(n/5) + T(7n/10) + \Theta(n)\). Given the two recurrence factors, how do we evaluate the driving function? The form itself does not fit the master theorem, so it cannot be applied in this case. We could use the substitution method, recurrence trees, or the Akra-Bazzi theorem to solve this one.&lt;/p&gt;
&lt;h2 id=&#34;example-cormen-et-al-dot-exercise-4-dot-5-2&#34;&gt;Example: Cormen et al. Exercise 4.5-2&lt;/h2&gt;
&lt;p&gt;In this exercise from &lt;em&gt;Introduction to Algorithms&lt;/em&gt;, we are asked to find the largest integer value \(a\) such that an algorithm with the recurrence \(T(n) = aT(n/4) + \Theta(n^2)\) is asymptotically faster than \(\Theta(n^{\log_2 7})\). Since \(b = 4\), the largest integer \(a\) will be the smallest integer such that \(\log_4 a &amp;lt; \log_2 7\). Solving for the inequality shows that \(a = 48\) is the largest such integer.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Cormen, Thomas H., Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 2022. &lt;i&gt;Introduction to Algorithms&lt;/i&gt;. 4th ed. MIT Press. &lt;a href=&#34;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&#34;&gt;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Divide and Conquer Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/</link>
      <pubDate>Tue, 23 Jan 2024 08:38:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#definition&#34;&gt;Definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#solving-recurrences&#34;&gt;Solving Recurrences&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-merge-sort&#34;&gt;Example: Merge Sort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-multiplying-square-matrices&#34;&gt;Example: Multiplying Square Matrices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-convex-hull&#34;&gt;Example: Convex Hull&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-median-search&#34;&gt;Example: Median Search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;
&lt;p&gt;Divide and conquer algorithms are a class of algorithms that solve a problem by breaking it into smaller subproblems, solving the subproblems recursively, and then combining the solutions to the subproblems to form a solution to the original problem. Problems that can be solved in this manner are typically highly parallelizable. These notes investigate a few examples of classic divide and conquer algorithms and their analysis.&lt;/p&gt;
&lt;p&gt;A divide and conquer method is split into three steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Divide the problem into smaller subproblems.&lt;/li&gt;
&lt;li&gt;Conquer the subproblems by solving them recursively.&lt;/li&gt;
&lt;li&gt;Combine the solutions to the subproblems to form a solution to the original problem.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Their runtime can be characterized by the recurrence relation \(T(n)\). A recurrence \(T(n)\) is &lt;em&gt;algorithmic&lt;/em&gt; if, for every sufficiently large &lt;em&gt;threshold&lt;/em&gt; constant \(n_0 &amp;gt; 0\), the following two properties hold:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For all \(n \leq n_0\), the recurrence defines the running time of a constant-size input.&lt;/li&gt;
&lt;li&gt;For all \(n \geq n_0\), every path of recursion terminates in a defined base case within a finite number of recursive calls.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The algorithm must output a solution in finite time.
If the second property doesn&amp;rsquo;t hold, the algorithm is not correct &amp;ndash; it may end up in an infinite loop.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Whenever a recurrence is stated without an explicit base case, we assume that the recurrence is algorithmic.&amp;rdquo; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This assumption means that the algorithm is correct and terminates in finite time, so there must be a base case. The base case is less important for analysis than the recursive case. For example, your base case might work with 100 elements, and that would still be \(\Theta(1)\) because it is a constant.&lt;/p&gt;
&lt;p&gt;It is common to break up each subproblem uniformly, but it is not always the best way to do it. For example, an application such as matrix multiplication is typically broken up uniformly since there is no spatial or temporal relationship to consider. Algorithms for image processing, on the other hand, may have input values that are locally correlated, so it may be better to break up the input in a way that preserves this correlation.&lt;/p&gt;
&lt;h2 id=&#34;solving-recurrences&#34;&gt;Solving Recurrences&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Substitution method&lt;/li&gt;
&lt;li&gt;Recursion-tree method&lt;/li&gt;
&lt;li&gt;Master method&lt;/li&gt;
&lt;li&gt;Akra-Bazzi method&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;example-merge-sort&#34;&gt;Example: Merge Sort&lt;/h2&gt;
&lt;p&gt;Merge sort is a classic example of a divide and conquer algorithm. It works by dividing the input array into two halves, sorting each half recursively, and then merging the two sorted halves.&lt;/p&gt;
&lt;h3 id=&#34;divide&#34;&gt;Divide&lt;/h3&gt;
&lt;p&gt;The divide step takes an input subarray \(A[p:r]\) and computes a midpoint \(q\) before partitioning it into two subarrays \(A[p:q]\) and \(A[q+1:r]\). These subarrays will be sorted recursively until the base case is reached.&lt;/p&gt;
&lt;h3 id=&#34;conquer&#34;&gt;Conquer&lt;/h3&gt;
&lt;p&gt;The conquer step recursively sorts the two subarrays \(A[p:q]\) and \(A[q+1:r]\). If the base case is such that the input array has only one element, the array is already sorted.&lt;/p&gt;
&lt;h3 id=&#34;combine&#34;&gt;Combine&lt;/h3&gt;
&lt;p&gt;The combine step merges the two sorted subarrays to produce the final sorted array.&lt;/p&gt;
&lt;h3 id=&#34;python-implementation&#34;&gt;Python Implementation&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;merge_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(A) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Conquer -- base case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; A
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Divide Step&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(A) &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; merge_sort(A[:mid])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; merge_sort(A[mid:])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Combine Step&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; merge(left, right)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;merge&lt;/span&gt;(left, right):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    i, j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Merge the two subarrays&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; len(left)) &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; (j &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; len(right)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; left[i] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; right[j]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(left[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            i &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(right[j])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            j &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Add the remaining elements to the final array&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    result &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; left[i:]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    result &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; right[j:]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; result
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This function assumes that the subarrays &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt; are already sorted. If the value in the left subarray is less than the value in the right subarray, the left value is added to the final array. Otherwise, the right value is added. As soon as one of the subarrays is exhausted, the remaining elements in the other subarray are added to the final array. This is done with slicing in Python.&lt;/p&gt;
&lt;p&gt;The divide step simply splits the data into &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt; subarrays. The conquer step simplifies the sorting process by reducing it down to the base case &amp;ndash; a single element. Finally, the combine step merges or &lt;em&gt;folds&lt;/em&gt; the two sorted subarrays together.&lt;/p&gt;
&lt;p&gt;Example code can be found &lt;a href=&#34;https://github.com/ajdillhoff/python-examples/blob/main/sorting/merge_sort.py&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;When analyzing the running time of a divide and conquer algorithm, it is safe to assume that the base case runs in constant time. The focus of the analysis should be on the &lt;strong&gt;recurrence equation&lt;/strong&gt;. For merge sort, we originally have a problem of size \(n\). We then divide the problem into 2 subproblems of size \(n/2\). Therefore the recurrence is \(T(n) = 2T(n/2)\). These recurrence continues for as long as the base case is not reached.&lt;/p&gt;
&lt;p&gt;Of course we also have to factor in the time it takes for the divide and combine steps. These can be represented as \(D(n)\) and \(C(n)\), respectively. The total running time of the algorithm is then \(T(n) = 2T(n/2) + D(n) + C(n)\) when \(n &amp;gt;= n_0\), where \(n_0\) is the base case.&lt;/p&gt;
&lt;p&gt;For merge sort specifically, the base case is \(D(n) = \Theta(1)\) since all it does is compute the midpoint. As we saw above, the conquer step is the recurrent \(T(n) = 2T(n/2)\). The combine step is \(C(n) = \Theta(n)\) since it takes linear time to merge the two subarrays. Thus, the worst-case running time of merge sort is \(T(n) = 2T(n/2) + \Theta(n)\).&lt;/p&gt;
&lt;p&gt;Not every problem will have a recurrence of \(2T(n/2)\). We can generalize this to \(aT(n/b)\), where \(a\) is the number of subproblems and \(b\) is the size of the subproblems.&lt;/p&gt;
&lt;p&gt;We haven&amp;rsquo;t finished the analysis yet since it is still not clear what the asymptotic upper bound is. &lt;strong&gt;Recurrence trees&lt;/strong&gt; can be used to visualize the running time of a divide and conquer algorithms. After inspecting the result of the tree, we will be able to easily determine the complexity of merge sort in terms of big-O notation.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-02-04_15-09-47_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Expansion of recursion tree for merge sort (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Cormen et al. 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Expansion of recursion tree for merge sort (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;In the figure above from &lt;em&gt;Introduction to Algorithms&lt;/em&gt;, the root of the tree represents the original problem of size \(n\) in (a). In (b), the divide step splits the problem into two problems of size \(n/2\). The cost of this step is indicated by \(c_2n\). Here, \(c_2\) represents the constant cost per element for dividing and combining. As mentioned above, the combine step is dependent on the size of the subproblems, so the cost is \(c_2n\). Subfigure (c) shows a third split, where each new subproblem has size \(n/4\). This would continue recursively until the base case is reached, as shown in the figure below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-02-04_15-14-25_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Full recursion tree for merge sort (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Cormen et al. 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Full recursion tree for merge sort (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The upper bound for each level of the tree is \(c_2n\). The height of a binary tree is \(\log_b n\). The total cost of the tree is the sum of the costs at each level. In this case, the cost is \(c_2n \log n + c_1n\), where the last \(c1_n\) comes from the base case. The first term is the dominating factor in the running time, so the running time of merge sort is \(\Theta(n \log n)\).&lt;/p&gt;
&lt;h3 id=&#34;questions&#34;&gt;Questions&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Assume that the base case is \(n &amp;gt; 1\). What is the running time of the conquer step dependent on?&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;example-multiplying-square-matrices&#34;&gt;Example: Multiplying Square Matrices&lt;/h2&gt;
&lt;p&gt;Matrix multiplication is defined as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;square_matrix_multiply&lt;/span&gt;(A, B):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(A)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    C &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n)] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n)]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                C[i][j] &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; A[i][k] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B[k][j]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; C
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Initializing values takes \(\Theta(n^2)\). The full process takes \(\Theta(n^3)\).&lt;/p&gt;
&lt;h3 id=&#34;divide-and-conquer&#34;&gt;Divide and Conquer&lt;/h3&gt;
&lt;p&gt;In this approach, the matrix will be split into block matrices of size \(n/2\). Each submatrix can be multiplied with the corresponding submatrix of the other matrix. The resulting submatrices can be added together to form the final matrix. This is permissible based on the definition of matrix multiplication.&lt;/p&gt;
&lt;p&gt;Base case is \(n=1\) where only a single addition and multiplication are performed. This is \(T(1) = \Theta(1)\). For \(n &amp;gt; 1\), the recursive algorithm starts by splitting into 8 subproblems of size \(n/2\). There are 8 subproblems because there are 4 submatrices in each matrix, and each submatrix is multiplied with the corresponding submatrix in the other matrix.&lt;/p&gt;
&lt;p&gt;Each recursive call contributes \(T(n/2)\) to the running time. There are 8 recursive calls, so the total running time is \(8T(n/2) + \Theta(n^2)\). There is no need to implement a combine step since the matrix is updated in place. The final running time is \(T(n) = 8T(n/2) + \Theta(1)\) &lt;strong&gt;for the recursive portion&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This method easily adapts to parallel processing. The size of each &lt;em&gt;tile&lt;/em&gt; can be adjusted to fit the number of processors available. The algorithm can be parallelized by assigning each processor to a subproblem.&lt;/p&gt;
&lt;p&gt;We now walk through an example on a \(4 \times 4\) matrix. Assume that each \(A_{ij}\) and \(B_{ij}\) is a \(2 \times 2\) matrix.&lt;/p&gt;
&lt;p&gt;\begin{bmatrix}
A_{11} &amp;amp; A_{12} \\
A_{21} &amp;amp; A_{22}
\end{bmatrix}&lt;/p&gt;
&lt;p&gt;\begin{bmatrix}
B_{11} &amp;amp; B_{12} \\
B_{21} &amp;amp; B_{22}
\end{bmatrix}&lt;/p&gt;
&lt;p&gt;These matrices are already partitioned. They currently don&amp;rsquo;t meet the base case, so 8 recursive calls are made which compute the following products:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;\(A_{11}B_{11}\)&lt;/li&gt;
&lt;li&gt;\(A_{12}B_{21}\)&lt;/li&gt;
&lt;li&gt;\(A_{11}B_{12}\)&lt;/li&gt;
&lt;li&gt;\(A_{12}B_{22}\)&lt;/li&gt;
&lt;li&gt;\(A_{21}B_{11}\)&lt;/li&gt;
&lt;li&gt;\(A_{22}B_{21}\)&lt;/li&gt;
&lt;li&gt;\(A_{21}B_{12}\)&lt;/li&gt;
&lt;li&gt;\(A_{22}B_{22}\)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Peeking into the first recursive call, the \(2 \times 2\) matrices are partitioned into 4 \(1 \times 1\) matrices, or scalars. The base case is reached, and the product is computed. The same process is repeated for the other 7 recursive calls. The final matrix is then formed by adding the products together.&lt;/p&gt;
&lt;h2 id=&#34;example-convex-hull&#34;&gt;Example: Convex Hull&lt;/h2&gt;
&lt;p&gt;Given \(n\) points in plane, the convex hull is the smallest convex polygon that contains all the points.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No two points have the same \(x\) or \(y\) coordinate.&lt;/li&gt;
&lt;li&gt;Sequence of points on boundary in clockwise order as doubly linked list.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;naive-solution&#34;&gt;Naive Solution&lt;/h3&gt;
&lt;p&gt;Draw lines between each pair of points. If all other points are on the same side of the line, the line is part of the convex hull. This is \(\Theta(n^3)\).&lt;/p&gt;
&lt;h3 id=&#34;divide-and-conquer&#34;&gt;Divide and Conquer&lt;/h3&gt;
&lt;p&gt;Sort the points by \(x\) coordinate. Split into two halves by \(x\). Recursively find the convex hull of each half. Merge the two convex hulls.&lt;/p&gt;
&lt;h4 id=&#34;merging&#34;&gt;Merging&lt;/h4&gt;
&lt;p&gt;Find upper tangent and lower tangent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why not just select the highest point from each half?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The highest point in each half may not be part of the convex hull. The question assumes that the two convex hulls are relatively close to each other.&lt;/p&gt;
&lt;h4 id=&#34;two-finger-algorithm&#34;&gt;Two Finger Algorithm&lt;/h4&gt;
&lt;p&gt;Start at the rightmost point of the left convex hull and the leftmost point of the right convex hull. Move the right finger clockwise and the left finger counterclockwise until the tangent is found. The pseudocode is as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;merge_convex_hulls&lt;/span&gt;(left, right):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Find the rightmost point of the left convex hull&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    left_max &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max(left, key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; p: p[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Find the leftmost point of the right convex hull&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    right_min &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(right, key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; p: p[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Find the upper tangent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Move the right finger clockwise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        right_max &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max(right, key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; p: p[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; is_upper_tangent(left_max, right_max):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Move the left finger counterclockwise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        left_max &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max(left, key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; p: p[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Find the lower tangent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Move the right finger clockwise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        right_min &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(right, key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; p: p[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; is_lower_tangent(left_min, right_min):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Move the left finger counterclockwise&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        left_min &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(left, key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; p: p[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This runs in \(\Theta(n)\) time.&lt;/p&gt;
&lt;p&gt;Removing the lines that are not part of the convex hull require the cut and paste operations. Starting at the upper tangent, move clockwise along the right convex hull until you reach the point in the lower tangent of the right convex hull. Make the connection to the corresponding point on the left convex hull based on the lower tangent, then move clockwise until you reach the upper tangent of the left convex hull. This is \(\Theta(n)\).&lt;/p&gt;
&lt;h2 id=&#34;example-median-search&#34;&gt;Example: Median Search&lt;/h2&gt;
&lt;p&gt;Finding the median value of a set can be performed in linear time without fully sorting the data. The recurrence is based on discarding a constant fraction of the elements at each step.&lt;/p&gt;
&lt;h3 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Divide&lt;/strong&gt;&lt;/strong&gt;: Partition the set into groups of 5 elements. Depending on the size of the set, there may be less than 5 elements in the last set.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Conquer&lt;/strong&gt;&lt;/strong&gt;: Sort each group and find the median of each group. Since the subsets are of constant size, this is done in constant time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Combine&lt;/strong&gt;&lt;/strong&gt;: Given the median of each group from step 2, find the median of medians. This value will be used as a pivot for the next step.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Partition&lt;/strong&gt;&lt;/strong&gt;: Use the pivot to separate values smaller and larger than the pivot.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Select&lt;/strong&gt;&lt;/strong&gt;: If the given pivot is the true median based on its position in the original set, select it. If not, recursively select the median from the appropriate partition.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Given a set of \(n\) numbers, define \(rank(X)\) as the number in the set that are less than or equal to \(X\).&lt;/p&gt;
&lt;p&gt;\(Select(S, i)\)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pick \(x \in S\)&lt;/li&gt;
&lt;li&gt;Compute \(k = rank(x)\)&lt;/li&gt;
&lt;li&gt;B = {y in S | y &amp;lt; x}&lt;/li&gt;
&lt;li&gt;C = {y in S | y &amp;gt; x}&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If \(i = k\), return \(x\).
else if \(k &amp;gt; i\), return \(Select(B, i)\).
else return \(Select(C, i-k)\).&lt;/p&gt;
&lt;p&gt;How do we get balanced partitions?&lt;/p&gt;
&lt;p&gt;Arrange \(S\) into columns of size 5.
Sort each column descending (linear time).
Find &amp;ldquo;median of medians&amp;rdquo; as \(X\)&lt;/p&gt;
&lt;p&gt;If the columns are sorted, it is trivial to find the median of each column.&lt;/p&gt;
&lt;p&gt;Half of the groups contribute at least 3 elements greater than \(X\), except for the last group. We have one group that contains \(x\).&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;Given a set \(A = \{a_1, a_2, \ldots, a_n\}\), the median search algorithm returns the $k$th smallest element of \(A\). We now analyze the runtime of this algorithm.&lt;/p&gt;
&lt;h4 id=&#34;divide&#34;&gt;Divide&lt;/h4&gt;
&lt;p&gt;In the &lt;strong&gt;divide&lt;/strong&gt; step, the set is partitioned into \(\lceil n/5 \rceil\) groups of 5 elements each. This is done in linear time.&lt;/p&gt;
&lt;h4 id=&#34;conquer&#34;&gt;Conquer&lt;/h4&gt;
&lt;p&gt;Each group is sorted using insertion sort or some other algorithm. Even though the search itself may have a higher complexity, the sorting of the groups is \(\Theta(1)\) since the groups are of constant size. Collectively across all groups, the sorting is \(\Theta(n)\).&lt;/p&gt;
&lt;h4 id=&#34;combine&#34;&gt;Combine&lt;/h4&gt;
&lt;p&gt;The median of each group is found, introducing a recurrence of \(T(\lceil n/5 \rceil)\). Once each median is found, the median of medians is computed.&lt;/p&gt;
&lt;h4 id=&#34;partition&#34;&gt;Partition&lt;/h4&gt;
&lt;p&gt;As reasoned above, the median of medians is used as a pivot to partition the set into two groups. At least 30% of the elements are greater than the pivot. This leaves a search space of at most \(7n/10\). Partitioning is done in linear time.&lt;/p&gt;
&lt;h4 id=&#34;select&#34;&gt;Select&lt;/h4&gt;
&lt;p&gt;If the pivot is the $k$th smallest element, the algorithm terminates. Otherwise, the algorithm recursively searches the appropriate partition. Comparing the size of the partition to the size of the original set, the recurrence is \(T(7n/10)\).&lt;/p&gt;
&lt;p&gt;Pseudocode is available &lt;a href=&#34;https://en.wikipedia.org/wiki/Median_of_medians&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Cormen, Thomas H., Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 2022. &lt;i&gt;Introduction to Algorithms&lt;/i&gt;. 4th ed. MIT Press. &lt;a href=&#34;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&#34;&gt;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GPU Pattern: Stencils</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_stencils/</link>
      <pubDate>Mon, 22 Jan 2024 19:39:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_stencils/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#differential-equations&#34;&gt;Differential Equations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#stencils&#34;&gt;Stencils&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-basic-stencil&#34;&gt;Example: Basic Stencil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tiled-stencil&#34;&gt;Tiled Stencil&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#thread-coarsening&#34;&gt;Thread Coarsening&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#register-tiling&#34;&gt;Register Tiling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#questions&#34;&gt;Questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;ul&gt;
&lt;li&gt;Used in differential equations&lt;/li&gt;
&lt;li&gt;Frequently use higher precision&lt;/li&gt;
&lt;li&gt;Some similarity to convolutions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;differential-equations&#34;&gt;Differential Equations&lt;/h2&gt;
&lt;p&gt;Any computational problem requires discretization of data or equations so that they can be solved numerically. This is fundamental in numerical analysis, where differential equations need to be approximated.&lt;/p&gt;
&lt;p&gt;Structured grids are used in finite-difference methods for solving partial differential equations (PDEs). Approximate derivatives can be computed point-wise by considering the neighbors on the grid. As we saw earlier in this course, a grid representation is a natural way to think about data parallelism.&lt;/p&gt;
&lt;p&gt;Depending on the function and level of discretization, interpolation will be more or less accurate. Consider the logistic sigmoid function sampled at 4 points. In the middle, linear interpolation would work just fine. Near the &lt;em&gt;bends&lt;/em&gt; of the function, a linear approximation would introduce error. The closer the spacing, the more accurate a linear approximation becomes. The downside is that more memory is required to store the points.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-27_13-03-40_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Logistic sigmoid function (Wikipedia).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Logistic sigmoid function (Wikipedia).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The precision of the data type also plays an important role. Higher precision data types like &lt;code&gt;double&lt;/code&gt; require more bandwidth to transfer and will typically require more cycles when computing arithmetic operations.&lt;/p&gt;
&lt;h2 id=&#34;stencils&#34;&gt;Stencils&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;stencil&lt;/strong&gt; is a geometric pattern of weights applied at each point of a structured grid. The points on the grid will derive their values from neighboring points using some numerical approximation. For example, this is used to solve differential equations. Consider a 1D grid of discretized values from a function \(f(x)\). The finite difference approximation can be used to find \(f&amp;rsquo;(x)\):&lt;/p&gt;
&lt;p&gt;\[ f&amp;rsquo;(x) = \frac{f(x+h) - f(x-h)}{2h} + O(h^2) \]&lt;/p&gt;
&lt;p&gt;In code, this would look like:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void finite_difference(float *f, float *df, float h) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    df[i] = (f[i+1] - f[i-1]) / (2 * h);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A PDE of two variables can be solved using a 2D stencil. Likewise, a PDE of three variables can be solved using a 3D stencil. The figures below show examples of common 2D and 3D stencils. Note that they typically have an odd number of points so that there is a center point.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-27_15-23-57_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;1D stencils. Recreated from (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Hwu, Kirk, and El Hajj 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;1D stencils. Recreated from (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The 1D stencils shown above are used to approximate the first-order (A), second-order (B), and third-order (C) derivatives of a function \(f(x)\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-27_15-24-37_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;2D and 3D stencils. Recreated from (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Hwu, Kirk, and El Hajj 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;2D and 3D stencils. Recreated from (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The 2D stencils shown above are used to approximate first-order (A) and second-order (B) derivatives of a function \(f(x, )\). Likewise, the 3D stencils are used to approximate first-order (C) and second-order (D) derivatives of a function \(f(x, y, z)\).&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;stencil sweep&lt;/em&gt; is the process of applying the stencil to all points on the grid, similar to how a convolution is applied. There are many similarities between the two, but the subtle differences will require us to think differently about how to optimize them.&lt;/p&gt;
&lt;h2 id=&#34;example-basic-stencil&#34;&gt;Example: Basic Stencil&lt;/h2&gt;
&lt;p&gt;The code below presents a naive kernel for a stencil pattern using a 3D seven-point stencil.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void stencil_kernel(float *in, float *out, unsigned int N) {
    unsigned int i = blockIdx.z * blockDim.z + threadIdx.z;
    unsigned int j = blockIdx.y * blockDim.y + threadIdx.y;
    unsigned int k = blockIdx.x * blockDim.x + threadIdx.x;

    if (i &amp;gt;= 1 &amp;amp;&amp;amp; i &amp;lt; N - 1 &amp;amp;&amp;amp; j &amp;gt;= 1 &amp;amp;&amp;amp; j &amp;lt; N - 1 &amp;amp;&amp;amp; k &amp;gt;= 1 &amp;amp;&amp;amp; k &amp;lt; N - 1) {
        out[i*N*N + j*N + k] = c0 * in[i*N*N + j*N + k]
                             + c1 * in[i*N*N + j*N + (k - 1)]
                             + c2 * in[i*N*N + j*N + (k + 1)]
                             + c3 * in[i*N*N + (j - 1)*N + k]
                             + c4 * in[i*N*N + (j + 1)*N + k]
                             + c5 * in[(i - 1)*N*N + j*N + k]
                             + c6 * in[(i + 1)*N*N + j*N + k];
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This example assumes the input and output are 3D grids. For this particular stencil, you should try to identify the number of memory accesses and operations performed. Can you already see some opportunities for optimization?&lt;/p&gt;
&lt;h2 id=&#34;tiled-stencil&#34;&gt;Tiled Stencil&lt;/h2&gt;
&lt;p&gt;Just like with convolution, it is possible to use shared memory to improve the performance of a stencil. The code below shows a tiled stencil kernel that uses shared memory.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void stencil_kernel(float *in, float *out, unsigned int N) {
    __shared__ float tile[IN_TILE_DIM][IN_TILE_DIM][IN_TILE_DIM];
    int i = blockIdx.z * OUT_TILE_DIM + threadIdx.z - 1;
    int j = blockIdx.y * OUT_TILE_DIM + threadIdx.y - 1;
    int k = blockIdx.x * OUT_TILE_DIM + threadIdx.x - 1;

    if (i &amp;gt;= 0 &amp;amp;&amp;amp; i &amp;lt; N &amp;amp;&amp;amp; j &amp;gt;= 0 &amp;amp;&amp;amp; j &amp;lt; N &amp;amp;&amp;amp; k &amp;gt;= 0 &amp;amp;&amp;amp; k &amp;lt; N) {
        tile[threadIdx.z][threadIdx.y][threadIdx.x] = in[i*N*N + j*N + k];
    }
    __syncthreads();
    if (i &amp;gt;=1 &amp;amp;&amp;amp; i &amp;lt; N-1 &amp;amp;&amp;amp; j &amp;gt;= 1 &amp;amp;&amp;amp; j &amp;lt; N-1 &amp;amp;&amp;amp; k &amp;gt;= 1 &amp;amp;&amp;amp; k &amp;lt; N-1) {
        if (threadIdx.z &amp;gt;= 1 &amp;amp;&amp;amp; threadIdx.z &amp;lt; IN_TILE_DIM-1 &amp;amp;&amp;amp;
            threadIdx.y &amp;gt;= 1 &amp;amp;&amp;amp; threadIdx.y &amp;lt; IN_TILE_DIM-1 &amp;amp;&amp;amp;
            threadIdx.x &amp;gt;= 1 &amp;amp;&amp;amp; threadIdx.x &amp;lt; IN_TILE_DIM-1) {
            out[i*N*N + j*N + k] = c0 * tile[threadIdx.z][threadIdx.y][threadIdx.x]
                                 + c1 * tile[threadIdx.z][threadIdx.y][threadIdx.x - 1]
                                 + c2 * tile[threadIdx.z][threadIdx.y][threadIdx.x + 1]
                                 + c3 * tile[threadIdx.z][threadIdx.y - 1][threadIdx.x]
                                 + c4 * tile[threadIdx.z][threadIdx.y + 1][threadIdx.x]
                                 + c5 * tile[threadIdx.z - 1][threadIdx.y][threadIdx.x]
                                 + c6 * tile[threadIdx.z + 1][threadIdx.y][threadIdx.x];
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Just like before, the threads of a block will first collaborate to load a tile with the relevant data. Stencil patterns are more sparse than convolutional filters and require less data to be loaded into shared memory. This will be the central detail in our analysis of stencil patterns.&lt;/p&gt;
&lt;h3 id=&#34;scaling-stencil-size-vs-dot-convolution-filter-size&#34;&gt;Scaling stencil size vs. Convolution filter size&lt;/h3&gt;
&lt;p&gt;Convolutions are more efficient as the size increases since more values are accessed in shared memory. For a \(3 \times 3\) convolution, the upper bound on compute to memory ratio is 4.5 OP/B. A 5 point 2D stencil has a ratio of 2.5 OP/B due to the sparsity of the pattern. The threads in the block would load the diagonal values from global memory, but each thread would only use the 5 points defined by the kernel.&lt;/p&gt;
&lt;h3 id=&#34;tiling-analysis&#34;&gt;Tiling Analysis&lt;/h3&gt;
&lt;p&gt;Let us consider the effectiveness of shared memory tiling where each thread performs 13 floating-point ops (7 multiplies and 6 adds) with each block using \((T - 2)^3\) threads. Each block also performs \(T^3\) loads of 4 bytes each. The compute to memory ratio can be express as:&lt;/p&gt;
&lt;p&gt;\[
\frac{13(T - 2)^3}{4T^3} = \frac{13}{4} \left(1 - \frac{2}{T}\right)^3
\]&lt;/p&gt;
&lt;p&gt;Due to the low limit on threads, the size of \(T\) is typically small. This means there is a smaller amount of reuse of data in shared memory. The ratio of floating-point ops to memory accesses will be low.&lt;/p&gt;
&lt;p&gt;Each warp loads values from 4 distant locations in global memory. This means that the memory accesses are not coalesced: the memory bandwidth is low. Consider an \(8 \times 8 \times 8\) block. A warp of 32 threads will load 4 rows of 8 values each. &lt;strong&gt;The values within each row contiguous, but the rows are not contiguous.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;thread-coarsening&#34;&gt;Thread Coarsening&lt;/h2&gt;
&lt;p&gt;Stencils do not benefit from shared memory as much as convolutions due to the sparsity of the sampled points. Most applications of the stencil patterns work with a 3D grid, resulting in relatively small tile sizes per block.&lt;/p&gt;
&lt;p&gt;A solution to this is to increase the amount of work each thread performs, AKA &lt;em&gt;thread coarsening&lt;/em&gt;. The price paid for parallelism in the stencil pattern is the low frequency of memory reuse.&lt;/p&gt;
&lt;p&gt;Each thread performs more work in the \(z\) direction for a 3D seven-point stencil. All threads collaborate to load in a \(z\) layer at time from \(z-1\) to \(z+1\). There are then 3 different shared memory tiles per block. After computing values in the current output tile, the shared memory is rearranged for the next layer. This means that there are more transfers between shared memory as opposed to global memory.&lt;/p&gt;
&lt;p&gt;The threads are launched to work with a 2D tile at a time, so the size of the block is now \(T^2\). This means we can use a larger value for \(T\). The compute to memory ratio is almost doubled under this scheme. Additionally, the amount of shared memory required is \(3T^2\) rather than \(T^3\).&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void stencil_kernel(float *in, float *out, unsigned int N) {
    int iStart = blockIdx.z * OUT_TILE_DIM;
    int j = blockIdx.y * OUT_TILE_DIM + threadIdx.y - 1;
    int k = blockIdx.x * OUT_TILE_DIM + threadIdx.x - 1;
    __shared__ float inPrev_s[IN_TILE_DIM][IN_TILE_DIM];
    __shared__ float inCurr_s[IN_TILE_DIM][IN_TILE_DIM];
    __shared__ float inNext_s[IN_TILE_DIM][IN_TILE_DIM];

    if (iStart - 1 &amp;gt;= 0 &amp;amp;&amp;amp; iStart - 1 &amp;lt; N &amp;amp;&amp;amp; j &amp;gt;= 0 &amp;amp;&amp;amp; j &amp;lt; N &amp;amp;&amp;amp; k &amp;gt;= 0 &amp;amp;&amp;amp; k &amp;lt; N) {
        inPrev_s[threadIdx.y][threadIdx.x] = in[(iStart - 1)*N*N + j*N + k];
    }
    if (iStart &amp;gt;= 0 &amp;amp;&amp;amp; iStart &amp;lt; N &amp;amp;&amp;amp; j &amp;gt;= 0 &amp;amp;&amp;amp; j &amp;lt; N &amp;amp;&amp;amp; k &amp;gt;= 0 &amp;amp;&amp;amp; k &amp;lt; N) {
        inCurr_s[threadIdx.y][threadIdx.x] = in[iStart*N*N + j*N + k];
    }
    for (int i = iStart; i &amp;lt; iStart + OUT_TILE_DIM; i++) {
        if (i + 1 &amp;gt;= 0 &amp;amp;&amp;amp; i + 1 &amp;lt; N &amp;amp;&amp;amp; j &amp;gt;= 0 &amp;amp;&amp;amp; j &amp;lt; N &amp;amp;&amp;amp; k &amp;gt;= 0 &amp;amp;&amp;amp; k &amp;lt; N) {
            inNext_s[threadIdx.y][threadIdx.x] = in[(i + 1)*N*N + j*N + k];
        }
        __syncthreads();
        if (i &amp;gt;= 1 &amp;amp;&amp;amp; i &amp;lt; N - 1 &amp;amp;&amp;amp; j &amp;gt;= 1 &amp;amp;&amp;amp; j &amp;lt; N - 1 &amp;amp;&amp;amp; k &amp;gt;= 1 &amp;amp;&amp;amp; k &amp;lt; N - 1) {
            if (threadIdx.y &amp;gt;= 1 &amp;amp;&amp;amp; threadIdx.y &amp;lt; IN_TILE_DIM - 1 &amp;amp;&amp;amp;
                threadIdx.x &amp;gt;= 1 &amp;amp;&amp;amp; threadIdx.x &amp;lt; IN_TILE_DIM - 1) {
                out[i*N*N + j*N + k] = c0 * inCurr_s[threadIdx.y][threadIdx.x]
                    + c1 * inCurr_s[threadIdx.y][threadIdx.x - 1]
                    + c2 * inCurr_s[threadIdx.y][threadIdx.x + 1]
                    + c3 * inCurr_s[threadIdx.y - 1][threadIdx.x]
                    + c4 * inCurr_s[threadIdx.y + 1][threadIdx.x]
                    + c5 * inPrev_s[threadIdx.y][threadIdx.x]
                    + c6 * inNext_s[threadIdx.y][threadIdx.x];
            }
        }
        __syncthreads();
        inPrev_s[threadIdx.y][threadIdx.x] = inCurr_s[threadIdx.y][threadIdx.x];
        inCurr_s[threadIdx.y][threadIdx.x] = inNext_s[threadIdx.y][threadIdx.x];
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This kernel is visualized below with a block size of \(6 \times 6\). The left and top sides of the tile have been removed for clarity. All of the blue blocks are loaded from global memory. The dark blue blocks represent the &lt;em&gt;active&lt;/em&gt; plane that is used to compute the corresponding output values. After the current plane is completed, the block synchronizes before moving the current values to the previous plane and loads the next plane&amp;rsquo;s values into the current plane &lt;code&gt;inCurr_s&lt;/code&gt;.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-28_15-28-25_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;Visualization of the thread coarsening tile.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;Visualization of the thread coarsening tile.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h2 id=&#34;register-tiling&#34;&gt;Register Tiling&lt;/h2&gt;
&lt;p&gt;In the coarsening solution presented above, each thread works with a single element in the previous and next shared memory tiles. There are 4 elements in that example that really need to be loaded from shared memory. For the 3 elements that are only required by the current thread, they can be loaded into registers.&lt;/p&gt;
&lt;p&gt;Since only the values in the \(x-y\) direction are required for shared memory, the amount of memory used is reduced by \(\frac{1}{3}\).&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void stencil_kernel(float *in, float *out, unsigned int N) {
    int iStart = blockIdx.z * OUT_TILE_DIM;
    int j = blockIdx.y * OUT_TILE_DIM + threadIdx.y - 1;
    int k = blockIdx.x * OUT_TILE_DIM + threadIdx.x - 1;
    float inPrev;
    float inCurr;
    float inNext;

    __shared__ float inCurr_s[IN_TILE_DIM][IN_TILE_DIM];

    if (iStart - 1 &amp;gt;= 0 &amp;amp;&amp;amp; iStart - 1 &amp;lt; N &amp;amp;&amp;amp; j &amp;gt;= 0 &amp;amp;&amp;amp; j &amp;lt; N &amp;amp;&amp;amp; k &amp;gt;= 0 &amp;amp;&amp;amp; k &amp;lt; N) {
        inPrev = in[(iStart - 1)*N*N + j*N + k];
    }
    if (iStart &amp;gt;= 0 &amp;amp;&amp;amp; iStart &amp;lt; N &amp;amp;&amp;amp; j &amp;gt;= 0 &amp;amp;&amp;amp; j &amp;lt; N &amp;amp;&amp;amp; k &amp;gt;= 0 &amp;amp;&amp;amp; k &amp;lt; N) {
        inCurr = in[iStart*N*N + j*N + k];
        inCurr_s[threadIdx.y][threadIdx.x] = inCurr;
    }
    for (int i = iStart; i &amp;lt; iStart + OUT_TILE_DIM; i++) {
        if (i + 1 &amp;gt;= 0 &amp;amp;&amp;amp; i + 1 &amp;lt; N &amp;amp;&amp;amp; j &amp;gt;= 0 &amp;amp;&amp;amp; j &amp;lt; N &amp;amp;&amp;amp; k &amp;gt;= 0 &amp;amp;&amp;amp; k &amp;lt; N) {
            inNext = in[(i + 1)*N*N + j*N + k];
        }
        __syncthreads();
        if (i &amp;gt;= 1 &amp;amp;&amp;amp; i &amp;lt; N - 1 &amp;amp;&amp;amp; j &amp;gt;= 1 &amp;amp;&amp;amp; j &amp;lt; N - 1 &amp;amp;&amp;amp; k &amp;gt;= 1 &amp;amp;&amp;amp; k &amp;lt; N - 1) {
            if (threadIdx.y &amp;gt;= 1 &amp;amp;&amp;amp; threadIdx.y &amp;lt; IN_TILE_DIM - 1 &amp;amp;&amp;amp;
                threadIdx.x &amp;gt;= 1 &amp;amp;&amp;amp; threadIdx.x &amp;lt; IN_TILE_DIM - 1) {
                out[i*N*N + j*N + k] = c0 * inCurr
                    + c1 * inCurr_s[threadIdx.y][threadIdx.x - 1]
                    + c2 * inCurr_s[threadIdx.y][threadIdx.x + 1]
                    + c3 * inCurr_s[threadIdx.y - 1][threadIdx.x]
                    + c4 * inCurr_s[threadIdx.y + 1][threadIdx.x]
                    + c5 * inPrev
                    + c6 * inNext;
            }
        }
        __syncthreads();
        inPrev = inCurr;
        inCurr = inNext;
        inCurr_s[threadIdx.y][threadIdx.x] = inNext_s[threadIdx.y][threadIdx.x];
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The kernel always has the active plane in shared memory. Every thread collectively store the previous and next planes in registers.&lt;/p&gt;
&lt;p&gt;The larger the stencil size, the more registers are required per thread. In this case, a tradeoff between shared memory space and register usage could be made. This will be explored in your lab.&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Stencils are a useful pattern for solving differential equations. They have some similarities to convolutions, but present unique challenges in terms of optimization. The sparsity of the pattern means that shared memory is not as effective as it is for convolutions. Thread coarsening and register tiling are two techniques that can be used to improve performance.&lt;/p&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;How many registers per thread are required for a 3D seven-point stencil, 3D nine-point stencil, and 3D 27-point stencil?&lt;/li&gt;
&lt;li&gt;How do convolutions relate to stencil patterns? Could you implement a stencil pattern using a convolution filter?&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Hwu, Wen-mei W., David B. Kirk, and Izzat El Hajj. 2022. &lt;i&gt;Programming Massively Parallel Processors: A Hands-on Approach&lt;/i&gt;. Fourth. Morgan Kaufmann.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GPU Pattern: Convolution</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_convolution/</link>
      <pubDate>Mon, 15 Jan 2024 21:35:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_convolution/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#convolution&#34;&gt;Convolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#properties-of-convolutions&#34;&gt;Properties of Convolutions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#implementing-a-convolution-kernel&#34;&gt;Implementing a Convolution Kernel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#constant-memory-and-caching&#34;&gt;Constant Memory and Caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tiled-convolutions&#34;&gt;Tiled Convolutions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#caching-the-halo-cells&#34;&gt;Caching the Halo Cells&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;This pattern involves tiling and input data staging.&lt;/p&gt;
&lt;p&gt;Recall from Lab 1 where we implementing a kernel to blur an image. This kernel worked on each individual output pixel by computing the weighted average of each pixel from the input image, centered on the output pixel location. When we implemented this, we set the weight of every pixel to 1. Whether you were aware of it or not, you implemented a convolution between an input image and weighted kernel.&lt;/p&gt;
&lt;p&gt;The convolution is an extremely important operator that works on time-varying signals of different dimensionality. In computer vision, they are commonly used to compute responses between a known pattern and an input image. The pixels that return a greater response as a result of convolution indicate a match between the pattern and the input image.&lt;/p&gt;
&lt;p&gt;This operator can and has been efficiently implemented in a GPU. Through studying this pattern, you will learn to utilize constant memory storage and shared memory storage to efficiently implement a convolution kernel. These techniques will be useful in later applications as well.&lt;/p&gt;
&lt;h2 id=&#34;convolution&#34;&gt;Convolution&lt;/h2&gt;
&lt;p&gt;A convolution is a function that takes two functions as input and produces a third function as output. The first function is the input and the second function is the kernel. The output is called the feature map. The kernel is also sometimes called the filter.&lt;/p&gt;
&lt;p&gt;\[
(f * g)(t) = \int f(t-a)g(a)da
\]&lt;/p&gt;
&lt;p&gt;We can view them more concretely by considering the functions to be vectors. For example, let the function \(f\) be an input vector \(x\) and \(w\) be a kernel representing a filter. The convolution operator is then&lt;/p&gt;
&lt;p&gt;\[
(x * w)(t) = \int x(t-a)w(a)da.
\]&lt;/p&gt;
&lt;p&gt;The result the &lt;strong&gt;feature map&lt;/strong&gt; representing the response of the kernel at each location in the input.&lt;/p&gt;
&lt;p&gt;In the case of discrete values, it is common to use an odd-sized kernel and center it on an input value. The kernel size is given by some radius \(r\). The convolution operator is then&lt;/p&gt;
&lt;p&gt;\[
(x * w)(t) = \sum_{-r}^r x(t-r)w( r).
\]&lt;/p&gt;
&lt;p&gt;The figure below shows an example of a 1D convolution of a vector if size 8 with a kernel of size 5, centered on the \(t = 2\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-17_18-00-44_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;1D Convolution between a vector of size 8 and a kernel of size 5.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;1D Convolution between a vector of size 8 and a kernel of size 5.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Convolution is defined in such a way that the kernel is traversed in an inverted manner. In the example above, \(y_2\) is computed by applying the kernel to \(\mathbf{x}\) centered on \(x_2\). The calculation in terms of the locations accesses is&lt;/p&gt;
&lt;p&gt;\[
y_2 = x_4 w_{-2} + x_3 w_{-1} + x_2 w_0 + x_1 w_1 + x_0 w_2.
\]&lt;/p&gt;
&lt;p&gt;This operation is very similar to the &lt;em&gt;correlation&lt;/em&gt; operator, which is defined as&lt;/p&gt;
&lt;p&gt;\[
(x \star w)(t) = \sum_{-r}^r x(t+r)w( r).
\]&lt;/p&gt;
&lt;p&gt;We can use the correlation operator to compute the convolution by flipping the kernel. In this case, the calculation can be represented using the dot product. We can also slightly adjust the indexing so that the first index is 0.&lt;/p&gt;
&lt;p&gt;\[
y_i = \sum_{k=0}^{2r} x_{i+k-r} w_{2r-k}.
\]&lt;/p&gt;
&lt;p&gt;Note that the convolution shown above would be undefined for \(i = 0\) and \(i = 1\) since the kernel would be accessing negative indices. Based on the definition, we would ignore these values. This is called a &lt;em&gt;valid&lt;/em&gt; convolution. The output size is then \(n - 2r\). There is also a &lt;em&gt;full&lt;/em&gt; convolution where the output size is \(n\). In this case, the kernel is padded with zeros so that it can be applied to all elements of the input.&lt;/p&gt;
&lt;h3 id=&#34;2d-convolution&#34;&gt;2D Convolution&lt;/h3&gt;
&lt;p&gt;Image convolutions use 2D filters applied to 2D images. For a filter with radius \(r\), size of the filter is \((2r + 1) \times (2r + 1)\). The convolution is then&lt;/p&gt;
&lt;p&gt;\[
(x * w)(i, j) = \sum_{-r}^r \sum_{-r}^r x(i-r, j-r)w(r, s).
\]&lt;/p&gt;
&lt;h2 id=&#34;properties-of-convolutions&#34;&gt;Properties of Convolutions&lt;/h2&gt;
&lt;p&gt;Convolutional networks are commonly built on &lt;em&gt;full&lt;/em&gt; or &lt;em&gt;valid&lt;/em&gt; convolutions. Other variants have also been explored. Here, we will briefly discuss the different properties of this operator. A more detailed treatment can be found in (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Dumoulin and Visin 2018&lt;/a&gt;).&lt;/p&gt;
&lt;h3 id=&#34;padding&#34;&gt;Padding&lt;/h3&gt;
&lt;p&gt;By definition, a convolution of an input with a filter of size \(n\times n\) will produce an output of size \((m-n+1)\times(m-n+1)\), where \(m\) is the size of the input. This means that the output will be smaller than the input. This is often referred to as a &lt;strong&gt;valid&lt;/strong&gt; convolution. The figure below shows a convolution between a \(3\times3\) kernel and a \(5\times5\) input.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-26_16-31-26_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;A valid convolution (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Dumoulin and Visin 2018&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;A valid convolution (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Dumoulin and Visin 2018&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The output of this convolution is a \(3\times3\) feature map. This is a problem if we want to build a deep network. Each convolution will reduce the size of the input. If we were to stack multiple convolutional layers, the output would eventually be too small to be useful. If we want our output to be same size as the input, we can add padding to the original input image before convolving it. This is often known as a &lt;strong&gt;full&lt;/strong&gt; convolution. An example is shown below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-26_16-34-50_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;A full convolution (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Dumoulin and Visin 2018&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;A full convolution (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Dumoulin and Visin 2018&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;stride&#34;&gt;Stride&lt;/h3&gt;
&lt;p&gt;So far, we have only looked at convolutions which step by 1 unit as they shift over the image. We can control the size of this step, or &lt;strong&gt;stride&lt;/strong&gt;, to produce different outcomes. Picking a non-unit stride has a number of effects on the features that are learned in a convolutional neural network.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dimensionality reduction&lt;/strong&gt;: Skipping over pixels reduces the size of the output feature map. This provides another way of downsampling the input.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Less computation&lt;/strong&gt;: Fewer computations are required to produce the output feature map.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Increased field of view&lt;/strong&gt;: A larger stride increases the field of view of the kernel, leading to larger receptive fields in deeper layers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given an input of size \(m\times m\) and a kernel of size \(n\times n\), the output size of a convolution with stride \(s\) is given by&lt;/p&gt;
&lt;p&gt;\[
\left\lfloor\frac{m-n}{s}\right\rfloor + 1.
\]&lt;/p&gt;
&lt;p&gt;The figure below shows a convolution with stride 2 on a \(5\times5\) input.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-26_16-45-20_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;A convolution with stride 2 (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Dumoulin and Visin 2018&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;A convolution with stride 2 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Dumoulin and Visin 2018&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;kernel-size&#34;&gt;Kernel Size&lt;/h3&gt;
&lt;p&gt;The size of the kernel has a large impact on the features that are learned. A larger kernel will have a larger receptive field. This means that the kernel will be able to capture more information about the input. However, this comes at the cost of increased computation. Common kernel sizes in most CNNs are \(3\times3\), \(5\times5\), and \(7\times7\). It is also convenient to pick an odd kernel size so that the kernel has a center pixel.&lt;/p&gt;
&lt;h3 id=&#34;dilation&#34;&gt;Dilation&lt;/h3&gt;
&lt;p&gt;Around 2015, a research trend for CNNs was to find a way to increase the receptive field without adding more parameters. The result is a &lt;strong&gt;dilated&lt;/strong&gt; convolution. The output of a dilated convolution is computed by skipping over pixels in the input. The figure below shows a \(3\times3\) kernel with a dilation of 2.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-27_08-19-10_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 5: &amp;lt;/span&amp;gt;A dilated convolution (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Dumoulin and Visin 2018&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 5: &lt;/span&gt;A dilated convolution (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Dumoulin and Visin 2018&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The output size is computed as&lt;/p&gt;
&lt;p&gt;\[
\left\lfloor\frac{m + 2p - n - (n-1)(d-1)}{s}\right\rfloor + 1,
\]&lt;/p&gt;
&lt;p&gt;where \(p\) is the amount of padding and \(d\) is the dilation factor.&lt;/p&gt;
&lt;h2 id=&#34;implementing-a-convolution-kernel&#34;&gt;Implementing a Convolution Kernel&lt;/h2&gt;
&lt;p&gt;It is straightforward to write the convolution operation in CUDA C++. Each thread will compute the value for a single output pixel using the filter. We already implemented something very similar with the blurring kernel. The kernel itself should accept the following arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The input image&lt;/li&gt;
&lt;li&gt;The output image&lt;/li&gt;
&lt;li&gt;The kernel&lt;/li&gt;
&lt;li&gt;The radius of the kernel&lt;/li&gt;
&lt;li&gt;The width of the output image&lt;/li&gt;
&lt;li&gt;The height of the output image&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A more robust implementation would consider things like padding, stride, dilation, and whether or not a valid or full convolution is desired. For now, we will focus on the simplest case: a valid convolution with a stride of 1 and no padding or dilation. First, let&amp;rsquo;s review the initial naive solution from &lt;em&gt;Programming Massively Parallel Processors&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void conv2D(float *input, float *filter, float *output,
                       int r, int width, int height) {
    int outCol = blockIdx.x * blockDim.x + threadIdx.x;
    int outRow = blockIdx.y * blockDim.y + threadIdx.y;

    float sum = 0.0f;
    for (int row = 0; row &amp;lt; 2*r+1; row++) {
        for (int col = 0; col &amp;lt; 2*r+1; col++) {
            int inRow = outRow + row - r;
            int inCol = outCol + col - r;
            if (inRow &amp;gt;= 0 &amp;amp;&amp;amp; inRow &amp;lt; height &amp;amp;&amp;amp; inCol &amp;gt;= 0 &amp;amp;&amp;amp; inCol &amp;lt; width) {
                sum += input[inRow * width + inCol] * filter[row * (2*r+1) + col];
            }
        }
    }
    output[outRow * width + outCol] = sum;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this kernel, the input and output sizes are assumed to be the same. There is a boundary check in the inner-most loop to account for pixels for which a convolution cannot be computed. Based on this check, we can see that this kernel is performing a &lt;em&gt;valid&lt;/em&gt; convolution. The extra \(2r\) pixels on each side of the output are skipped. This presents a computational problem in the form of control divergence. Recall that all threads in a warp must execute the same instruction. If the boundary check fails for some threads, they will still execute the instructions in the loop, but will not contribute to the output. This is a waste of resources.&lt;/p&gt;
&lt;p&gt;It is also a waste of resources in terms of memory used for the output. If we already know that we want to perform a valid convolution, we can allocate the output image to be the appropriate size before calling it. A slightly modified version is shown below.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void conv2D(float *input, float *filter, float *output,
                       int r, int width, int height) {
    int outCol = blockIdx.x * blockDim.x + threadIdx.x;
    int outRow = blockIdx.y * blockDim.y + threadIdx.y;

    float sum = 0.0f;
    for (int row = 0; row &amp;lt; 2*r+1; row++) {
        for (int col = 0; col &amp;lt; 2*r+1; col++) {
            int inRow = outRow + row;
            int inCol = outCol + col;
            sum += input[inRow * width + inCol] * filter[row * (2*r+1) + col];
        }
    }
    output[outRow * width + outCol] = sum;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;constant-memory-and-caching&#34;&gt;Constant Memory and Caching&lt;/h2&gt;
&lt;p&gt;There is a much larger issue present in both versions of this kernel in terms of memory bandwidth. Similar to the matrix multiplication kernel, this kernel can benefit from tiling. However, there is a new problem that arises specifically with convolution. The same filter is accessed by every single thread. This filter does not change for the entire duration of the kernel. This means that we are wasting memory bandwidth by having every thread access the same filter.&lt;/p&gt;
&lt;p&gt;Given its relatively small size, this kernel is a perfect candidate for constant memory. This is a special type of memory that is cached on the GPU. It is read-only and has a limited size, but it is much faster than global memory. We can write to the devices constant memory from the host code.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;#define FILTER_RADIUS 1
__constant__ float kFilter_d[2*FILTER_RADIUS+1][2*FILTER_RADIUS+1];
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This informs the compiler to allocate a 2D array of floats in constant memory. The size of the array is determined by the constant `FILTER_RADIUS`. We can then copy the filter to the device using the `cudaMemcpyToSymbol` function.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;cudaMemcpyToSymbol(kFilter_d, filter_h, (2*FILTER_RADIUS+1)*(2*FILTER_RADIUS+1)*sizeof(float));
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The line above assumes there is some data on the host in the array `filter_h`. This array is copied to the device. A small note on naming convention, &lt;a href=&#34;https://google.github.io/styleguide/cppguide.html#Constant_Names&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Google&amp;rsquo;s C++&lt;/a&gt; style guide recommends naming constant variables with a &lt;code&gt;k&lt;/code&gt; prefix. I have adopted this convention here.&lt;/p&gt;
&lt;p&gt;At this point, &lt;code&gt;kFilter_d&lt;/code&gt; is accessible from the kernel as a global variable. There is no need to pass it as an argument. The kernel can be modified to use this constant memory as follows.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void conv2D(float *input, float *output,
                       int r, int width, int height) {
    int outCol = blockIdx.x * blockDim.x + threadIdx.x;
    int outRow = blockIdx.y * blockDim.y + threadIdx.y;

    float sum = 0.0f;
    for (int row = 0; row &amp;lt; 2*r+1; row++) {
        for (int col = 0; col &amp;lt; 2*r+1; col++) {
            int inRow = outRow + row;
            int inCol = outCol + col;
            sum += input[inRow * width + inCol] * F_d[row][col];
        }
    }
    output[outRow * width + outCol] = sum;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you organize your files such that the kernel is in a separate file from the host code, you will need to declare the constant variable in the kernel file as well.&lt;/p&gt;
&lt;p&gt;Constant memory variables are stored in DRAM with global memory. The CUDA runtime will cache them since it knows they will not be modified. Processors use caches to reduce the latency of memory accesses by keeping frequently used data in a small, fast memory that is often located directly on the chip. This type of &lt;em&gt;constant cache&lt;/em&gt; is preferable to one that would support high-throughput writes in terms of chip design. It would require specialized hardware to support both which would increase the cost of the chip.&lt;/p&gt;
&lt;h2 id=&#34;tiled-convolutions&#34;&gt;Tiled Convolutions&lt;/h2&gt;
&lt;p&gt;Even with caching, the convolutional kernel still makes many accesses to DRAM. Similar to matrix multiplication, we can tile the input image to reduce the number of accesses. Similar to that example, we will use a \(4 \times 4\) tile size. If the input is a \(16 \times 16\) image and we apply a kernel with radius \(r=2\), the output image under a valid convolution will be \(12 \times 12\). This is visualized in the figure below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-19_16-35-39_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 6: &amp;lt;/span&amp;gt;Left: The input image and its tiling. Middle: the filter. Right: The output image and its tiling.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 6: &lt;/span&gt;Left: The input image and its tiling. Middle: the filter. Right: The output image and its tiling.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The parallel solution to this problem will follow the tiled approach used for matrix multiplication. One key difference in this case is that the input tile size will be larger than the output tile size. This size difference would further be complicated if we left the kernel size as a parameter.&lt;/p&gt;
&lt;p&gt;Following the design presented by (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;) in Chapter 7, there are two immediate approaches to this problem based on the tile size. The first is to choose a block size that matches the size of the input tiles. The benefit to this approach is that each thread can load a single input element into shared memory. The drawback is that some of the threads will be disabled when computing the output value since the output tile is smaller. This is a form of control divergence and will result in wasted resources.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;#define FILTER_RADIUS 1
#define IN_TILE_DIM 4
#define OUT_TILE_DIM ((IN_TILE_DIM) - 2*(FILTER_RADIUS))
__constant__ float kFilter_d[2*FILTER_RADIUS+1][2*FILTER_RADIUS+1];
__global__ void conv2DTiledConstKernel(float *input, float *output,
                                       int width, int height) {
    __shared__ float inputTile[IN_TILE_DIM][IN_TILE_DIM];
    // Input tile coordinates
    int col = blockIdx.x * OUT_TILE_DIM + threadIdx.x;
    int row = blockIdx.y * OUT_TILE_DIM + threadIdx.y;
    if (row &amp;lt; height &amp;amp;&amp;amp; col &amp;lt; width) {
        inputTile[threadIdx.y][threadIdx.x] = input[row * width + col];
    } else {
        inputTile[threadIdx.y][threadIdx.x] = 0.0f;
    }
    __syncthreads();

    // Output tile coordinates
    int tileCol = threadIdx.x - FILTER_RADIUS;
    int tileRow = threadIdx.y - FILTER_RADIUS;

    // In a valid convolution, the output is smaller than the input
    row -= FILTER_RADIUS;
    col -= FILTER_RADIUS;

    if (tileCol &amp;gt;= 0 &amp;amp;&amp;amp; tileCol &amp;lt; OUT_TILE_DIM &amp;amp;&amp;amp; tileRow &amp;gt;= 0 &amp;amp;&amp;amp; tileRow &amp;lt; OUT_TILE_DIM) {
        float sum = 0.0f;
        for (int fRow = 0; fRow &amp;lt; 2*FILTER_RADIUS+1; fRow++) {
            for (int fCol = 0; fCol &amp;lt; 2*FILTER_RADIUS+1; fCol++) {
                sum += inputTile[tileRow + fRow][tileCol + fCol] * kFilter_d[fRow][fCol];
            }
        }
        output[row * (width - 2 * FILTER_RADIUS) + col] = sum;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are a few things to consider here. The first phase of this kernel collaboratively loads data into a shared memory space, similar to what we have seen before. This kernel assumes a convenient indexing scheme where the row and column will always be &amp;gt;= 0. We could adopt a scheme that centers the convolution on the center point of the kernel by allowing for negative indices. In this case, it would be necessary to check if the row and column are less than 0. This implementation only needs to verify that the row and column are within the given image size.&lt;/p&gt;
&lt;p&gt;When it comes to computing the output, not every thread will contribute. This is depicted by the lightly shaded areas in the figure below. You should also note which threads are active for output computation per block. In this simple example, a \(3 \times 3\) filter is used. The input tile dimension is \(4 \times 4\) which means the output tile will be \(2 \times 2\). Only the threads corresponding to the darker blue on the left contribute to the output calculation. Since this one block computes 4 output values, the next block should start 2 units to the right of this one.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-21_16-08-37_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 7: &amp;lt;/span&amp;gt;The active threads for computing the output tile.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 7: &lt;/span&gt;The active threads for computing the output tile.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;performance-analysis&#34;&gt;Performance Analysis&lt;/h3&gt;
&lt;p&gt;The purpose of this approach was to increase the ratio of arithmetic operations to global memory accesses. For the threads that compute an output tile, there is one multiplication and one addition which yields \(\mathtt{OUT\_TILE\_DIM}^2*(2*\mathtt{FILTER\_RADIUS} + 1)^2*2\) operations total. Each thread in the input tile loads a single &lt;code&gt;float&lt;/code&gt; value for a total of \(\mathtt{IN\_TILE\_DIM}^2 * 4\) bytes. For our small example above, this gives&lt;/p&gt;
&lt;p&gt;\[
\frac{2^2 * 3^2 * 2}{4^2 * 4} = 1.125\ \text{Ops/byte}.
\]&lt;/p&gt;
&lt;p&gt;In a more realistic example, we would maximize our input tile size to take advantage of the available threads on the device. Currently, the maximum number of supported threads is 1024. This allows for an input tile size of \(32 \times 32\). The resulting operations per byte under this tile size is&lt;/p&gt;
&lt;p&gt;\[
\frac{30^2 * 3^2 * 2}{32^2 * 4} = 3.955\ \text{Ops/byte}.
\]&lt;/p&gt;
&lt;p&gt;This ratio increases with the size of the filter.&lt;/p&gt;
&lt;h2 id=&#34;caching-the-halo-cells&#34;&gt;Caching the Halo Cells&lt;/h2&gt;
&lt;p&gt;In the previous example, the size of the input tile compared to the output tile means that there were some threads that did not contribute to the output computation. These are the threads managing the lightly shaded cells in the figure above. We will refer to these as &lt;em&gt;halo cells&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This implementation is going to take advantage of the caching behavior in the chip itself. &lt;strong&gt;Values that have been recently used are more likely to already be in L2 cache.&lt;/strong&gt; This is a safe assumption since the neighboring blocks will have loaded these values into shared memory. This means that the input and output tile sizes can be the same; there is no need to waste any threads in the block. The full kernel is given below.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void conv2DTiledCachedConstKernel(float *input, float *output,
                                             int width, int height) {
    __shared__ float inputTile[IN_TILE_DIM][IN_TILE_DIM];
    // Input tile coordinates
    int col = blockIdx.x * IN_TILE_DIM + threadIdx.x;
    int row = blockIdx.y * IN_TILE_DIM + threadIdx.y;
    if (row &amp;lt; height &amp;amp;&amp;amp; col &amp;lt; width) {
        inputTile[threadIdx.y][threadIdx.x] = input[row * width + col];
    } else {
        inputTile[threadIdx.y][threadIdx.x] = 0.0f;
    }
    __syncthreads();

    if (row &amp;lt; FILTER_RADIUS || col &amp;lt; FILTER_RADIUS || col &amp;gt;= (width - FILTER_RADIUS) || row &amp;gt;= (height - FILTER_RADIUS)) return;

    // Output tile coordinates
    row -= FILTER_RADIUS;
    col -= FILTER_RADIUS;
    int tileCol = threadIdx.x - FILTER_RADIUS;
    int tileRow = threadIdx.y - FILTER_RADIUS;

    float sum = 0.0f;
    for (int fRow = 0; fRow &amp;lt; 2 * FILTER_RADIUS + 1; fRow++) {
        for (int fCol = 0; fCol &amp;lt; 2 * FILTER_RADIUS + 1; fCol++) {
            // If this value is in shared memory, access it there
            if (tileCol + fCol &amp;gt;= 0 &amp;amp;&amp;amp;
                tileCol + fCol &amp;lt; IN_TILE_DIM &amp;amp;&amp;amp;
                tileRow + fRow &amp;gt;= 0 &amp;amp;&amp;amp;
                tileRow + fRow &amp;lt; IN_TILE_DIM) {
                sum += inputTile[tileRow + fRow][tileCol + fCol] * kFilter_d[fRow][fCol];
            } else {
                // Otherwise, access it from global memory
                sum += input[(row + fRow) * width + (col + fCol)] * kFilter_d[fRow][fCol];
            }
        }
    }

    output[row * (width - 2 * FILTER_RADIUS) + col] = sum;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Dumoulin, Vincent, and Francesco Visin. 2018. A Guide to Convolution Arithmetic for Deep Learning. &lt;i&gt;Arxiv:1603.07285 [Cs, Stat]&lt;/i&gt;, January. &lt;a href=&#34;http://arxiv.org/abs/1603.07285&#34;&gt;http://arxiv.org/abs/1603.07285&lt;/a&gt;.&lt;/div&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_2&#34;&gt;&lt;/a&gt;Hwu, Wen-mei W., David B. Kirk, and Izzat El Hajj. 2022. &lt;i&gt;Programming Massively Parallel Processors: A Hands-on Approach&lt;/i&gt;. Fourth. Morgan Kaufmann.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GPU Performance Basics</title>
      <link>https://ajdillhoff.github.io/notes/gpu_performance_basics/</link>
      <pubDate>Sun, 14 Jan 2024 13:31:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/gpu_performance_basics/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#memory-coalescing&#34;&gt;Memory Coalescing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hiding-memory-latency&#34;&gt;Hiding Memory Latency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#thread-coarsening&#34;&gt;Thread Coarsening&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#optimization-checklist&#34;&gt;Optimization Checklist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#identifying-bottlenecks&#34;&gt;Identifying Bottlenecks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;These notes are on &amp;ldquo;Chapter 6: Performance Considerations&amp;rdquo; from the book &lt;em&gt;Programming Massively Parallel Processors&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&#34;memory-coalescing&#34;&gt;Memory Coalescing&lt;/h2&gt;
&lt;p&gt;Global memory accesses are one of the largest bottlenecks in GPU applications.
DRAM has high latency based on its design. Each cell has a transistor and a capacitor. If the capacitor is charged, it represents a 1. The process to detect the charges in these cells is on the order of 10s of nanoseconds. DRAM can read consecutive groups of cells via &lt;em&gt;bursts&lt;/em&gt;. This means that if the data we wish to access is stored consecutively, it can be accessed within the same burst. Contrast that was random access, in which the DRAM will have to make multiple bursts to read the required data. &lt;strong&gt;Memory coalescing&lt;/strong&gt; refers to optimizing our global memory accesses to take advantage of DRAM bursts.&lt;/p&gt;
&lt;p&gt;Matrices are &lt;em&gt;naturally coalesced&lt;/em&gt;, so we have already been utilizing this performance pattern in previous examples.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-15_13-00-31_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Memory accesses for a matrix in row-major ordering (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Hwu, Kirk, and El Hajj 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Memory accesses for a matrix in row-major ordering (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Strategies to optimize code for memory coalescing are to rearrange the threads, the data, or transfer the data first to shared memory so that accesses are faster, referred to as &lt;strong&gt;corner turning&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;example-matrix-multiplication&#34;&gt;Example: Matrix Multiplication&lt;/h3&gt;
&lt;p&gt;Consider \(C = AB\), where \(A\) is in row-major order and \(B\) is in column-major order. The naive implementation of this algorithm will have poor memory coalescing. The figure below demonstrates the memory accesses for this scenario. The values required are not consecutive in memory, so the DRAM will have to make multiple bursts to read the data.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-14_20-47-50_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Memory accesses for a matrix in column-major ordering (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Hwu, Kirk, and El Hajj 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Memory accesses for a matrix in column-major ordering (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The accesses to the elements in \(B\) will be slower since the data is not coalesced. Accessing the elements &lt;em&gt;is&lt;/em&gt; efficient if we assign \(N\) consecutive threads to load \(N\) consecutive elements from the same column of \(B\). This works in conjunction with tiling. The original loads to shared memory pull from consecutive elements in \(B\) which allows the application to take advantage of DRAM bursts. Once the data is in shared memory, the rest of the algorithm can be performed with coalesced accesses. Shared memory uses SRAM instead of DRAM, so coalescing is not an issue.&lt;/p&gt;
&lt;h2 id=&#34;hiding-memory-latency&#34;&gt;Hiding Memory Latency&lt;/h2&gt;
&lt;p&gt;DRAMS have &lt;em&gt;banks&lt;/em&gt; and &lt;em&gt;channels&lt;/em&gt;. A controller has a bus that connects banks to the processor. When the DRAM accesses data, the decoder enables the cells so that they can share the information stored with the sensing amplifier. This presents a high latency relative to the time it takes to actually transfer the data. This is why there are multiple banks per channel. The controller can initiate accesses on other banks instead of sitting and waiting for a single bank to finish.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-14_17-19-55_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Single versus Multi-bank burst timings (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Hwu, Kirk, and El Hajj 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Single versus Multi-bank burst timings (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;It is possible that the controller will initiate a request to a bank that is already busy. This is called a &lt;em&gt;bank conflict&lt;/em&gt;. The controller will have to wait for the bank to finish its current request before it can service the new request. The more banks that are available, the less likely it is that a bank conflict will occur.&lt;/p&gt;
&lt;h3 id=&#34;example-matrix-multiplication&#34;&gt;Example: Matrix Multiplication&lt;/h3&gt;
&lt;p&gt;Consider DRAM with 4 channels and 2 banks per channel. The burst size of this DRAM is 8 bytes, or 2 elements. When data is written to DRAM in the first place, it is distributed in an interleaved fashion across the different channels and banks. The first figure below shows the input matrix \(M\) and output matrix \(P\). The second input matrix is omitted for brevity. The indices of \(M\) are linearized in row-major order to show how they are distributed across the DRAM banks. \(P\) is split into 4 blocks of size \(2 \times 2\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-15_13-55-33_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;Matrix M with linearized indices and matrix P split into 4 blocks.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;Matrix M with linearized indices and matrix P split into 4 blocks.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;\(M\) is loaded into DRAM in an interleaved fashion. The first 8 bytes are loaded into bank 0 of channel 0. The next 8 bytes go into bank 0 of channel 1, and so on. Each burst returns 8 bytes. While the first access is being performed on bank 0 channel 0, the controller can initiate a request to bank 0 channel 1. This is visualized in the figure below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-15_14-14-44_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 5: &amp;lt;/span&amp;gt;DRAM distribution for matrix M.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 5: &lt;/span&gt;DRAM distribution for matrix M.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Given the distribution visualized above, we can see that the data accesses for the blocks of \(P\) will be coalesced. Output tile 1 in matrix \(P\) requires $M_0, M_1, M_4,$ and \(M_5\). The first two are available in a single burst from channel 0 bank 0, and the second two are available in a single burst from channel 2 bank 0.&lt;/p&gt;
&lt;h2 id=&#34;thread-coarsening&#34;&gt;Thread Coarsening&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;price of parallelism&lt;/em&gt; may refer to the cost of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;launching threads&lt;/li&gt;
&lt;li&gt;synchronization&lt;/li&gt;
&lt;li&gt;redundant work&lt;/li&gt;
&lt;li&gt;redundant memory accesses&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It there are enough hardware resources available, parallelism at the finest level is ideal. If there are not enough resources, there is a price to pay for this parallelism. The hardware will need to serialize the work into blocks of threads that can be executed in parallel.&lt;/p&gt;
&lt;p&gt;If this is the case for a particular application, it may be beneficial to apply some form of &lt;strong&gt;thread coarsening&lt;/strong&gt;. If the hardware would serialize the work due to inefficient resources, the price of parallelism was paid for nothing. As the programmer, you have the ability to coarsen the threads to alleviate the price of parallelism.&lt;/p&gt;
&lt;h3 id=&#34;example-coarsening-tiled-matrix-multiplication&#34;&gt;Example: Coarsening Tiled Matrix Multiplication&lt;/h3&gt;
&lt;p&gt;In tiled matrix multiplication, it is possible that two separate blocks work with the same tile of data from an input matrix. We pay a price for this redundancy, but the benefit is that we can parallelize the work. If the hardware does not have sufficient resource, it will serialize these two blocks. This results in paying the price of data redundancy without the benefit of parallelism.&lt;/p&gt;
&lt;p&gt;Let \(A, B \in \mathbb{R}^{6 \times 6}\), then \(C = AB \in \mathbb{R}^{6 \times 6}\). If we use a \(2 \times 2\) tile size, then we have 9 blocks of work that can be executed concurrently. For argument&amp;rsquo;s sake, let&amp;rsquo;s say that the hardware can only execute 3 blocks of work at a time. We can use thread coarsening to reduce the number of blocks to 3. Each block will be responsible for a single row of the tiled output matrix. That is, if the output matrix is \(6 \times 6\), then each block will be responsible for a \(2 \times 6\) tile of the output matrix. This is visualized in the figure below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-14_21-42-55_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 6: &amp;lt;/span&amp;gt;Thread coarsening for tiled matrix multiplication.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 6: &lt;/span&gt;Thread coarsening for tiled matrix multiplication.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The block itself will perform a similar function as the implementation of tiled matrix multiplication we saw previously. We will need to modify the kernel so that it processes values to fill for 3 blocks of work, spanning each row. In the figure above, this is represented by the three gray, numbered blocks. Although each block uses a different column from matrix \(N\), they all use the same row from matrix \(M\). Our solution will take advantage of this reuse of data.&lt;/p&gt;
&lt;p&gt;Consider the thread that computes the value for the top left entry of block 1. This thread will compute the output value as normal before looping to compute the corresponding relative position in blocks 2 and 3. That is, if the first entry computed is \((0, 0)\) of block 1, then the next entry computed will be \((0, 0)\) of block 2, and so on. This is visualized by the three solid black cells in the figure below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-14_21-45-47_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 7: &amp;lt;/span&amp;gt;A single thread loops through three blocks as a result of thread coarsening.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 7: &lt;/span&gt;A single thread loops through three blocks as a result of thread coarsening.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The kernel code is given below. The additional loop controls the switch between the three consecutive tiles. The values from matrix &lt;code&gt;M&lt;/code&gt; are loaded inside the outer-most loop and are reused across the coarse tiles.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;#define TILE_WIDTH 2
#define COARSE_FACTOR 3
__global__ void matMulCoarse(float *M, float *N, float *P, int width) {
    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];
    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];

    int bx = blockIdx.x;
    int by = blockIdx.y;
    int tx = threadIdx.x;
    int ty = threadIdx.y;

    // Identify the row and column of the element to work on
    int row = by * TILE_WIDTH + ty;
    int colStart = bx * TILE_WIDTH * COARSE_FACTOR;

    // Initialize Pvalue
    float Pvalue[COARSE_FACTOR];
    for (int i = 0; i &amp;lt; COARSE_FACTOR; i++) {
        Pvalue[i] = 0.0f;
    }

    // Loop over the tiles required to compute the current output value
    for (int ph = 0; ph &amp;lt; width / TILE_WIDTH; ph++) {
        Mds[ty][tx] = M[row * width + ph * TILE_WIDTH + tx];

        for (int c = 0; c &amp;lt; COARSE_FACTOR; c++) {
            int col = colStart + c * TILE_WIDTH;

            Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col];
            __syncthreads();

            for (int k = 0; k &amp;lt; TILE_WIDTH; k++) {
                Pvalue[c] += Mds[ty][k] * Nds[k][tx];
            }
            __syncthreads();
        }
    }

    for (int c = 0; c &amp;lt; COARSE_FACTOR; c++) {
        int col = colStart + c * TILE_WIDTH;
        P[row * width + col] = Pvalue[c];
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;how-to-use-coarsening-in-your-applications&#34;&gt;How to use coarsening in your applications&lt;/h3&gt;
&lt;p&gt;Thread coarsening is yet another technique that can be applied to optimize your parallel programs. The previous section demonstrated &lt;em&gt;how&lt;/em&gt; it can be applied, but you are probably wondering &lt;em&gt;when&lt;/em&gt; it should be applied. Deciding on whether to apply this technique is largely determined by careful analysis of your current application. This analysis should include benchmarking and profiling. There is work that provides an automatic solution (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Stawinoga and Field 2018&lt;/a&gt;), but we will rely on determining that for ourselves.&lt;/p&gt;
&lt;p&gt;For now, we can at least discuss when &lt;em&gt;not&lt;/em&gt; to apply coarsening. The most obvious instance is when coarsening is completely unnecessary. Consider the vector addition kernel. Each thread performs an independent computation that has no overlapping data with other thread. There is no need to apply coarsening in this case.&lt;/p&gt;
&lt;p&gt;Another bad case for implementation would be when the coarsening factor causes hardware to be underutilized. Parallelization in hardware is scalable. If we take away the opporunity for scale, there may be unused compute. This is typically something we can determine via benchmarking.&lt;/p&gt;
&lt;p&gt;In the coarsened version of matrix multiplication above, we had to create additional private variables to store the coarsened values. These use additional registers per thread. If our application required more than the 32 registers available on our H100, for example, this would have a direct effect on occupancy. Keep that in mind when developing your thread coarsened solution.&lt;/p&gt;
&lt;h2 id=&#34;optimization-checklist&#34;&gt;Optimization Checklist&lt;/h2&gt;
&lt;p&gt;Section 6.4 of &lt;em&gt;Programming Massively Parallel Processors&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;) provides a checklist of items to consider when optimizing your GPU applications. These are summarized below.&lt;/p&gt;
&lt;h3 id=&#34;maximizing-occupancy&#34;&gt;Maximizing Occupancy&lt;/h3&gt;
&lt;p&gt;Having more threads than physical cores available is beneficial, as it hides the latency required for other operations such as data fetching. Instead of waiting on some operation to return, the hardware can switch to another thread to perform work. This is implemented by adjusting the launch configurations or optimizing the number of registers used per thread, for example. We also discussed solutions for hiding memory-based latency.&lt;/p&gt;
&lt;h3 id=&#34;coalesced-global-memory-accesses&#34;&gt;Coalesced Global Memory Accesses&lt;/h3&gt;
&lt;p&gt;Random accesses to memory are less efficient than consecutive ones. This is a theme that is repeated through many themes of computer science, such as sorting. Understanding of how the underlying hardware works brought to light new ways to optimize our applications. We can rearrange our data to take advantage of DRAM bursts, or we can use shared memory to reduce the latency of memory accesses.&lt;/p&gt;
&lt;h3 id=&#34;minimizing-control-divergence&#34;&gt;Minimizing Control Divergence&lt;/h3&gt;
&lt;p&gt;Although we have not used any applications that exhibit control divergence, we have studied the concept. During SIMD execution, the hardware executes the same instructions on multiple data elements. If a thread or group of threads would diverge from the others, the hardware would have to make multiple passes to cover all of the possible paths.&lt;/p&gt;
&lt;h3 id=&#34;tiling&#34;&gt;Tiling&lt;/h3&gt;
&lt;p&gt;Global memory accesses exhibit higher latency due to the nature of DRAM. We can reduce the number of global memory accesses by using shared memory. This was exemplified in the tiled matrix multiplication examples, where there are many redundant data accesses. Moving these data to shared memory reduces the number of global memory accesses.&lt;/p&gt;
&lt;h3 id=&#34;thread-coarsening&#34;&gt;Thread Coarsening&lt;/h3&gt;
&lt;p&gt;In cases where the hardware would serialize execution of a kernel, thread coarsening can eliminate redundant work. In the tiled matrix multiplication example, we saw that the hardware would serialize execution of the kernel if there were not enough resources available. In this case, the same redundant loads to shared memory would be performed. To reduce this overhead, we coarsened the thread by having a single kernel perform the work of multiple blocks.&lt;/p&gt;
&lt;h2 id=&#34;identifying-bottlenecks&#34;&gt;Identifying Bottlenecks&lt;/h2&gt;
&lt;p&gt;Knowing when to apply each of these optimization techniques comes down to understanding your application. &lt;strong&gt;The single most important step in optimizing your application is to identify the bottleneck&lt;/strong&gt;. What resource is limiting the performance of your solution? Benchmarking and profiling are two techniques that can be used to identify these bottlenecks. We will begin learning these tools in the next lecture.&lt;/p&gt;
&lt;h2 id=&#34;the-takeaway&#34;&gt;The Takeaway&lt;/h2&gt;
&lt;p&gt;At this point, you have learned the basics of GPU programming with CUDA. You should be familiar with writing kernels, setting launch configurations, and compiling them. You should be familiar with a few optimization techniques that can be applied to your applications, but you are probably not confident in your ability to identify when they should be used.&lt;/p&gt;
&lt;p&gt;The next module of this course will focus on problems for which a straightforward solution is not obvious. These are problems that come from other domains of computer science, such as graph theory and linear algebra. We will learn how to apply the techniques we have learned to these problems, and we will learn new techniques that are specific to these problems. Even though the applications themselves may be specific, the techniques used to optimize them are not.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Hwu, Wen-mei W., David B. Kirk, and Izzat El Hajj. 2022. &lt;i&gt;Programming Massively Parallel Processors: A Hands-on Approach&lt;/i&gt;. Fourth. Morgan Kaufmann.&lt;/div&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_2&#34;&gt;&lt;/a&gt;Stawinoga, Nicolai, and Tony Field. 2018. Predictable Thread Coarsening. &lt;i&gt;Acm Transactions on Architecture and Code Optimization&lt;/i&gt; 15 (2): 23:123:26. &lt;a href=&#34;https://doi.org/10.1145/3194242&#34;&gt;https://doi.org/10.1145/3194242&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>CUDA Memory Architecture</title>
      <link>https://ajdillhoff.github.io/notes/cuda_memory_architecture/</link>
      <pubDate>Thu, 11 Jan 2024 15:07:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/cuda_memory_architecture/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#memory-access&#34;&gt;Memory Access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#memory-types&#34;&gt;Memory Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tiling&#34;&gt;Tiling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-tiled-matrix-multiplication&#34;&gt;Example: Tiled Matrix Multiplication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#boundary-checking&#34;&gt;Boundary Checking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#memory-use-and-occupancy&#34;&gt;Memory Use and Occupancy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dynamically-changing-the-block-size&#34;&gt;Dynamically Changing the Block Size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;So far, the kernels we have used assume everything is on global memory. Even though there are thousands of cores that can effectively hide the latency of transferring data to and from global memory, we will see this delay will become a bottleneck in many applications. These notes explore the different types of memory available on the GPU and how to use them effectively.&lt;/p&gt;
&lt;h2 id=&#34;memory-access&#34;&gt;Memory Access&lt;/h2&gt;
&lt;p&gt;Transferring memory is one of the biggest bottlenecks in GPU programming. Companies like NVIDIA devote a lot of resources to improving the bandwidth and latency of memory transfers. When training a deep learning model, the datasets used are far too large to fit on the GPU. This means that the data must be transferred to the GPU before the actual training code can execute on the device. Training large models can take days or weeks, so the time spent transferring data can be significant.&lt;/p&gt;
&lt;p&gt;The example provided in Chapter 5 of &amp;ldquo;Programming Massively Parallel Processors&amp;rdquo; is a great introduction to understanding memory access efficiency (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;). In matrix multiplication, the data accesses are limited to a single line of code in the inner-most loop. This means that the memory access pattern is very regular and predictable. The example code is shown below:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;for (int k = 0; i k &amp;lt; numCols; k++) {
    Cvalue += A[row * numCols + k] * B[k * numCols + col];
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This line consists of a floating-point multiplication, floating-point addition, and two memory accesses. Note that we are not storing the result yet, so there is no access to the C matrix. The operation effiency can be described in terms of floating-point operations per second (FLOP/s) and the accesses can be measured in the number of bytes transferred. In this case, we have 2 FLOPs and 8 bytes transferred. This means that the ratio of FLOPs to bytes transferred is 0.25 FLOP/B. This is described as &lt;em&gt;computational intensity&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;With this definition, we get a clearer picture on how to improve the performance of our code. If our kernel relies on too many memory accesses, then the computational intensity will be low. This means that the GPU will be spending more time waiting for data to be transferred than actually performing computations. The goal is to increase the computational intensity as much as possible.&lt;/p&gt;
&lt;p&gt;To put this in perspective, the H100 SXM5 has 3TB/s of memory bandwidth. This global memory bandwidth limits the kernel to 3000 * 0.25 = 750 GFLOP/s. The peak performance of the H100 is 66.9 TFLOPS. If the specialized Tensor cores are utilized, the peak performance is 494.7 TFLOPS. That means that are kernel is only using 0.15% of the peak performance of the GPU. This program is certainly &lt;strong&gt;memory bound&lt;/strong&gt;. Our theoretical limit to computational intensity is the peak performance of the GPU. Programs that achieve this peak are called &lt;strong&gt;compute bound&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Based on the tools we have discussed so far, it is not clear how we can optimize this kernel. The only way to improve the computational intensity is to reduce the number of memory accesses. Modern GPUs have more than just global memory. The next section will explore the different types of memory available on the GPU.&lt;/p&gt;
&lt;h2 id=&#34;memory-types&#34;&gt;Memory Types&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Global Memory&lt;/li&gt;
&lt;li&gt;Local Memory
Resides on global memory, but is not shared between threads. This includes local variables and function arguments.&lt;/li&gt;
&lt;li&gt;Shared Memory
Resides on the chip. Allocated to thread blocks. Shared between threads in the same block.&lt;/li&gt;
&lt;li&gt;Constant Memory&lt;/li&gt;
&lt;li&gt;Registers
Resides on the chip. Each thread has its own registers. Very fast memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data in CPU registers are swapped depending on the context of the program. GPU registers are consistent even when other threads are launched to hide latency. This results in a larger register file on the GPU.&lt;/p&gt;
&lt;p&gt;Following the von Neumann architecture, memory that is closer to the chip is faster but more expensive. Data residing on registers is the most ideal for performance since the processor can work directly with the register values. This benefit comes in the form of energy consumption as well. Transferring data from global memory to the chip requires additional cycles resulting in more energy used.&lt;/p&gt;
&lt;p&gt;When a private variable is declared in a kernel, every single thread will have its own copy of that variable.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Variable declaration&lt;/th&gt;
&lt;th&gt;Memory&lt;/th&gt;
&lt;th&gt;Scope&lt;/th&gt;
&lt;th&gt;Lifetime&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Automatic variables (not arrays)&lt;/td&gt;
&lt;td&gt;Register&lt;/td&gt;
&lt;td&gt;Thread&lt;/td&gt;
&lt;td&gt;Grid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Automatic array variables&lt;/td&gt;
&lt;td&gt;Local&lt;/td&gt;
&lt;td&gt;Thread&lt;/td&gt;
&lt;td&gt;Grid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__device__ __shared__ int SharedVar;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Shared&lt;/td&gt;
&lt;td&gt;Block&lt;/td&gt;
&lt;td&gt;Grid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__device__ int GlobalVar;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Global&lt;/td&gt;
&lt;td&gt;Grid&lt;/td&gt;
&lt;td&gt;Application&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__device__ __constant__ int ConstVar;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Constant&lt;/td&gt;
&lt;td&gt;Grid&lt;/td&gt;
&lt;td&gt;Application&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Automatic array variables should seldom be used. It may have seemed convenient to use a static array for computing channel-specific values in an image processing kernel, but it is more efficient to use three separate variables. Each variable will be allocated to a register resulting in faster access times.&lt;/p&gt;
&lt;p&gt;Global variables are more commonly used to pass information to another kernel that is being launched.&lt;/p&gt;
&lt;h2 id=&#34;tiling&#34;&gt;Tiling&lt;/h2&gt;
&lt;p&gt;These memory types serve as tools that we can use to increase efficiency. The first pattern discussed is &lt;strong&gt;tiling&lt;/strong&gt;. Throughout the rest of the course, we will add many more patterns to our repertoire. Tiling is a well-described technique that has a fitting analogy. If a wall needs to be tiled, it is more efficient to use many small tiles that are lighter and easier to handle. In GPU programming, the wall represents the entire global memory space. The individual tiles are local memory that is allocated to each thread block.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_10-13-54_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Global memory access pattern (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Global memory access pattern (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The kernels we have seen so far have used a &lt;em&gt;global memory access pattern&lt;/em&gt;. In this pattern, all threads have access to every data point from the input. Using a &lt;em&gt;tiling pattern&lt;/em&gt;, we can optimize memory accesses by moving shared resources to local memory that is faster to access.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_10-16-40_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Tiling pattern (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Tiling pattern (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The tool itself is quite simple in concept, but the challenge will be identifying when the tool can be properly applied. Consider matrix multiplication. The naive kernel we explored previously uses each thread to compute one value of the output matrix. This kernel uses a global memory access pattern, and we can identify that many of the computations require the same input. They key to introducing tiling for matrix multiplication will be identifying which data use reused.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_10-28-30_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Memory accesses for matrix multiplication (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Memory accesses for matrix multiplication (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;In the figure above, the block size is \(2 \times 2\). Each row of the block relies on the same input row from the matrix on the left. That is, \(P_{0,0}\) and \(P_{0,1}\) will use the same data from the first row of \(M\). In our original kernel, this requires 8 global memory accesses. If we placed this row in shared memory, each output thread could access the values much quicker. We can see a similar pattern for the column values in \(N\).&lt;/p&gt;
&lt;p&gt;Since we are using tiling with a block size of \(B\), we will consider working with \(2B\) values from the input at a time. If the number of values we need to compute an output entry exceeds \(2B\), then we can synchronize the threads before moving to the next section.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_10-25-26_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;Tiled matrix multiplication overview (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;Tiled matrix multiplication overview (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Verify that the potential reduction in global memory traffic in matrix multiplication is proportional to the dimension of the blocks used.&lt;/li&gt;
&lt;li&gt;Verify that the reduction is by a factor of \(N\) if the tiles are \(N \times N\).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;example-tiled-matrix-multiplication&#34;&gt;Example: Tiled Matrix Multiplication&lt;/h2&gt;
&lt;p&gt;The concept of tiled matrix multiplication is this: load a subset of data from \(M\) and \(N\) into shared memory before using that data to perform the dot product. We have a few limitations to think about here. First, the amount of shared memory is much smaller than global memory; we cannot fit all the data at once. Second, the block size will limit how many elements can be loaded into shared memory at once. As suggested by tiling, we are only working with a small chunk at a time.&lt;/p&gt;
&lt;p&gt;Using a \(2 \times 2\) block gives us 4 threads to work with. Overlaying that block on the input only allows us to grab 2 values from the first 2 rows in \(M\) and 2 values from the first 2 columns in \(M\). For each tile, the subset of data will be loaded in followed by adding the dot product of the subset to the current value.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_11-14-57_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 5: &amp;lt;/span&amp;gt;Loading the first tile (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 5: &lt;/span&gt;Loading the first tile (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;







&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_11-15-33_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 6: &amp;lt;/span&amp;gt;Computing the dot product of the first subset (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 6: &lt;/span&gt;Computing the dot product of the first subset (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;In this example, the block will move to the next subset of data to finish computing the first block of the output matrix. This process can be arbitrarily scaled up to support larger matrices without necessarily increasing the block size. Although, we would want to increase the block size to take advantage of the additional threads. The figure below shows a table of the computations required for each phase.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_11-18-02_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 7: &amp;lt;/span&amp;gt;Tiled matrix multiplication computations (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 7: &lt;/span&gt;Tiled matrix multiplication computations (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Check your understanding&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;By using tiling with a block size of \(B \times B\), what is the total reduction in global memory traffic?&lt;/p&gt;
&lt;h3 id=&#34;implementation-in-cuda&#34;&gt;Implementation in CUDA&lt;/h3&gt;
&lt;p&gt;Our implementation should follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Establish shared memory for the input from matrix \(M\) and matrix \(N\).&lt;/li&gt;
&lt;li&gt;Load the first subset of data from \(M\) and \(N\) into shared memory (remember to synchronize threads).&lt;/li&gt;
&lt;li&gt;Compute the dot product of the subset (remember to synchronize threads).&lt;/li&gt;
&lt;li&gt;Repeat steps 2 and 3 until all subsets have been computed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Step 1 is obvious. We need to establish the shared memory for this solution. Steps 2 and 3 are the same as described above, but we do need to remember to synchronize the threads. Without synchronization, the computation may continue before all the data is properly loaded. Step 4 implies that each thread will loop through the subsets until all values have been computed. The kernel is shown below.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void MatMulKernel(float* M, float* N, float* P, int Width) {
    // Block index
    int bx = blockIdx.x;
    int by = blockIdx.y;

    // Thread index
    int tx = threadIdx.x;
    int ty = threadIdx.y;

    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];
    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];

    // Identify the row and column of the P element to work on
    int Row = by * TILE_WIDTH + ty;
    int Col = bx * TILE_WIDTH + tx;

    float Pvalue = 0;
    for (int ph = 0; ph &amp;lt; Width / TILE_WIDTH; ++ph) {
        // Collaborative loading of M and N tiles into shared memory
        Mds[ty][tx] = M[Row * Width + ph * TILE_WIDTH + tx];
        Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * Width + Col];
        __syncthreads();

        for (int k = 0; k &amp;lt; TILE_WIDTH; ++k) {
            Pvalue += Mds[ty][k] * Nds[k][tx];
        }
        __syncthreads();
    }

    P[Row * Width + Col] = Pvalue;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s break this down with a small example. Consider multiplying two \(4 \times 4\) matrices. We will use a block size of \(2 \times 2\), as seen in the figure below. Our block will compute the top left submatrix of the output, \(P_{0,0}\), \(P_{0,1}\), \(P_{1,0}\), and \(P_{1,1}\). We will view the computation from the perspective of the thread for \(P_{0,0}\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_14-15-32_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 8: &amp;lt;/span&amp;gt;Setup of tiled matrix multiplication example.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 8: &lt;/span&gt;Setup of tiled matrix multiplication example.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The row and column of the output computed by the current thread is calculated using the block and thread indices. Of course, this is simply \((0, 0)\) for the first thread. It gets slightly more complicated when computing the input subset in the loop. The input needs to be transferred to shared memory. The loop will skip over a tile at a time. At this point, we already know which row of \(M\) and column of \(N\) we need to access. We need to compute the column index for \(M\) and the row index for \(N\).&lt;/p&gt;
&lt;p&gt;For \(M\), we start with &lt;code&gt;Row * Width&lt;/code&gt;. This needs to be offset by the tile offset index &lt;code&gt;ph&lt;/code&gt; of the main loop, yielding &lt;code&gt;Row * Width + ph * TILE_WIDTH&lt;/code&gt;. Finally, we need to add the thread index &lt;code&gt;tx&lt;/code&gt; to get the final index &lt;code&gt;Row * Width + ph * TILE_WIDTH + tx&lt;/code&gt;. The same process is applied to \(N\). &lt;strong&gt;Note that this only transfers a single value from each matrix to shared memory, but our computation relies on 2 values from each matrix.&lt;/strong&gt; Each thread in the block is collaboratively loading the data into shared memory. This is why the call to &lt;code&gt;__syncthreads()&lt;/code&gt; is necessary.&lt;/p&gt;
&lt;p&gt;Specifically, the thread for \(P_{0, 0}\) copies \(M_{0, 0}\) and \(N_{0, 0}\) to shared memory. The thread for \(P_{0, 1}\) copies \(M_{0, 1}\) and \(N_{1, 0}\) to shared memory. The thread for \(P_{1, 0}\) copies \(M_{1, 0}\) and \(N_{0, 1}\) to shared memory. Finally, the thread for \(P_{1, 1}\) copies \(M_{1, 1}\) and \(N_{1, 1}\) to shared memory.&lt;/p&gt;
&lt;p&gt;The next step is to compute the dot product of the subset. Again, we see a call to &lt;code&gt;__syncthreads()&lt;/code&gt;. Without this synchronization, the loop may be allowed to continue and overwrite the data in shared memory before a thread has finished. Once the final value is computed, each thread can freely write it back to global memory. Since each thread is computing a different value, there is no need to synchronize the threads before writing to global memory.&lt;/p&gt;
&lt;p&gt;\begin{align*}
P_{0, 0} &amp;amp;+= 2 \times 2 + 1 \times 1 \\
P_{0, 1} &amp;amp;+= 2 \times 1 + 1 \times 0 \\
P_{1, 0} &amp;amp;+= 1 \times 2 + 0 \times 1 \\
P_{1, 1} &amp;amp;+= 1 \times 1 + 0 \times 0
\end{align*}&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_14-21-27_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 9: &amp;lt;/span&amp;gt;Updated values for the first subset.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 9: &lt;/span&gt;Updated values for the first subset.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The next iteration of the loop will grab the next subset of the data and repeat the process. The result after this step is shown below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_14-26-26_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 10: &amp;lt;/span&amp;gt;Updated values for the second subset.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 10: &lt;/span&gt;Updated values for the second subset.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;To summarize, &lt;code&gt;ph&lt;/code&gt; is the tile offset index, &lt;code&gt;Row&lt;/code&gt; and &lt;code&gt;Col&lt;/code&gt; are the row and column of the output computed by the current thread, and &lt;code&gt;tx&lt;/code&gt; and &lt;code&gt;ty&lt;/code&gt; will give the offset with respect to the current tile.&lt;/p&gt;
&lt;p&gt;The kernel above has an outer loop that calls another loop managed by thread synchronization, breaking the computation up into several distinct phases. This is called &lt;strong&gt;strip-mining&lt;/strong&gt; and is an important part of tiling. This existed even before GPUs were used (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).&lt;/p&gt;
&lt;h3 id=&#34;performance-analysis&#34;&gt;Performance Analysis&lt;/h3&gt;
&lt;p&gt;In the naive implementation, we had a computational intensity of 0.25 FLOP/B. With a \(16 \times 16\) tile, the number of global memory accesses is reduced by a factor of 16. This gives us a computational intensity of 4 FLOP/B. We previously stated that the H100 has a global memory bandwidth of 3TB/s. This means that the theoretical limit for the performance of this kernel is 3000 * 4 = 12000 GFLOP/s which is much better than the 750 GFLOP/s we had before.&lt;/p&gt;
&lt;p&gt;This is not the most optimal way to implement matrix multiplication, and you should always refer to the cuBLAS library for matrix operations. The purpose of this example is to demonstrate the use of tiling.&lt;/p&gt;
&lt;h2 id=&#34;boundary-checking&#34;&gt;Boundary Checking&lt;/h2&gt;
&lt;p&gt;The previous implementation assumed that the width of the matrices was a multiple of the tile width and that the input would always be square matrices. Consider changing our \(2 \times 2\) block to a \(3 \times 3\) block using the same input sizes.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-13_12-56-49_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 11: &amp;lt;/span&amp;gt;Using a 3x3 block (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 11: &lt;/span&gt;Using a 3x3 block (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Our implementation would follow the same process for the first subset of pattern. An issue arises when computing the second tile offset since the block exceeds the boundaries of our input and output. One solution would be to check the boundary condition on both the input, when transferring the data to shared memory, and the output, when reading the data from shared memory. This would require a conditional statement in the inner loop. This is not ideal since the conditional statement would be executed for every thread in the block.&lt;/p&gt;
&lt;p&gt;Another solution is to pad the input with zeros. If the index is outside our boundary, adding a 0 will not affect the result of the dot product. This allows for a simpler implementation while still being flexible enough to handle matrices of any size. The relevant portion of the kernel is shown below.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;float Pvalue = 0;
for (int ph = 0; ph &amp;lt; ceil(Width/(float)TILE_WIDTH); ph++) {
    // Collaborative loading of M and N tiles into shared memory
    if (Row &amp;lt; Width &amp;amp;&amp;amp; ph * TILE_WIDTH + tx &amp;lt; Width) {
        Mds[ty][tx] = M[Row * Width + ph * TILE_WIDTH + tx];
    } else {
        Mds[ty][tx] = 0.0;
    }
    if (ph * TILE_WIDTH + ty &amp;lt; Width &amp;amp;&amp;amp; Col &amp;lt; Width) {
        Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * Width + Col];
    } else {
        Nds[ty][tx] = 0.0;
    }
    __syncthreads();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The rest of the kernel remains the same. In Lab 2, you will implement this and adapt it to work with non square matrices as well.&lt;/p&gt;
&lt;h2 id=&#34;memory-use-and-occupancy&#34;&gt;Memory Use and Occupancy&lt;/h2&gt;
&lt;p&gt;Just like exceeding the number of registers per thread can negatively affect occupancy, so can over allocating shared memory. The H100 can have up to 228 KB per SM. If we are maximizing the 2048 threads available per SM, each block cannot exceed 228 KB / 2048 threads = 112 B/thread.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How much shared memory is used by each block?&lt;/strong&gt; Each block has 2 arrays of size \(TILE\_WIDTH \times TILE\_WIDTH\) of type &lt;code&gt;float&lt;/code&gt;. This gives us a total of \(2 \times TILE\_WIDTH \times TILE\_WIDTH \times 4 = 8(TILE\_WIDTH)^2\) B. Each block uses \(TILE\_WIDTH^2\) threads, resulting in 8 B/thread. This is well below the limit of 112 B/thread.&lt;/p&gt;
&lt;h2 id=&#34;dynamically-changing-the-block-size&#34;&gt;Dynamically Changing the Block Size&lt;/h2&gt;
&lt;p&gt;The solution presented above uses a constant to determine the tile size. What if this tile size was not optimal for a given hardware configuration? We would surely want to adjust this dynamically to maximize performance. In CUDA, we can support this by using the &lt;code&gt;extern&lt;/code&gt; keyword. First, we need to define our shared memory as one array: &lt;code&gt;extern __shared__ float Mds_Nds[];&lt;/code&gt;. This is a 1D array that represents the shared memory for both input matrices.&lt;/p&gt;
&lt;p&gt;When launching this kernel, we need some way to inform it of the tile size. First, we would query the device properties and determine the optimal tile size based on the hardware. This size can be used as a third launch configuration input, as shown below. Additionally, the size of the shared memory for each input matrix is provided as two additional arguments to the kernel.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;size_t size = compute_optimal_size(); // Determine optimal tile size
MatMulKernel&amp;lt;&amp;lt;&amp;lt;dimGrid, dimBlock, size&amp;gt;&amp;gt;&amp;gt;(M_d, N_d, P_d, Width, size/2, size/2);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The kernel will need to be modified to use the new shared memory array. The first step is to determine the offset for each matrix. This is done by multiplying the tile size by the thread index. The second step is to use the offset to access the correct value in the shared memory array. The kernel is shown below.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__ void MatMulKernel(float* M, float* N, float* P, int Width, int Mds_offset, int Nds_offset) {
    extern __shared__ float Mds_Nds[];

    float *Mds = (float *)Mds_Nds;
    float *Nds = (float *)Mds_Nds + Mds_offset;

    // Rest of the kernel
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Completing this modification would require us to use linear indexing for &lt;code&gt;Mds&lt;/code&gt; and &lt;code&gt;Nds&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-takeaway&#34;&gt;The Takeaway&lt;/h2&gt;
&lt;p&gt;Tiling is a powerful tool that can be used to improve the performance of a kernel. It is important to understand the memory access pattern of your kernel and identify which data is reused. This will allow you to move that data to shared memory and reduce the number of global memory accesses. Tiling is the first of many &lt;em&gt;patterns&lt;/em&gt; that we will explore. Just like not every tool is useful for every job, not every pattern will be useful for each problem we face. Increasing the number of tools, or patterns, that we have available will allow us to solve a wider range of problems efficiently.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Hwu, Wen-mei W., David B. Kirk, and Izzat El Hajj. 2022. &lt;i&gt;Programming Massively Parallel Processors: A Hands-on Approach&lt;/i&gt;. Fourth. Morgan Kaufmann.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>CUDA Architecture</title>
      <link>https://ajdillhoff.github.io/notes/cuda_architecture/</link>
      <pubDate>Mon, 08 Jan 2024 20:49:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/cuda_architecture/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#architecture&#34;&gt;Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#block-scheduling&#34;&gt;Block Scheduling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#synchronization&#34;&gt;Synchronization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#warps&#34;&gt;Warps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#control-divergence&#34;&gt;Control Divergence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#warp-scheduling&#34;&gt;Warp Scheduling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#resource-partitioning&#34;&gt;Resource Partitioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dynamic-launch-configurations&#34;&gt;Dynamic Launch Configurations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;A GPU consists of chip that is composed of several &lt;strong&gt;streaming multiprocessors&lt;/strong&gt; (SMs). Each SM has a number of cores that execute instructions in parallel. The H100, seen below, has 144 SMs (you can actually count them by eye). Each SM has 128 FP32 cores for a total of 18,432 cores. Historically, CUDA has used DDR memory, but newer architectures use high-bandwidth memory (HBM). This is closely integrated with the GPU for faster data transfer.&lt;/p&gt;
&lt;p&gt;In the image below, you can see 6 HBM3 memory modules surrounding the GPU, 3 on either side of the die. HBM3 is capable of 3 TB/s of bandwidth. The platform shown only uses 5 of these modules. The full version will utilize all 6.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-11_14-29-08_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;NVIDIA H100 GPU with 144 SMs ([NVIDIA](https://resources.nvidia.com/en-us-tensor-core)).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;NVIDIA H100 GPU with 144 SMs (&lt;a href=&#34;https://resources.nvidia.com/en-us-tensor-core&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;NVIDIA&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h2 id=&#34;block-scheduling&#34;&gt;Block Scheduling&lt;/h2&gt;
&lt;p&gt;When a kernel is launched, the blocks that we configure in our code are assigned to SMs. All threads in each block will be assigned to each SM. Depending on the platform, the number of blocks that can be assigned to an SM will vary. This is discussed in more detail below. Since all threads in a block are on the same SM, they can share data and communicate with each other.&lt;/p&gt;
&lt;h2 id=&#34;synchronization&#34;&gt;Synchronization&lt;/h2&gt;
&lt;p&gt;Threads that run on the same block can be synchronized using &lt;code&gt;__syncthreads()&lt;/code&gt;. This is a pretty straightforward concept, but it is important to understand the caveats. When a kernel reaches this call, the execution of the threads will stop until all of them have reached that point. This construct is typically used when threads need to share data or are dependent on the results of other threads.&lt;/p&gt;
&lt;p&gt;Be careful on using this call. An example of incorrect usage is shown below.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__
void kernel(int *a, int *b, int *c) {
    if (threadIdx.x % 2 == 0) {
        // Perform some work
        __syncthreads();
    else {
        // Perform some other work
        __syncthreads();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Unlike a general-purpose processor, a GPU does not have control hardware for each individual core. This means that all threads must execute the same instructions using shared resources. In the example above, it is possible for some threads to branch off into a different part of the program. However, only one of the paths can be executed based on this limitation. This is called &lt;strong&gt;control divergence&lt;/strong&gt; and is discussed in more detail below.&lt;/p&gt;
&lt;p&gt;Even though the call looks the same, each &lt;code&gt;__syncthreads()&lt;/code&gt; is different. The first call will only synchronize the threads that executed the first path. The second call will only synchronize the threads that executed the second path. The result is either undefined output or a deadlock, in which the threads will never reach the second call.&lt;/p&gt;
&lt;p&gt;Since threads in separate blocks cannot be synchronized, the blocks can be executed in any arbitrary order. You might immediately ask yourself how a complex problem that requires synchronization between all parts of the data can get around this limitation. We will explore more complex patterns and their solutions in later sections.&lt;/p&gt;
&lt;h2 id=&#34;warps&#34;&gt;Warps&lt;/h2&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-28_21-03-23_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Warps across several blocks (credit: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Warps across several blocks (credit: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Streaming Multiprocessors in a CUDA chip execute threads in a group of 32 called &lt;strong&gt;warps&lt;/strong&gt;. Since Compute Capability 1.0, the warp size has not changed. When a block is assigned to an SM, it is divided into warps. Given this size, you can easily determine the number of warps assigned to an SM. For example, if you have a block of 256 threads, the SM has 256 / 32 = 8 warps. If the block size is not evenly divisible by the number of warps per SM, the last warp will be padded with inactive threads.&lt;/p&gt;
&lt;p&gt;When multi-dimensional thread blocks are assigned to an SM, the threads are linearly mapped in a &lt;strong&gt;row-major&lt;/strong&gt; order before being partitioned into warps. For example, a 2D block of \(16 \times 16\) threads will be mapped to a 1D array of 256 threads. The first 32 threads will be assigned to the first warp, the next 32 to the second warp, and so on.&lt;/p&gt;
&lt;p&gt;Warps are executed following the Single-Instruction, Multiple-Data (SIMD) model. There is a single program that runs the same instruction on all threads in the same order. If a thread would have executed a different path based on its input data, it would not be executed with the others. This is called &lt;strong&gt;control divergence&lt;/strong&gt; and is explained in the next section.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-28_21-08-27_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;SM layout (source: NVIDIA DLI)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;SM layout (source: NVIDIA DLI)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The advantage of this model is that more physical space can be dedicated to ALUs instead of control logic. In a traditional CPU, each processing core would have its own control logic. The tradeoff is that different cores can execute their own programs at varying points in time.&lt;/p&gt;
&lt;h2 id=&#34;control-divergence&#34;&gt;Control Divergence&lt;/h2&gt;
&lt;p&gt;Since a traditional CPU has separate control logic for each core, it can execute different programs at the same time. If the program has a conditional statement, it does not need to worry about synchronizing instructions with another core. This is not the case with a GPU. Since every thread in a warp executes the same instruction, only threads that would execute the same path can be processed at the same time. If a thread would execute a different path, it is not executed with the others. This is called &lt;strong&gt;control divergence&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What exactly happens then if a warp has 32 threads of which only 16 would execute the same path? Simply, multiple passes are made until all possible paths of execution are considered based on the divergence of the threads. The SM would process the first 16 threads that all follow the same path before processing the second 16 threads.&lt;/p&gt;
&lt;p&gt;This also applies to other control flow statements such as loops. Consider a CUDA program that processes the elements of a vector. Depending on the loop and data used, the threads may execute a different number of iterations. As threads finished their iterations, they would be disabled while the remaining threads continue.&lt;/p&gt;
&lt;p&gt;There are some cases in which it is apparent that your program will exhibit control divergence. For example, if you have a conditional statement based on the thread index, you can be sure that the threads will execute different paths.&lt;/p&gt;
&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;
&lt;p&gt;Consider a \(200 \times 150\) image that is processed by a CUDA program. The kernel is launched with \(16 \times 16\) blocks which means there are \(200 / 16 = 13\) blocks in the x-direction and \(150 / 16 = 10\) blocks in the y-direction. The total number of blocks is \(13 \times 10 = 130\). Each block has 256 threads, or 8 warps. That means that the total number of warps is \(130 \times 8 = 1040\).&lt;/p&gt;
&lt;h2 id=&#34;warp-scheduling&#34;&gt;Warp Scheduling&lt;/h2&gt;
&lt;p&gt;An SM can only execute instructions for a small number of warps. The architecture allows for more warps than the SM can execute since warps will often be waiting for some result or data transfer. Warps are selected based on a priority mechanism. This is called &lt;strong&gt;latency tolerance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Zero-overhead thread scheduling allows for selecting warps without any overhead. A CPU has more space on the chip for caching and branch prediction so that latency is as low as possible. GPUs have more floating point units and can switch between warps, effectively hiding latency.&lt;/p&gt;
&lt;p&gt;The execution states for all assigned warps are stored in the hardware registers, eliminating the need to save and restore registers when switching between warps.&lt;/p&gt;
&lt;p&gt;Under this model, it is ideal for an SM to be assigned more threads than it can execute at once. This increases the odds that the SM will have a warp ready to execute when another warp is waiting for data.&lt;/p&gt;
&lt;h2 id=&#34;resource-partitioning&#34;&gt;Resource Partitioning&lt;/h2&gt;
&lt;p&gt;There is a limit on the number of warps that an SM can support. In general, we want to maximize the throughput of an SM by assigning as many warps as possible. The ratio of warps assigned to the number of warps an SM supports is called &lt;strong&gt;occupancy&lt;/strong&gt;. If we understand how the architecture partitions the resources, we can optimize our programs for peak performance. Consider the NVIDIA GH100 GPU, pictured below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-11_11-44-01_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;GH100 Full GPU with 144 SMs ([NVIDIA](https://resources.nvidia.com/en-us-tensor-core)).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;GH100 Full GPU with 144 SMs (&lt;a href=&#34;https://resources.nvidia.com/en-us-tensor-core&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;NVIDIA&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The H100 architecture shares the same limitations in compute capability as the A100, so this example will follow the book closely (Hwu, Kirk, and El Hajj 2022). The H100 supports 32 threads per warp, 64 warps per SM, 32 blocks per SM, and 2048 threads per SM. Depending on the block size chosen, the number of blocks per SM will differ. For example, a block size of 256 threads means that there are 2048 / 256 = 8 blocks per SM. This block size would maximize occupancy since the architecture supports more than 8 blocks per SM. Also, the number of threads per block is less than the limit of 1024.&lt;/p&gt;
&lt;p&gt;What if we chose 32 threads per block? Then there would be 2048 / 32 = 64 blocks per SM. However, the device only supports 32 blocks per SM. With only 32 blocks allocated with 32 threads per block, a total of 1024 threads would be utilized. The occupancy in this case is 1024 / 2048 = 50%.&lt;/p&gt;
&lt;p&gt;Historically, NVIDIA provided an excel spreadsheet to compute occupancy. It has since been deprecated in favor of Nsight Compute, a tool that provides more information about the performance of your program. We will cover this tool in a later section.&lt;/p&gt;
&lt;h3 id=&#34;including-registers&#34;&gt;Including Registers&lt;/h3&gt;
&lt;p&gt;Another factor for occupancy is the number of registers used per thread. The H100 has 65,536 registers available for use. As long as your program does not use more than this, you can follow the simpler occupancy calculation from above. With 2048 threads, that leaves 65,536 / 2048 = 32 registers per thread. If we run a program with 256 threads/block, there would be 2048 / 256 = 8 blocks per SM. This means that there are 8 * 256 = 2048 threads per SM. With 31 registers per thread, the total number of registers used per SM is 2048 * 31 = 63,488. In this case we still maximize occupancy since 63,488 &amp;lt; 65,536.&lt;/p&gt;
&lt;p&gt;What if each thread required 33 registers? In that case, the total number of registers used per SM would be 2048 * 33 = 67,584. How would these resources be partitioned? Only 7 blocks could be assigned since 7 * 256 * 33 = 59,136 &amp;lt; 65,536. This means that only 7 * 256 = 1792 threads would be used, reducing the occupancy to 1792 / 2048 = 87.5%.&lt;/p&gt;
&lt;h2 id=&#34;dynamic-launch-configurations&#34;&gt;Dynamic Launch Configurations&lt;/h2&gt;
&lt;p&gt;Depending on our application requirements, we may need to support a range of devices across several compute capabalities. The CUDA API makes this simple by providing several different functions for querying device properties. These can be called from the host before configuring and launching a kernel. This is not an exhaustive list, but it covers the most important properties. When we first launch a program that utilizes CUDA, we will want to know how many devices are available. Later in this course, we will develop programs that utilize multiple GPUs, but we would also want our code to adapt dynamically to a single GPU.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; deviceCount;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cudaGetDeviceCount(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;deviceCount);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the device count is known, the properties of each device can be acquired with &lt;code&gt;cudaGetDeviceProperties&lt;/code&gt;. This function takes a pointer to a &lt;code&gt;cudaDeviceProp&lt;/code&gt; struct. The struct contains several properties that can be used to configure the kernel launch. The most important properties are listed below. A full list can be found &lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;in the CUDA documentation.&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Property&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;name&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Name of the device&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;totalGlobalMem&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Total amount of global memory available on the device in bytes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;sharedMemPerBlock&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Shared memory available per block in bytes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;regsPerBlock&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;32-bit registers available per block&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;warpSize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Warp size in threads&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;maxThreadsPerBlock&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Maximum number of threads per block&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;maxThreadsDim&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Maximum size of each dimension of a block&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;maxGridSize&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Maximum size of each dimension of a grid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;multiProcessorCount&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Number of SMs on the device&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;maxThreadsPerMultiProcessor&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Maximum number of threads per SM&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The following example iterates through all devices and queries their properties.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; deviceCount; i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cudaDeviceProp prop;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cudaGetDeviceProperties(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;prop, i);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Use properties to configure kernel launch
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;the-takeaway&#34;&gt;The Takeaway&lt;/h2&gt;
&lt;p&gt;The CUDA architecture is designed to maximize the number of threads that can be executed in parallel. This is achieved by partitioning the resources of the GPU into SMs. Each SM can execute a small number of warps at a time. The number of warps that can be assigned to an SM is called &lt;strong&gt;occupancy&lt;/strong&gt;. The occupancy is determined by the number of threads per block, the number of blocks per SM, and the number of registers used per thread. The CUDA API provides functions for querying device properties so that the kernel launch can be configured dynamically.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multidimensional Grids and Data</title>
      <link>https://ajdillhoff.github.io/notes/multidimensional_grids_and_data/</link>
      <pubDate>Fri, 05 Jan 2024 11:56:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/multidimensional_grids_and_data/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#multidimensional-grid-organization&#34;&gt;Multidimensional Grid Organization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-color-to-grayscale&#34;&gt;Example: Color to Grayscale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#no-longer-embarrassing-overlapping-data&#34;&gt;No longer embarrassing: overlapping data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#matrix-multiplication&#34;&gt;Matrix Multiplication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-s-next&#34;&gt;What&amp;rsquo;s Next?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;The CUDA Programming model allows us to organize our data in a multidimensional grid. The purpose of this is primarily for our own convenience, but it also allows us to take advantage of the GPU&amp;rsquo;s memory hierarchy. In Lab 0, we only required a single dimension for our grid as well as each block since the input was a vector. When performing computations on multidimensional data like matrices, we can match the dimensions of our launch configuration to the dimensions of our data.&lt;/p&gt;
&lt;h2 id=&#34;multidimensional-grid-organization&#34;&gt;Multidimensional Grid Organization&lt;/h2&gt;
&lt;p&gt;All threads share a block index, &lt;code&gt;blockIdx&lt;/code&gt;, and a thread index, &lt;code&gt;threadIdx&lt;/code&gt;. These indices are three-dimensional vectors of type &lt;code&gt;dim3&lt;/code&gt;. The &lt;code&gt;dim3&lt;/code&gt; type is defined as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dim3&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x, y, z;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;};
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Each grid is a 3D array of blocks, and every block a 3D array of threads. Consider the kernel execution for &lt;code&gt;vecAdd&lt;/code&gt; from Lab 0:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;blocksPerGrid&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;threadsPerBlock&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vecAdd&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;blocksPerGrid, threadsPerBlock&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(a_d, b_d, c_d, n);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will execute with \(32 \times 128 = 4096\) threads.&lt;/p&gt;
&lt;p&gt;If our input is a matrix, we should organize our launch dimensions to match its 2D structure. We seemingly have two options: either the grid size or the block size. Consider the figure below, there are 4 blocks in the grid, each with 16 threads organized as a \(4 \times 2 \times 2\) volume.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-05_14-20-10_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;A 2D grid of blocks, each with 16 threads arranged in a 3D configuration (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;A 2D grid of blocks, each with 16 threads arranged in a 3D configuration (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Under such a configuration, we would make use of &lt;code&gt;gridDim.x&lt;/code&gt;, &lt;code&gt;gridDim.y&lt;/code&gt;, and &lt;code&gt;gridDim.z&lt;/code&gt; to access the dimensions of the grid. The dimensions of the block would be accessed with &lt;code&gt;blockDim.x&lt;/code&gt;, &lt;code&gt;blockDim.y&lt;/code&gt;, and &lt;code&gt;blockDim.z&lt;/code&gt;. The thread indices would be accessed with &lt;code&gt;threadIdx.x&lt;/code&gt;, &lt;code&gt;threadIdx.y&lt;/code&gt;, and &lt;code&gt;threadIdx.z&lt;/code&gt;. Would this be the best way to organize our launch configuration? &lt;strong&gt;Not exactly.&lt;/strong&gt; We have no use for the 3D structure if we are only working with matrices.&lt;/p&gt;
&lt;p&gt;Consider an \(n \times m\) matrix. If the matrix is small enough, we could launch a single block with a 2D arrangement of threads to perform the necessary computation. For larger matrices, we would optimally split the work into multiple blocks. This would allow us to perform more work in parallel. Let \(n=62\) and \(m=76\). If we chose a \(16 \times 16\) block size, we would need \(4 \times 5 = 20\) blocks to cover the entire matrix, as shown in the figure below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-05_15-04-59_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;A 2D grid of blocks, each with 16 threads arranged in 2D (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;A 2D grid of blocks, each with 16 threads arranged in 2D (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;notes-on-compute-capability&#34;&gt;Notes on Compute Capability&lt;/h3&gt;
&lt;p&gt;It is more important to dynamically adjust the grid size so that your program can adapt to varying input sizes. As of CC 9.0, the maximum number of threads a block can have is 1024, this means that a \(32 \times 32\) block is the largest we can do for matrix data.&lt;/p&gt;
&lt;p&gt;If the input matrix is smaller than \(32 \times 32\), then only a single block is needed. The additional threads allocated to that block will be inactive for indices outside the range of our input.&lt;/p&gt;
&lt;p&gt;If the input matrix is larger than \(32 \times 32\), additional blocks should be added to the grid to accommodate the increased size. It is safe to keep the block size fixed, but the grid size &lt;strong&gt;must&lt;/strong&gt; be dynamic.&lt;/p&gt;
&lt;h3 id=&#34;optimal-launch-parameters&#34;&gt;Optimal Launch Parameters&lt;/h3&gt;
&lt;p&gt;Is it better to have fewer blocks that maximize the amount of threads per block? Or is it better to have more blocks with fewer threads per block? The current maximum number of threads per block is 1024. In practice, a maximum block dimension size of 128 or 256 is ideal. This has more to do with the specific problem and the amount of shared memory required. You will explore this question in Lab 1.&lt;/p&gt;
&lt;h2 id=&#34;example-color-to-grayscale&#34;&gt;Example: Color to Grayscale&lt;/h2&gt;
&lt;p&gt;Given the layout just described, we will write a kernel that converts a color image to grayscale. This is an &lt;em&gt;embarrassingly parallel&lt;/em&gt; problem since each pixel can be converted independently of the others. We will use the following formula to convert each pixel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gray &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.299f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; red &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.587f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; green &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.114f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blue
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A CPU implementation would require a &lt;code&gt;for&lt;/code&gt; loop over the exact number of pixels. The CUDA kernel for this is straightforward since it only depends on the current pixel. The only real challenge is to compute the correct indices for each thread.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__
void colorToGrayscale(unsigned char *rgbImage,
                      unsigned char *grayImage,
                      int numRows, int numCols)
{
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;
    if (x &amp;gt;= numCols || y &amp;gt;= numRows) return;

    int index = y * numCols + x;
    int rgbOffset = index * 3;
    unsigned char r = rgbImage[rgbOffset];
    unsigned char g = rgbImage[rgbOffset + 1];
    unsigned char b = rgbImage[rgbOffset + 2];
    float channelSum = 0.299f * r + 0.587f * g + 0.114f * b;
    grayImage[index] = channelSum;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this example, we assume an RGB image where each pixel is represented by three unsigned characters. It is standard convention in C to pass a pointer to the first element of the array. This implies that we cannot use the &lt;code&gt;[]&lt;/code&gt; operator to access the elements in a multidimensional way. Instead, we must compute the index ourselves. If you are not currently familiar with flat indexing, you certainly will be by the end of this course.&lt;/p&gt;
&lt;p&gt;In C, multi-dimensional arrays are stored in row-major order. To compute the index of row &lt;code&gt;j&lt;/code&gt; and column &lt;code&gt;i&lt;/code&gt; in a 2D array, we need to skip over &lt;code&gt;j&lt;/code&gt; rows and &lt;code&gt;i&lt;/code&gt; columns. The total number of columns is the width of the array. The total number of rows is the height of the array. The index is computed as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; width &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; i;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is represented in the following figure.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-05_16-56-55_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;A 2D array stored in row-major order (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;A 2D array stored in row-major order (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Since the image is now represented as a flat 1D array, we can use the index computed above to access the correct pixel. The image is typically stored in the same row-major format, although this is not always the case. You should always check the documentation for the image format you are using.&lt;/p&gt;
&lt;h3 id=&#34;launch-configuration&#34;&gt;Launch Configuration&lt;/h3&gt;
&lt;p&gt;As stated above, we are going to launch 20 blocks in a \(4 \times 5\) grid. Each block will have 256 threads arranged in a \(16 \times 16\) 2D configuration. This totals to \(20 \times 256 = 5120\) threads. The example figure above shows this configuration overlaid on a \(76 \times 62\) image. That means we have 4712 pixels that need to be converted. The remaining 408 threads will be idle.&lt;/p&gt;
&lt;p&gt;You might be wondering if all 5120 threads launch at the same time. What if the number of pixels exceeded the number of threads available on the GPU? The short answer is that the GPU will launch as many threads as possible, but the long answer is slightly more complicated and will be discussed in a later lesson.&lt;/p&gt;
&lt;p&gt;In any case, our kernel can be launched using the following code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;blockSize&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;gridSize&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;colorToGrayscale&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;gridSize, blockSize&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(rgbImage, grayImage, numRows, numCols);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;no-longer-embarrassing-overlapping-data&#34;&gt;No longer embarrassing: overlapping data&lt;/h2&gt;
&lt;p&gt;At this point, you should have a basic understanding of how to solve problems that are embarrassingly parallel. Now comes the next step in shaping your parallel thinking skills. What if the thread relies on multiple data points that may be used by other threads. This is further complicated with problems that require some computation to complete before a thread can begin its work. Let&amp;rsquo;s take a step into deeper waters by looking at image blurring. This is a common technique used in image processing to reduce noise and detail. The basic idea is to replace each pixel with a weighted average of its neighboring pixels. The size of the neighborhood is called the &lt;strong&gt;kernel size&lt;/strong&gt;. The kernel size is typically an odd number so that the pixel of interest is in the center of the neighborhood.&lt;/p&gt;
&lt;p&gt;The core operation behind blurring is called a &lt;strong&gt;convolution&lt;/strong&gt;. We will explore this operation in depth as it serves as a more advanced pattern for parallelism. For now, we will focus on the basic idea. Given a kernel size of \(5 \times 5\) centered on a pixel, we will compute the weighted average of the 25 pixels in the neighborhood. To keep it simple, the weights will be uniform.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-06_15-50-37_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;A blurring kernel (red) centered on a pixel (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;A blurring kernel (red) centered on a pixel (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Given a pixel location \((x, y)\), we can compute the index of the pixel in the neighborhood as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (y &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; ky) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; numCols &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; kx);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Where \(ky\) and \(kx\) are the row and column indices of the kernel. The kernel is centered on the pixel of interest, so \(ky\) and \(kx\) range from \(-2\) to \(2\). The total number of pixels in the neighborhood is \(5 \times 5 = 25\). The weighted average is computed as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; sum &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0f&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; numPixels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; ky &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;; ky &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;; ky&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; kx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;; kx &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;; kx&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; kx &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; kx &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; numCols) &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (y &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; ky &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; ky &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; numRows) &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (y &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; ky) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; numCols &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; kx);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        sum &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; image[index];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        numPixels&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;image[y &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; numRows &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; x] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sum &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; numPixels;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Some extra care will be needed to account for pixels outside the boundaries. There are several strategies to handle out-of-bounds pixels. The simplest is to ignore them. We will explore other strategies when discussing convolutions. In Lab 1, you will implement a blur kernel that can support a varying kernel size.&lt;/p&gt;
&lt;h2 id=&#34;matrix-multiplication&#34;&gt;Matrix Multiplication&lt;/h2&gt;
&lt;p&gt;Matrix multiplication is one of the most important operations in linear algebra. Many high performance computing applications rely on it. It is one of the most widely called operations in deep learning, for example. Parallelizing this and other linear algebra operations has resulted in an explosion of research and applications ranging from computer vision to computational fluid dynamics. Exploring the parallelism of matrix multiplication will give us a deeper understanding of the CUDA programming model. It will also serve as a jumping off point for more advanced topics like shared memory and convolutional neural networks.&lt;/p&gt;
&lt;h3 id=&#34;definition&#34;&gt;Definition&lt;/h3&gt;
&lt;p&gt;Let \(A = \mathbb{R}^{m \times n}\) and \(B = \mathbb{R}^{n \times p}\) be two matrices. The product \(C = AB\) is defined as follows:&lt;/p&gt;
&lt;p&gt;\[
C_{ij} = \sum_{k=1}^n A_{ik} B_{kj}\quad \text{for } i = 1, \ldots, m \text{ and } j = 1, \ldots, p
\]&lt;/p&gt;
&lt;p&gt;This operation is only defined on compatible matrices. That is, the number of columns in \(A\) must equal the number of rows in \(B\). The resulting matrix \(C\) will have \(m\) rows and \(p\) columns.&lt;/p&gt;
&lt;h3 id=&#34;cpu-implementation&#34;&gt;CPU Implementation&lt;/h3&gt;
&lt;p&gt;The CPU implementation of matrix multiplication is straightforward. There is a double &lt;code&gt;for&lt;/code&gt; loop to iterate through each element in the &lt;em&gt;output&lt;/em&gt; matrix. The inner loop computes the dot product of the $i$th row of \(A\) and the $j$th column of \(B\). The dot product is computed by summing the element-wise product of the two vectors.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;matrixMultiplyCPU&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;A, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; m, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; p) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; m; i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; j &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; p; j&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; sum &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0f&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; k &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; n; k&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                sum &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; A[i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; k] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B[k &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; j];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            C[i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; p &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; j] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sum;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;gpu-implementation&#34;&gt;GPU Implementation&lt;/h3&gt;
&lt;p&gt;For a parallel implementation, we can reason that each thread should compute a single element of the output matrix. To compute element \(C_{ij}\), the thread needs access to row \(i\) from \(A\) and column \(j\) from \(B\). Each thread is simply computing the dot product between these two vectors. The figure below visualizes this process.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-08_12-56-34_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 5: &amp;lt;/span&amp;gt;Matrix multiplication (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 5: &lt;/span&gt;Matrix multiplication (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The output matrix is separated into blocks based on our block size. When writing the kernel, it is necessary to make sure that the index is not out of bounds.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__
void matrixMultiplyGPU(float *A, float *B, float *C, int m, int n, int p) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    if (row &amp;gt;= m || col &amp;gt;= p) return;

    float sum = 0.0f;
    for (int k = 0; k &amp;lt; n; k++) {
        sum += A[row * n + k] * B[k * p + col];
    }
    C[row * p + col] = sum;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;launch-configuration&#34;&gt;Launch Configuration&lt;/h3&gt;
&lt;p&gt;The launch configuration is similar to the previous examples. We will launch a 2D grid of blocks, each with a 2D arrangement of threads. The block size will be \(16 \times 16\) and the grid size will be \(m / 16 \times p / 16\). The kernel is launched as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;blockSize&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;gridSize&lt;/span&gt;((p &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; blockSize.x &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; blockSize.x,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              (m &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; blockSize.y &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; blockSize.y, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;matrixMultiplyGPU&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;gridSize, blockSize&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(A_d, B_d, C_d, m, n, p);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;What happens when the output matrix size exceeds the number of blocks per grid and threads per block? Either multiple kernels will be launched, each working with a submatrix of the original input, or each thread will be responsible for multiple elements.&lt;/p&gt;
&lt;h2 id=&#34;what-s-next&#34;&gt;What&amp;rsquo;s Next?&lt;/h2&gt;
&lt;p&gt;The complexity was slightly increased by considering multidimensional data. Matrices are a prime example of this. The algorithms explored required us to consider multiple input values to compute a single output value. However, the computation did not rely on any thread synchronization, so the task was still simple enough.&lt;/p&gt;
&lt;p&gt;Before diving into more complex operations like thread synchronization, was need a better understanding of the GPU&amp;rsquo;s architecture and memory hierarchy. With this knowledge at our disposal, we can begin to optimize our kernels for maximum performance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Heterogeneous Data Parallel Computing</title>
      <link>https://ajdillhoff.github.io/notes/heterogeneous_data_parallel_computing/</link>
      <pubDate>Sat, 30 Dec 2023 14:41:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/heterogeneous_data_parallel_computing/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#key-concepts&#34;&gt;Key Concepts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cuda-c-programs&#34;&gt;CUDA C Programs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-vector-addition&#34;&gt;Example: Vector Addition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#error-checking&#34;&gt;Error Checking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Task Parallelism vs. Data Parallelism&lt;/li&gt;
&lt;li&gt;kernels&lt;/li&gt;
&lt;li&gt;threads&lt;/li&gt;
&lt;li&gt;grids&lt;/li&gt;
&lt;li&gt;blocks&lt;/li&gt;
&lt;li&gt;global memory&lt;/li&gt;
&lt;li&gt;data transfer&lt;/li&gt;
&lt;li&gt;error checking&lt;/li&gt;
&lt;li&gt;compilation of CUDA programs&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;This topic introduces the basics of data parallelism and CUDA programming. The most important concept is that data parallelism is achieved through independent computations on each sample or groups of samples. The basic structure of a CUDA C program consists of writing a &lt;strong&gt;kernel&lt;/strong&gt; that is executed independently on many threads. Memory must be allocated on the GPU device before transferring the data from the host machine (CPU). Upon completion of the kernel, the results need to be transferred back to the &lt;strong&gt;host&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;cuda-c-programs&#34;&gt;CUDA C Programs&lt;/h2&gt;
&lt;p&gt;A basic CUDA program consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;kernel&lt;/strong&gt; function defining the work to be performed on each thread.&lt;/li&gt;
&lt;li&gt;Data that is accessible on the &lt;strong&gt;device&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Device memory allocation.&lt;/li&gt;
&lt;li&gt;Memory transfer from the &lt;strong&gt;host&lt;/strong&gt; to the &lt;strong&gt;device&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Execution of the &lt;strong&gt;kernel&lt;/strong&gt; from the &lt;strong&gt;host&lt;/strong&gt; machine.&lt;/li&gt;
&lt;li&gt;Data transfer from the &lt;strong&gt;device&lt;/strong&gt; back to the &lt;strong&gt;host&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Memory cleanup.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At first glance, the execution flow of a CUDA program appears sequential; you launch the threads on the GPU and wait for it to complete. A more realistic program would launch the threads and continue local execution, if necessary.&lt;/p&gt;
&lt;h2 id=&#34;example-vector-addition&#34;&gt;Example: Vector Addition&lt;/h2&gt;
&lt;p&gt;Hwu et al. refer to vector addition as the &amp;ldquo;Hello World&amp;rdquo; of GPU programming (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;). It is a simple problem that can be described as &lt;em&gt;embarrassingly parallel&lt;/em&gt;. Vector addition is a simple operation. Given two vectors of the same length, \(\mathbf{x}\) and \(\mathbf{y}\), the vector addition operation is defined as:&lt;/p&gt;
&lt;p&gt;\[
\mathbf{z}_i = \mathbf{x}_i + \mathbf{y}_i \quad \forall i \in \{1, \ldots, n\}
\]&lt;/p&gt;
&lt;p&gt;The vector addition operation is commutative and associative. The operation can be performed in parallel on each element of the vectors. This can be implemented simply in C.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vecAdd&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;x_h, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;y_h, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;z_h, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; n; i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        z_h[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x_h[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; y_h[i];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;One small note about the variable names: it is common to use the suffix `_h` to denote a variable that is allocated on the host (CPU) and `_d` to denote a variable that is allocated on the device (GPU). In this case, the vector addition operation is performed on the host machine.&lt;/p&gt;
&lt;p&gt;An equivalent implementation in CUDA C is shown below.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;__global__
void vecAdd(float *x_d, float *y_d, float *z_d, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i &amp;lt; n) {
        z_d[i] = x_d[i] + y_d[i];
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This kernel executes on a single thread. The thread index is computed using built-in variables `blockIdx.x`, `blockDim.x`, and `threadIdx.x`. The details of how these variables are defined are not important right now. The main point is that each kernel is executed on a single thread. For a GPU with thousands of individual threads, this kernel will be executed thousands of times in parallel.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;__global__&lt;/code&gt; keyword placed before the function definition indicates that the function can be called from both the host and the device, but it is only executed on the device. The table below shows the different keywords used to define functions in CUDA C.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Keyword&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__global__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Executed on the device, callable from the host and device&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__device__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Executed on the device, callable from the device only&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;__host__&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Executed on the host, callable from the host only&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Unless otherwise specified, functions that you define will be executed on the host. That is, it is not necessary to specify the &lt;code&gt;__host__&lt;/code&gt; keyword. If you want the compiler to generate both host and device code, you can use the &lt;code&gt;__host__ __device__&lt;/code&gt; keyword combination.&lt;/p&gt;
&lt;p&gt;The kernel is executed on the host machine using the following code.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;int main() {
    // Allocate memory on the host
    float *x_h, *y_h, *z_h;
    int n = 1024;

    x_h = malloc(n * sizeof(float));
    y_h = malloc(n * sizeof(float));
    z_h = malloc(n * sizeof(float));

    // Allocate memory on the device
    float *x_d, *y_d, *z_d;
    cudaMalloc(&amp;amp;x_d, n * sizeof(float));
    cudaMalloc(&amp;amp;y_d, n * sizeof(float));
    cudaMalloc(&amp;amp;z_d, n * sizeof(float));

    // Transfer data from host to device
    cudaMemcpy(x_d, x_h, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(y_d, y_h, n * sizeof(float), cudaMemcpyHostToDevice);

    // Execute kernel
    vecAdd&amp;lt;&amp;lt;&amp;lt;ceil(n / 256.0), 256&amp;gt;&amp;gt;&amp;gt;(x_d, y_d, z_d, n);

    // Transfer data from device to host
    cudaMemcpy(z_h, z_d, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free memory on host and device
    free(x_h);
    free(y_h);
    free(z_h);
    cudaFree(x_d);
    cudaFree(y_d);
    cudaFree(z_d);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There is a lot to unpack here, so we&amp;rsquo;ll start from the top.&lt;/p&gt;
&lt;h3 id=&#34;memory-allocation&#34;&gt;Memory Allocation&lt;/h3&gt;
&lt;p&gt;It doesn&amp;rsquo;t really matter where the host data comes from or how it is allocated, but the above example allocates memory using &lt;code&gt;malloc&lt;/code&gt; anyway. Before transferring data to the device, we must allocate memory on it. This is done via &lt;code&gt;cudaMalloc&lt;/code&gt;. The first argument is a pointer to address of the variable. Remember that taking the address of a pointer will result in a double pointer. This is necessary because the function will need to dereference the pointer to store the address to the allocated data. Once the memory is allocated on the device, it cannot be accessed from the host until it is transferred back.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-05_11-54-01_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Overview of memory layout (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Overview of memory layout (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The memory that is allocated on the device is called &lt;strong&gt;global memory&lt;/strong&gt;. It is accessible by all threads on the device. There is also a small amount of &lt;strong&gt;shared memory&lt;/strong&gt; that is accessible by threads within a single block along with a &lt;strong&gt;unified memory&lt;/strong&gt; model.&lt;/p&gt;
&lt;h3 id=&#34;memory-transfer&#34;&gt;Memory Transfer&lt;/h3&gt;
&lt;p&gt;Now that the memory has been allocated, the data can be safely transferred from the host to the device. This is accomplished using &lt;code&gt;cudaMemcpy&lt;/code&gt;. The arguments are the &lt;strong&gt;destination pointer&lt;/strong&gt;, &lt;strong&gt;source pointer&lt;/strong&gt;, &lt;strong&gt;size&lt;/strong&gt;, and &lt;strong&gt;direction&lt;/strong&gt;. The direction is an enumerated type that can be one of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cudaMemcpyHostToDevice&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cudaMemcpyDeviceToHost&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cudaMemcpyDeviceToDevice&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will only focus on the first two for now.&lt;/p&gt;
&lt;h3 id=&#34;grids-blocks-and-threads&#34;&gt;Grids, Blocks, and Threads&lt;/h3&gt;
&lt;p&gt;The CUDA programming model is based on a hierarchy of &lt;strong&gt;grids&lt;/strong&gt;, &lt;strong&gt;blocks&lt;/strong&gt;, and &lt;strong&gt;threads&lt;/strong&gt;. A &lt;strong&gt;grid&lt;/strong&gt; is a collection of &lt;strong&gt;blocks&lt;/strong&gt;. A &lt;strong&gt;block&lt;/strong&gt; is a collection of &lt;strong&gt;threads&lt;/strong&gt;. The number of &lt;strong&gt;blocks&lt;/strong&gt; and &lt;strong&gt;threads&lt;/strong&gt; is defined by the programmer. The number of &lt;strong&gt;blocks&lt;/strong&gt; and &lt;strong&gt;threads&lt;/strong&gt; that can be executed in parallel is limited by the hardware. The number of &lt;strong&gt;blocks&lt;/strong&gt; and &lt;strong&gt;threads&lt;/strong&gt; that can be executed in parallel is called the &lt;strong&gt;grid size&lt;/strong&gt; and &lt;strong&gt;block size&lt;/strong&gt;, respectively.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2024-01-05_11-22-39_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;A single block of 256 threads (source: NVIDIA DLI).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;A single block of 256 threads (source: NVIDIA DLI).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The figure above shows a single block of 256 threads. This could be one of many blocks in a grid. The threads within each block are executed in parallel and do not interact with threads in other blocks. For threads within a single block, there is a small amount of shared memory as well as other tools for communication. We will explore these in more depth as we dive into the details of the CUDA architecture.&lt;/p&gt;
&lt;h3 id=&#34;kernel-execution&#34;&gt;Kernel Execution&lt;/h3&gt;
&lt;p&gt;Calling the kernel function almost looks like any ordinary function call. The main difference is the inclusion of the &lt;code&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/code&gt; and &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; syntax. These are used to specify the size of the grid and blocks, respectively. In this example, we specified that each block has 256 threads. We can use that specification to dynamically determine the number of blocks based on the input size. The number of blocks is computed as the ceiling of the input size divided by the number of threads per block. This ensures that there are enough blocks to cover the entire input size.&lt;/p&gt;
&lt;p&gt;Returning to the kernel function, the thread index is computed using built-in variables &lt;code&gt;blockIdx.x&lt;/code&gt;, &lt;code&gt;blockDim.x&lt;/code&gt;, and &lt;code&gt;threadIdx.x&lt;/code&gt;. These are defined as &lt;code&gt;struct&lt;/code&gt; variables. Modern GPUs have a 3-dimensional grid, but we only need to worry about the first dimension for now. The thread index is computed as the product of the block index and the number of threads per block plus the thread index within the block. This is a common pattern for computing the thread index.&lt;/p&gt;
&lt;p&gt;You may have noticed that it is possible to have more threads than there are blocks. As much as possible, you should try and work with powers of 2. This will ensure that the hardware is used as efficiently as possible. You can always request more threads than there are data points and ignore the threads that are not needed. In this example, we check to see if the thread index is less than the input size. If it is, the vector addition operation is performed. Otherwise, the function exits.&lt;/p&gt;
&lt;p&gt;There are limits to the number of blocks and threads that can be executed in parallel. These limits are based on the compute capability of the device, referenced &lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;compiling&#34;&gt;Compiling&lt;/h3&gt;
&lt;p&gt;CUDA code is compiled using the NVCC compiler driver. It works by compiling host code using the host&amp;rsquo;s native C/C++ compiler and device code to PTX, the CUDA instruction set architecture. Each snippet of code is separated based on the CUDA keyword used to define it. For example, the &lt;code&gt;__global__&lt;/code&gt; keyword used to define the kernel function informs &lt;code&gt;nvcc&lt;/code&gt; that it should be compiled to a PTX file.&lt;/p&gt;
&lt;h2 id=&#34;error-checking&#34;&gt;Error Checking&lt;/h2&gt;
&lt;p&gt;The functions we use in the CUDA API return an error code. We can use this to create robust code that checks for errors and either corrects them or exits gracefully. The following example shows a simple way to check the result of `cudaMalloc`:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;cudaError_t err = cudaMalloc(&amp;amp;x_d, n * sizeof(float));
if (err != cudaSuccess) {
    fprintf(stderr, &amp;#34;Error: %s\n&amp;#34;, cudaGetErrorString(err));
    exit(EXIT_FAILURE);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A common pattern is to define a macro that checks the result of a CUDA function and exits if there is an error. This is shown below.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-cuda&#34; data-lang=&#34;cuda&#34;&gt;#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }
inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true) {
   if (code != cudaSuccess) {
      fprintf(stderr,&amp;#34;GPUassert: %s %s %d\n&amp;#34;, cudaGetErrorString(code), file, line);
      if (abort) exit(code);
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A small note on the above macro, it is technically C++ code. As of writing this, CUDA does not support all features of C++, but much of the code you will see is written as a mix of C and C++. CUDA was originally developed for C, but C++ features have slowly been introduced over time. If you view the &lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;official documentation&lt;/a&gt;, you can see that the link is defined as `cuda-c-programming-guide`, but the actual document has been renamed to `CUDA C++ Programming Guide`.&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t overthink the C/C++ distinction. The main point is that you can use C++ features in your CUDA code, but you should be aware that not all features are supported.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Hwu, Wen-mei W., David B. Kirk, and Izzat El Hajj. 2022. &lt;i&gt;Programming Massively Parallel Processors: A Hands-on Approach&lt;/i&gt;. Fourth. Morgan Kaufmann.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>MapReduce</title>
      <link>https://ajdillhoff.github.io/notes/mapreduce/</link>
      <pubDate>Fri, 24 Nov 2023 00:00:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/mapreduce/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what-is-mapreduce&#34;&gt;What is MapReduce?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hadoop-distributed-file-system--hdfs&#34;&gt;Hadoop Distributed File System (HDFS)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mapreduce-overview&#34;&gt;MapReduce Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hadoop-v2-aka-yarn&#34;&gt;Hadoop v2 AKA YARN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;These are my personal notes from the book &lt;em&gt;Fundamentals of Database Systems&lt;/em&gt; by (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;). I highly recommend reading the original source material. The contents of the article should only serve as a brief overview of the topic.&lt;/p&gt;
&lt;h2 id=&#34;what-is-mapreduce&#34;&gt;What is MapReduce?&lt;/h2&gt;
&lt;p&gt;MapReduce is a programming model for processing large datasets in parallel. It was originally developed by Jeffrey Dean and Sanjay Ghemawat at Google in 2004 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Dean and Ghemawat 2008&lt;/a&gt;). It is based on the functional programming paradigm and is inspired by the map and reduce functions in Lisp and other functional languages. The MapReduce programming model is implemented in the Hadoop framework.&lt;/p&gt;
&lt;p&gt;Hadoop is made up of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hadoop Distributed File System (HDFS)&lt;/li&gt;
&lt;li&gt;Yet Another Resource Negotiator (YARN)&lt;/li&gt;
&lt;li&gt;MapReduce&lt;/li&gt;
&lt;li&gt;Hadoop Common&lt;/li&gt;
&lt;/ul&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-11-26_20-32-30_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Diagram of MapReduce execution (Elmasri and Navathe).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Diagram of MapReduce execution (Elmasri and Navathe).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;example-word-count&#34;&gt;Example: Word Count&lt;/h3&gt;
&lt;p&gt;The classic introductory example for MapReduce is word count, as described in (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Dean and Ghemawat 2008&lt;/a&gt;). Let&amp;rsquo;s say we have a collection of text documents that we want to preprocess for a Natural Language Processing pipeline. One of the first steps is to count the number of times each word appears in the corpus. This is a simple task that can be done in a single machine, but let&amp;rsquo;s assume that the corpus is too large to fit in memory on a single machine. We can use MapReduce to distribute the work across multiple machines.&lt;/p&gt;
&lt;p&gt;The problem is split into two steps: map and reduce. Each step is represented as a function that can run on any arbitrary number of nodes. For now, we will not worry about how the original data is split up efficiently. Instead, assume that each machine gets a single document.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt;(doc):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; doc:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        emit(word, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reduce&lt;/span&gt;(word, counts):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    emit(word, sum(counts))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The map function takes a document and emits a key-value pair for each word in the document. The key is the word and the value is 1. The reduce function takes a word and a list of counts and emits a key-value pair with the word and the sum of the counts. The output of the map function is a list of key-value pairs that are grouped by key. The reduce function is then applied to each group of key-value pairs.&lt;/p&gt;
&lt;h2 id=&#34;hadoop-distributed-file-system--hdfs&#34;&gt;Hadoop Distributed File System (HDFS)&lt;/h2&gt;
&lt;p&gt;Store metadata and application data on different nodes.
Metadata is stored on the NameNode.
Application data is stored on DataNodes. This data is replicated across multiple DataNodes.
HDFS uses primary-secondary architecture. The NameNode is the primary and the DataNodes are the secondaries.
DataNodes are typically partitioned into 1 node per machine.
NameNodes maintain inodes about file and directories. These inodes are used to map file blocks to DataNodes.
NameNodes instruct the DataNodes to create, delete, and replicate blocks.
Data is retrieved by contacting the NameNode to get the block locations and then contacting the DataNodes directly.&lt;/p&gt;
&lt;h3 id=&#34;namenode&#34;&gt;NameNode&lt;/h3&gt;
&lt;p&gt;Maintain an image of the file system.
Maintain a journal of changes to the file system.&lt;/p&gt;
&lt;p&gt;Secondary NameNodes are used to create checkpoints of the NameNode&amp;rsquo;s state.&lt;/p&gt;
&lt;h3 id=&#34;datanode&#34;&gt;DataNode&lt;/h3&gt;
&lt;p&gt;Periodically send heartbeats to the NameNode to indicate their current state (BlockReport).
Block locations are not part of the namespace image.
BlockReports are used by services like the MapReduce JobTracker to determine where to schedule tasks.&lt;/p&gt;
&lt;h3 id=&#34;file-i-o-operations&#34;&gt;File I/O Operations&lt;/h3&gt;
&lt;p&gt;HDFS is single-writer, multiple-reader.
A file consists of blocks.
Data that is written on the last block becomes available after an hflush operation.&lt;/p&gt;
&lt;h2 id=&#34;mapreduce-overview&#34;&gt;MapReduce Overview&lt;/h2&gt;
&lt;p&gt;MapReduce is also a primary-secondary architecture.
The JobTracker is the primary process and the TaskTrackers are the secondaries.&lt;/p&gt;
&lt;h3 id=&#34;jobtracker&#34;&gt;JobTracker&lt;/h3&gt;
&lt;p&gt;Manages life cycles of jobs and schedules tasks on the cluster.&lt;/p&gt;
&lt;h4 id=&#34;job-submission&#34;&gt;Job Submission&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Gets a new ID from the job tracker.&lt;/li&gt;
&lt;li&gt;Verifies output specifications.&lt;/li&gt;
&lt;li&gt;Computes input splits for the job.&lt;/li&gt;
&lt;li&gt;Copies any resources needed to run the job.&lt;/li&gt;
&lt;li&gt;Informs the job tracker that it is ready for execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;job-initialization&#34;&gt;Job Initialization&lt;/h4&gt;
&lt;p&gt;When a job is initialized, it is placed in a queue with all information related to executing and tracking the job. A map task is created for each of the input splits. Further, a job setup and cleanup task are created.&lt;/p&gt;
&lt;h4 id=&#34;task-assignment&#34;&gt;Task Assignment&lt;/h4&gt;
&lt;p&gt;Each TaskTracker periodically sends a &lt;em&gt;heartbeat&lt;/em&gt; to the JobTracker with status updates. These inform the JobTracker that it is alive or is able to run a new task. When a TaskTracker is ready to run a new task, the JobTracker will allocate a new one by selecting it using some defined scheduler. There is a default scheduler that will pick based on priority, but a custom scheduler can be given to the job.&lt;/p&gt;
&lt;p&gt;Another consideration for assigning is a map task is &lt;strong&gt;data locality&lt;/strong&gt;. Map tasks are based on the input splits, so the JobTracker will try to run the task on the same node that the data is located. If this is not possible, it will prioritize based on the distance between the node and the data. For reduce tasks, there are no locality considerations.&lt;/p&gt;
&lt;h4 id=&#34;task-execution&#34;&gt;Task Execution&lt;/h4&gt;
&lt;p&gt;When a task is executed, any pertinent information is copied from the shared filesystem to a local filesystem. A JVM is launched to run each task so that any errors will only affect the JVM and not the entire TaskTracker. The JVM will run the task and then report back to the JobTracker with status updates.&lt;/p&gt;
&lt;h4 id=&#34;job-completion&#34;&gt;Job Completion&lt;/h4&gt;
&lt;p&gt;A job is completed once the last task is finished. In this case, a job cleanup task is run to clean up any resources used by the job.&lt;/p&gt;
&lt;h3 id=&#34;tasktracker&#34;&gt;TaskTracker&lt;/h3&gt;
&lt;p&gt;TaskTrackers run one per worker node on a cluster. Both map and reduce tasks run on Worker nodes. When a TaskTracker is started, it registers with the JobTracker so that the JobTracker can assign tasks to it. The actual task is run in a separate process on the Worker node which is managed by the TaskTracker.&lt;/p&gt;
&lt;h3 id=&#34;fault-tolerance&#34;&gt;Fault Tolerance&lt;/h3&gt;
&lt;p&gt;In Hadoop v1, three types of failures must be considered. The first two are the TaskTracker and JobTracker. The third is the spawned process that runs the task on the TaskTracker.&lt;/p&gt;
&lt;h4 id=&#34;task-failure&#34;&gt;Task Failure&lt;/h4&gt;
&lt;p&gt;Tasks can fail due to bad input, faulty code, hardware failure, or some other run time error. When an individual task fails, the error is logged and the failure is reported back to the parent TaskTracker. Since the TaskTracker is still running, it can notify the JobTracker that it is free to run another task.&lt;/p&gt;
&lt;p&gt;There is also a default timeout duration for tasks that are not making progress. If a task exceeds this timeout, it is killed and the TaskTracker is notified. The default timeout is 10 minutes but can be configured by the user. There are also settings dictating how many times a task can fail before the job is considered failed or the percentage of tasks that can fail before the job is considered failed. There may be circumstances in which task failures are acceptable as long as some of the work is completed.&lt;/p&gt;
&lt;h4 id=&#34;tasktracker-failure&#34;&gt;TaskTracker Failure&lt;/h4&gt;
&lt;p&gt;TaskTrackers that fail or are unresponsive past the heartbeat timeout are considered dead. The JobTracker will remove it from its pool of trackers to schedule tasks on. Tasks that were completed or in progress on the failed TaskTracker are rescheduled since the intermediate data is no longer available.&lt;/p&gt;
&lt;p&gt;TaskTrackers that fail repeatedly are added to a blacklist and are not used for scheduling tasks. This can occur if the TaskTracker is not configured correctly or if the TaskTracker is running on faulty hardware.&lt;/p&gt;
&lt;h4 id=&#34;jobtracker-failure&#34;&gt;JobTracker Failure&lt;/h4&gt;
&lt;p&gt;The JobTracker is a single point of failure in Hadoop v1. If the JobTracker fails, all jobs that are running or waiting to run are lost. The rate of failure is typically low since the chance that a single machine fails is low. If it does fail, a restart is attempted and all running jobs need to be restarted.&lt;/p&gt;
&lt;h3 id=&#34;shuffle-and-sort&#34;&gt;Shuffle and Sort&lt;/h3&gt;
&lt;p&gt;The shuffle and sort phase is a key process which defines how data is moved from the map tasks to the reduce tasks. Data may be split among many map tasks, but reducers get all rows for a given key together. The shuffle and sort phase is responsible for this. It is split up into three phases.&lt;/p&gt;
&lt;h4 id=&#34;map-phase&#34;&gt;Map Phase&lt;/h4&gt;
&lt;p&gt;Output from the map tasks is stored in memory in a circular buffer. Once that buffer becomes full, it spills over to the disk. Before going to the disk, it is partitioned based on the reducer that it will ultimately be sent to. This acts as a sort of pre-sorting to optimize the shuffle and sort phase.&lt;/p&gt;
&lt;p&gt;Depending on the setting for the size of spill files, the map phase may produce multiple spill files. These files are merged into a single file before being sent to the reducers. The final result is a single file per reducer that is sorted by key.&lt;/p&gt;
&lt;h4 id=&#34;copy-phase&#34;&gt;Copy Phase&lt;/h4&gt;
&lt;p&gt;The data needed by a particular reducer task is split up among many map tasks. The copy phase is responsible for copying the data from the map tasks to the reducer tasks. The reducer will begin copying as data is made available by the map tasks, even if all map tasks have not been completed.&lt;/p&gt;
&lt;p&gt;Copies can be executed in parallel via threading. The JobTracker is responsible for assigning the reducers to the map tasks so that the data is copied to the correct reducer. When all map tasks have completed, the reducer will begin the reduce phase.&lt;/p&gt;
&lt;h4 id=&#34;reduce-phase&#34;&gt;Reduce Phase&lt;/h4&gt;
&lt;p&gt;In this phase, data is merged while maintaining their sorted order. The reduce function is this executed for each key in the sorted output. The output is written directly to the &lt;em&gt;output filesystem&lt;/em&gt;, which is commonly HDFS.&lt;/p&gt;
&lt;h3 id=&#34;types-of-schedulers&#34;&gt;Types of Schedulers&lt;/h3&gt;
&lt;p&gt;Early versions of Hadoop used a simple FIFO scheduler. This scheduler would run jobs in the order that they were submitted. This is not ideal since it does not take into account the size of the job or the priority of the job. A job that is submitted after a large job will have to wait until the large job is completed. Considering longer running jobs like machine learning training, a better scheduler is needed.&lt;/p&gt;
&lt;h4 id=&#34;the-fair-scheduler&#34;&gt;The Fair Scheduler&lt;/h4&gt;
&lt;p&gt;The fair scheduler aims to give every user an equal amount of cluster capacity over time. This allows multiple jobs to be running simultaneously. The scheduler does this by placing jobs in &lt;em&gt;pools&lt;/em&gt; assigned to each user. This allows short jobs to run without waiting for long jobs to complete.&lt;/p&gt;
&lt;p&gt;The fair scheduler also supports &lt;em&gt;preemption&lt;/em&gt;. This allows the scheduler to kill tasks that are running for too long to make room for other jobs. This is useful for long running jobs that are not making progress. Note that this does not kill the entire job. The tasks that are killed are rescheduled on other TaskTrackers.&lt;/p&gt;
&lt;h4 id=&#34;the-capacity-scheduler&#34;&gt;The Capacity Scheduler&lt;/h4&gt;
&lt;p&gt;In capacity scheduling, a cluster is divided into multiple queues. Each queue is assigned some amount of cluster capacity. These queues are hierarchical, so a queue can be assigned to a user or a group of users. This allows for more fine grained control over the cluster capacity. In effect, this allows for multiple clusters to be managed by a single cluster.&lt;/p&gt;
&lt;h3 id=&#34;merging-database-functions-and-mapreduce&#34;&gt;Merging Database Functions and MapReduce&lt;/h3&gt;
&lt;p&gt;The power of MapReduce was apparent, but all operations had to be framed in the context of a mapping and reduce functions. This made it difficult or tedious to perform common database operations. Several projects were started to bridge the gap between MapReduce and databases.&lt;/p&gt;
&lt;h4 id=&#34;apache-pig&#34;&gt;Apache Pig&lt;/h4&gt;
&lt;p&gt;Developed by Yahoo, Pig Latin is a high level language that glues together SQL and MapReduce. It was not meant to replace SQL. In fact, the authors note that people in data analysis fine SQL to be unnatural for data analysis. Their work was mean to provide something that meets the declarative style of SQL and procedural style of MapReduce. Consider their opening example.&lt;/p&gt;
&lt;p&gt;Given a table of &lt;code&gt;urls&lt;/code&gt;: &lt;code&gt;(url, category, pagerank)&lt;/code&gt;, find the average pagerank of high-pagerank urls in that category. In SQL, a query might look like this.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; category, AV &lt;span style=&#34;color:#66d9ef&#34;&gt;G&lt;/span&gt;(pagerank)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; urls
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; pagerank &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; category
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;HAVING&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An equivalent query in Pig Latin would look like this.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-pig&#34; data-lang=&#34;pig&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;good_urls &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FILTER&lt;/span&gt; urls &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; pagerank &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;groups &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; good_urls &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; category;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;big_groups &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FILTER&lt;/span&gt; groups &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; COUNT(good_urls) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;**6;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;output&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FOREACH&lt;/span&gt; big_groups &lt;span style=&#34;color:#66d9ef&#34;&gt;GENERATE&lt;/span&gt; category, AVG(good_urls.pagerank);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Each statement in Pig Latin describes a data transformation. These statements are converted into an ensemble of MapReduce jobs, but each statement is not necessarily a single MapReduce job. The Pig Latin compiler is responsible for optimizing the statements.&lt;/p&gt;
&lt;h4 id=&#34;apache-hive&#34;&gt;Apache Hive&lt;/h4&gt;
&lt;p&gt;Hive was developed at Facebook to provide an SQL-like interface for processing queries on big data. In addition to providing a high-level language, it also treats Hadoop like a DBMS. This allows users to impose structure on the data and query it using as if it were a traditional database.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-11-26_16-11-09_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Hive Architecture (Elmasri and Navathe).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Hive Architecture (Elmasri and Navathe).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Hive comes with a query-based language called HiveQL that includes joints, aggregations, and other common SQL operations. The tables in Hive are linked directly to directories in HDFS. This allows for data to be loaded into Hive from HDFS and vice versa. Hive also supports partitioning and bucketing to improve performance. Bucketing stores the data physically in the same file, partitioned by the bucketing key.&lt;/p&gt;
&lt;h3 id=&#34;advantages-of-hadoop-mapreduce&#34;&gt;Advantages of Hadoop/MapReduce&lt;/h3&gt;
&lt;p&gt;Consider scanning a 100 TB dataset using a single machine. At a rate of 50 Mbps, this would take around 24 days. Using 1000 machines in parallel would reduce this to about 30 minutes. The resources available can be scaled easily by adding more machines to the cluster. In the event that a machine fails, the tasks can be reassigned to other machines without losing the job completely.&lt;/p&gt;
&lt;h2 id=&#34;hadoop-v2-aka-yarn&#34;&gt;Hadoop v2 AKA YARN&lt;/h2&gt;
&lt;p&gt;Hadoop v1 was well received and solved many of the problems efficiently through its MapReduce programming model. However, many problems arise naturally as the size of the cluster grows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The JobTracker is a single point of failure. As the cluster size increases, this becomes more of an issue.&lt;/li&gt;
&lt;li&gt;Resources are allocated statically, resulting in a large amount of unused compute when processing jobs.&lt;/li&gt;
&lt;li&gt;Not every job fits cleanly into the MapReduce programming model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to these issues, YARN aims to improve scalability, resource utilization, and flexibility. By increasing the availability of nodes at any given time, there are less wasted resources on a cluster. This is especially useful in enterprise-level clusters where there are many users and jobs running at any given time.&lt;/p&gt;
&lt;p&gt;Supporting multiple programming models also aids to this scalability. Consider a machine learning model being trained for long periods of time. In Hadoop v1, developers would frame these as MapReduce jobs. A major problem with this is that after the original update, the jobs would exchange data outside of the purview of the JobTracker. This also means that the fault tolerance features built into Hadoop v1 were not available for these jobs.&lt;/p&gt;
&lt;h3 id=&#34;architecture&#34;&gt;Architecture&lt;/h3&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-11-26_18-08-55_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Hadoop v1 vs. YARN Architecture (Elmasri and Navathe).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Hadoop v1 vs. YARN Architecture (Elmasri and Navathe).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h4 id=&#34;resourcemanager&#34;&gt;ResourceManager&lt;/h4&gt;
&lt;p&gt;The ResourceManager is the master process in YARN. It is responsible for allocating resources to applications and scheduling tasks. Allocations are based on the chosen scheduler. ApplicationMasters will request resources from the ResourceManager. The ResourceManager will then allocate resources to the ApplicationMaster and notify the NodeManager to start the containers.&lt;/p&gt;
&lt;p&gt;Since the ResourceManager is only responsible for scheduling the available resources, different applications can make use of the same cluster at the same time. This is a major improvement over Hadoop v1 where the JobTracker was responsible for scheduling all jobs.&lt;/p&gt;
&lt;h4 id=&#34;nodemanager&#34;&gt;NodeManager&lt;/h4&gt;
&lt;p&gt;The NodeManager runs on every worker node in the cluster. It launches and monitors containers on the node as well as reports the resource utilization back to the ResourceManager. It additionally provides services to Containers such as security, logging, and local file management.&lt;/p&gt;
&lt;h4 id=&#34;applicationmaster&#34;&gt;ApplicationMaster&lt;/h4&gt;
&lt;p&gt;The ApplicationMaster manages the execution of an application&amp;rsquo;s processes. These applications can range from a traditional MapReduce job to a long-running machine learning model. The ApplicationMaster is responsible for negotiating resources with the ResourceManager and working with the NodeManager to execute and monitor the containers. It sends resource status updates to the ResourceManager as requirements change.&lt;/p&gt;
&lt;h4 id=&#34;container&#34;&gt;Container&lt;/h4&gt;
&lt;p&gt;A container is a collection of resources allocated to an application. These resources are allocated by the ResourceManager and managed by the NodeManager. These resources refer directly to the resources available on the node. This includes CPU, memory, disk, and network.&lt;/p&gt;
&lt;h3 id=&#34;fault-tolerance&#34;&gt;Fault Tolerance&lt;/h3&gt;
&lt;p&gt;The ResourceManager is a single point of failure in YARN. If it fails, it can restart and recover its state. Any containers in the cluster are killed and restarted. The ApplicationMaster is responsible for restarting any tasks that were running in the containers.&lt;/p&gt;
&lt;h3 id=&#34;execution-flow&#34;&gt;Execution Flow&lt;/h3&gt;
&lt;p&gt;The following gives an example of how a typical MapReduce job would be executed in YARN.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The client submits a job to the ResourceManager.&lt;/li&gt;
&lt;li&gt;The ResourceManager allocates a container for the ApplicationMaster and launches the ApplicationMaster on a NodeManager.&lt;/li&gt;
&lt;li&gt;The ApplicationMaster negotiates resources with the ResourceManager.&lt;/li&gt;
&lt;li&gt;The ResourceManager allocates containers for the MapReduce tasks and launches them on the NodeManagers.&lt;/li&gt;
&lt;li&gt;The MapReduce tasks are executed in the containers.&lt;/li&gt;
&lt;li&gt;The ApplicationMaster monitors the MapReduce tasks and reports status updates to the ResourceManager.&lt;/li&gt;
&lt;li&gt;When the job is complete, the ApplicationMaster is unregistered and the containers are released.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Dean, Jeffrey, and Sanjay Ghemawat. 2008. MapReduce: Simplified Data Processing on Large Clusters. &lt;i&gt;Communications of the Acm&lt;/i&gt; 51 (1): 10713. &lt;a href=&#34;https://doi.org/10.1145/1327452.1327492&#34;&gt;https://doi.org/10.1145/1327452.1327492&lt;/a&gt;.&lt;/div&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_2&#34;&gt;&lt;/a&gt;Elmasri, Ramez, and Shamkant B. Navathe. 2015. &lt;i&gt;Fundamentals of Database Systems&lt;/i&gt;. 7th ed. Pearson. &lt;a href=&#34;https://www.pearson.com/en-us/subject-catalog/p/fundamentals-of-database-systems/P200000003546/9780137502523&#34;&gt;https://www.pearson.com/en-us/subject-catalog/p/fundamentals-of-database-systems/P200000003546/9780137502523&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Distributed Databases</title>
      <link>https://ajdillhoff.github.io/notes/distributed_databases/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/distributed_databases/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-fragmentation&#34;&gt;Data Fragmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-replication&#34;&gt;Data Replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-concurrency&#34;&gt;Data Concurrency&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;Distributed systems excel at partitioning large problems into smaller chunks that can be processed in parallel. This requires parallel thinking instead of serial thinking. Many algorithms and solutions that run serially may be easier to adapt to parallel applications than others.&lt;/p&gt;
&lt;p&gt;Distributed solutions are the natural next step to scaling up a system. In the context of databases, the main challenges related to distribution, replication, distributed transactions, distributed metadata management, and distributed query processing.&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;According to Elmasri and Navathe (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;), a distributed database should satisfy &lt;em&gt;at least&lt;/em&gt; the following conditions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;database nodes should be connected by a network,&lt;/li&gt;
&lt;li&gt;the information on each node should be logically related,&lt;/li&gt;
&lt;li&gt;and each node does not necessarily need to be identicaly in terms of data, hardware, and software.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;transparency&#34;&gt;Transparency&lt;/h3&gt;
&lt;p&gt;Transparency is the concept of hiding the complex details of a distributed database from the user. There are several types of transparency:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Distribution transparency&lt;/strong&gt;&lt;/strong&gt; - the user does not need to know how the data is distributed across the nodes. This could refer to the location of the data, the replication of the data, or the fragmentation of the data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Replication transparency&lt;/strong&gt;&lt;/strong&gt; - data may be stored in multiple nodes. This type of transparency improves availability by allowing the system to continue operating even if a node goes down.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Fragmentation transparency&lt;/strong&gt;&lt;/strong&gt; - data is either horizontally or vertically fragmented across nodes. Horizontal fragmentation, also called &lt;strong&gt;&lt;strong&gt;sharding&lt;/strong&gt;&lt;/strong&gt;, refers to decomposing tuples of a table into multiple systems. For example, we could horizontally fragment our &lt;code&gt;Character&lt;/code&gt; table based on the &lt;code&gt;class_id&lt;/code&gt;. Vertical fragmentation refers to decomposing the columns of a table into multiple systems. For example, we could vertically fragment our &lt;code&gt;Character&lt;/code&gt; table into a &lt;code&gt;Character&lt;/code&gt; table and a &lt;code&gt;CharacterStats&lt;/code&gt; table.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;availability-and-reliability&#34;&gt;Availability and Reliability&lt;/h3&gt;
&lt;p&gt;Having more than one point of failure means that a distributed database is more &lt;strong&gt;reliable&lt;/strong&gt; than a centralized database. With technologies like replication, the &lt;strong&gt;availability&lt;/strong&gt; of the database also increases.&lt;/p&gt;
&lt;h3 id=&#34;scalability&#34;&gt;Scalability&lt;/h3&gt;
&lt;p&gt;Scalability in a database that is distributed over multiple nodes can be categorized into two types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Horizontal scalability&lt;/strong&gt;&lt;/strong&gt; - adding more nodes to the system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Vertical scalability&lt;/strong&gt;&lt;/strong&gt; - adding more resources to the nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A centralized database can only support vertical scalability. If it goes down or is fragmented from a portion of a broader network, the data is no longer accessible. In a distributed system, the nodes can be partitioned into smaller networks that can still operate independently depending on the type of failure. This is called &lt;strong&gt;&lt;strong&gt;partition tolerance&lt;/strong&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;autonomy&#34;&gt;Autonomy&lt;/h3&gt;
&lt;p&gt;Autonomy refers to the ability of a node to operate independently of other nodes. This is important for distributed systems because it allows for the system to continue operating even if a node goes down.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Design autonomy&lt;/strong&gt; - Data model usage and transaction managament are independent of other nodes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Communication autonomy&lt;/strong&gt; - Nodes can communicate with each other without the need for a central coordinator.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Execution autonomy&lt;/strong&gt; - Nodes can execute transactions independently of other nodes. While this type of autonomy leads to more availability and higher performance, it can also create problems with consistency since nodes may not be able to agree on the order of operations.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;data-fragmentation&#34;&gt;Data Fragmentation&lt;/h2&gt;
&lt;p&gt;As mentioned at the beginning of these notes, breaking up a problem into smaller chunks is the key to parallelism. In the context of databases, this means figuring out which nodes have which portions of the data. We will discuss fragmentation under the assumption that no data replication is being used.&lt;/p&gt;
&lt;h3 id=&#34;horizontal-fragmentation--sharding&#34;&gt;Horizontal Fragmentation (Sharding)&lt;/h3&gt;
&lt;p&gt;Imagine a scenario in which we shard our &lt;code&gt;Users&lt;/code&gt; table based on the geographic location of their IP address. If we have 3 nodes in (west coast, central, east coast), then we can separate our table into 3 tables, one for each region. This is called &lt;strong&gt;&lt;strong&gt;horizontal fragmentation&lt;/strong&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;strong&gt;sharding&lt;/strong&gt;&lt;/strong&gt;. The main advantage of sharding is that it allows us to scale horizontally. The main disadvantage is that it makes it more difficult to perform queries that require data from multiple regions.&lt;/p&gt;
&lt;h3 id=&#34;vertical-fragmentation&#34;&gt;Vertical Fragmentation&lt;/h3&gt;
&lt;p&gt;Vertical fragmentation can make sense when we have a table with a large number of columns. For example, we could vertically fragment our &lt;code&gt;Users&lt;/code&gt; table into a &lt;code&gt;Users&lt;/code&gt; table and a &lt;code&gt;UserStats&lt;/code&gt; table. When vertically fragmenting data, there should be a common attribute between the two tables. In this case, the &lt;code&gt;user_id&lt;/code&gt; would be the common attribute.&lt;/p&gt;
&lt;h2 id=&#34;data-replication&#34;&gt;Data Replication&lt;/h2&gt;
&lt;p&gt;Data replication is the process of storing the same data in multiple nodes. There are obvious tradeoffs when it comes to selecting a replication strategy. First, let&amp;rsquo;s consider the extreme cases. If no replication is used, then the system is more consistent since there is only one copy of the data. The availability suffers, however, since there is only a single copy of the data.&lt;/p&gt;
&lt;p&gt;If the data is replicated to every single node, then the availability and performance of the system increases. However, the consistency of the system suffers since there are multiple copies of the data that need to be kept in sync. Picking a replication strategy will largely depend on the needs of the application. Deciding how this data is fragmented is the process of &lt;strong&gt;data distribution&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;
&lt;p&gt;The following example is from Elmasri and Navathe (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;). In this example, a company has three nodes for each of its departments. Node 2 stores data for the &lt;code&gt;Research&lt;/code&gt; department and Node 3 stores data for the &lt;code&gt;Administration&lt;/code&gt; department. The idea behind this is that the &lt;code&gt;EMPLOYEE&lt;/code&gt; and &lt;code&gt;PROJECT&lt;/code&gt; information for each department will be frequently accessed by that department. This would be more efficient than having to access the data from a centralized database. Node 1 is located at the company&amp;rsquo;s headquarters and includes data for all departments.&lt;/p&gt;
&lt;p&gt;The data in the &lt;code&gt;DEPARTMENT&lt;/code&gt; table is horizontally fragmented using the department number &lt;code&gt;Dnumber&lt;/code&gt;. Since there are foreign key relationships in &lt;code&gt;EMPLOYEE&lt;/code&gt;, &lt;code&gt;PROJECT&lt;/code&gt;, and &lt;code&gt;DEPT_LOCATIONS&lt;/code&gt;, they are also fragmented. This is a special type of fragmentation called &lt;strong&gt;derived fragmentation&lt;/strong&gt;. These are easier to fragment since they have a direct foreign key relationship.&lt;/p&gt;
&lt;p&gt;A more difficulty decision comes with the &lt;code&gt;WORKS_ON&lt;/code&gt; table. It does not have an attribute that indicates which department each tuple belongs to. The authors choose to fragment based on the department that the employee works for. This is further fragmented based on the department that controls the projects that the employee is working on.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-11-14_18-41-42_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Fragmentation of `WORKS_ON` table for department 5. &amp;lt;@elmasri_fundamentals_2015&amp;gt;&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Fragmentation of &lt;code&gt;WORKS_ON&lt;/code&gt; table for department 5. &amp;lt;@elmasri_fundamentals_2015&amp;gt;
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;In the figure above, all of the fragments include employees of the research department. The first fragment includes employees that work on projects controlled by the research department. The second fragment includes employees that work on projects controlled by the administration department. The third fragment includes employees that work on projects controlled by headquarters.&lt;/p&gt;
&lt;h2 id=&#34;data-concurrency&#34;&gt;Data Concurrency&lt;/h2&gt;
&lt;p&gt;Distributed systems that employ data replication or allow for multiple users to access the same data at the same time need to be concerned with data concurrency. This is the process of ensuring that the data remains consistent when multiple users are accessing the same data at the same time. Several problems can occur in a DDBMS, such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;inconsistency between multiple copies of the data,&lt;/li&gt;
&lt;li&gt;failure of a node,&lt;/li&gt;
&lt;li&gt;network outages that sever the connection between nodes,&lt;/li&gt;
&lt;li&gt;failure of a transaction that is applied to multiple nodes,&lt;/li&gt;
&lt;li&gt;and deadlocks between transactions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;concurrency-control&#34;&gt;Concurrency Control&lt;/h3&gt;
&lt;p&gt;Many control solutions for distributed systems are based on the idea of a centralized &lt;strong&gt;locking&lt;/strong&gt; authority. This authority is responsible for granting locks to transactions that request them. The authority is also responsible for granting access to data that is locked by other transactions. When an object is locked, it cannot be accessed by other transactions.&lt;/p&gt;
&lt;p&gt;In this case, the &lt;em&gt;central authority&lt;/em&gt; may be a &lt;strong&gt;distinguished copy&lt;/strong&gt; of the data. All requests to lock or unlock are sent to that copy.&lt;/p&gt;
&lt;h4 id=&#34;primary-site-technique&#34;&gt;Primary Site Technique&lt;/h4&gt;
&lt;p&gt;All locks are kept at a primary site. This site is responsible for granting locks to transactions that request them. The primary site is also responsible for granting access to data that is locked by other transactions. This is a simple technique that is easy to implement. However, it is not very scalable since all requests must go through the primary site. Note that this does not prevent transactions with read locks from accessing any copy of the item. If a transaction has a write lock, the primary site must update all copies of the data before releasing the lock.&lt;/p&gt;
&lt;h4 id=&#34;primary-site-with-backup&#34;&gt;Primary Site with Backup&lt;/h4&gt;
&lt;p&gt;If the primary site fails in the first approach, the system effectively becomes unavailable. To prevent this, we can have a backup primary site that takes over if the primary site fails. This is a simple solution that is easy to implement. If the primary site fails in this case, a backup takes over and becomes the new primary. A new backup is chosen so that the system can continue to operate. One downside to this approach is that locks must be recorded at both the primary and backup sites.&lt;/p&gt;
&lt;h4 id=&#34;primary-copy-technique&#34;&gt;Primary Copy Technique&lt;/h4&gt;
&lt;p&gt;Lock coordination is distributed among various sites. Distinguished copies for different items are distributed to different sites. A failure at one site would only affect the transactions that are accessing its distinguished copies. Other items not on the site would remain functional. In the case of a failure, the sites that are still running can choose a new coordinator based on some strategy. One such strategy is to have all running sites vote on a new coordinator. The site with the most votes becomes the new coordinator.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Elmasri, Ramez, and Shamkant B. Navathe. 2015. &lt;i&gt;Fundamentals of Database Systems&lt;/i&gt;. 7th ed. Pearson. &lt;a href=&#34;https://www.pearson.com/en-us/subject-catalog/p/fundamentals-of-database-systems/P200000003546/9780137502523&#34;&gt;https://www.pearson.com/en-us/subject-catalog/p/fundamentals-of-database-systems/P200000003546/9780137502523&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>NOSQL</title>
      <link>https://ajdillhoff.github.io/notes/nosql/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 -0600</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/nosql/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#nosql-characteristics-for-distributed-systems&#34;&gt;NOSQL Characteristics for Distributed Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nosql-data-models&#34;&gt;NOSQL Data Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cap-theorem&#34;&gt;CAP Theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#document-based-nosql-systems&#34;&gt;Document-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#key-value-nosql-systems&#34;&gt;Key-Value NOSQL Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#column-based-nosql-systems&#34;&gt;Column-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#graph-based-nosql-systems&#34;&gt;Graph-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;&lt;strong&gt;NOSQL&lt;/strong&gt; refers to Not Only SQL. A NOSQL system is commonly a distributed one that focuses on semi-structured data storage, high performance, availability, replication and scalability. These type of systems developed to meet the needs of large-scale internet applications where a traditional SQL database could not.&lt;/p&gt;
&lt;p&gt;Consider an application like Amazon which manages a high volume of data and user requests. The application needs to be able to store and retrieve this data quickly and reliably. They created their own database system called DynamoDB which is a key-value store. DynamoDB has been used for many applications that require high performance and availability such as video streaming through services like Disney+.&lt;/p&gt;
&lt;p&gt;The data that is used in these systems does not usually fit the mold of a traditional SQL database. For example, a relational database might store an object by disassembling it into its components and storing each component in a separate table. This is not ideal for a system that needs to store and retrieve data quickly. A NOSQL system will store the object as a whole and retrieve it as a whole.&lt;/p&gt;
&lt;h2 id=&#34;nosql-characteristics-for-distributed-systems&#34;&gt;NOSQL Characteristics for Distributed Systems&lt;/h2&gt;
&lt;p&gt;Given the nature of the applications that utilize NOSQL systems, the most important characteristic is high availability. Of course, performance is also important given the number of users that expect the service to remain responsive at all times.&lt;/p&gt;
&lt;h3 id=&#34;scalability&#34;&gt;Scalability&lt;/h3&gt;
&lt;p&gt;NOSQL systems typically aim for horizontal scalability. The applications that use these systems are expected to grow rapidly and the system needs to be able to handle the increased load. This sort of dynamic scaling means that implementations should not rely on a fixed number of nodes.&lt;/p&gt;
&lt;p&gt;For example, during the holiday season, Amazon will need to rapidly scale up their infrastructure to handle the increased load. Cloud technologies are capable of doing this automatically, but the database system needs to be able to handle the increased load as well.&lt;/p&gt;
&lt;h3 id=&#34;availability&#34;&gt;Availability&lt;/h3&gt;
&lt;p&gt;NOSQL systems are expected to be highly available. This means that the system should be able to handle failures and continue to operate. Data is typically replicated over multiple nodes. However, this replication comes with increased complexity for writing data. To deal with this, many NOSQL systems implement a relaxed version called &lt;strong&gt;eventual consistency&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;replication-models&#34;&gt;Replication Models&lt;/h3&gt;
&lt;p&gt;There are two main replication models for NOSQL systems: &lt;strong&gt;primary-replica&lt;/strong&gt; and &lt;strong&gt;primary-primary&lt;/strong&gt;. In primary-replica replication, only one copy is the primary for which all write operations are applied. The write is propagated asynchronously to the replicas.&lt;/p&gt;
&lt;p&gt;In primary-primary replication, all copies are equal and can accept write operations. This is more complex to implement, but it allows for better performance and availability. If multiple users write to the same object, the system needs to be able to handle the conflict through a reconciliation process.&lt;/p&gt;
&lt;h3 id=&#34;sharding&#34;&gt;Sharding&lt;/h3&gt;
&lt;p&gt;Depending on the application, a NOSQL collection could have millions of documents. These may need to be accessed simultaneously by a large number fo users. &lt;strong&gt;Sharding&lt;/strong&gt; is a technique that allows the data to be distributed across multiple nodes. In this way, multiple nodes can work in parallel to handle the load. This has an added benefit of ensuring that no single node is overloaded.&lt;/p&gt;
&lt;h3 id=&#34;high-performance-data-access&#34;&gt;High-Performance Data Access&lt;/h3&gt;
&lt;p&gt;In a distributed system with millions upon millions of objects distributed across many nodes, how do you find the object you are looking for? NOSQL systems typically use a &lt;strong&gt;hash-based&lt;/strong&gt; approach to find the object. This is done by hashing the key of the object and using the hash to determine which node the object is stored on. This is a very fast operation and allows for the system to scale to millions of objects.&lt;/p&gt;
&lt;p&gt;Another solution is called &lt;strong&gt;range partitioning&lt;/strong&gt; in which the location is determined based on a range of key values. Each node would handle a different partition of the keys.&lt;/p&gt;
&lt;h3 id=&#34;other-characteristics&#34;&gt;Other Characteristics&lt;/h3&gt;
&lt;p&gt;NOSQL systems do not require a schema. This means that the data does not need to be structured in a specific way. This is useful for applications that need to store a variety of data types. For example, a social media application might need to store user profiles, posts, comments, etc. These are all different types of data that would not fit well into a relational database. Instead of a schema, a language for describing the data is used. A common language is JSON.&lt;/p&gt;
&lt;p&gt;Given the common application of NOSQL systems, a complex query language is not required. Many of the requests are in the form of a simple read or write operation. This allows for the system to be optimized for these operations. These operations are typically provided by an API and are called &lt;strong&gt;CRUD operations&lt;/strong&gt; (Create, Read, Update, and Delete). Without the full power of SQL, complex operations such as &lt;code&gt;JOIN&lt;/code&gt; or &lt;code&gt;CONSTRAINTS&lt;/code&gt; must be handled by the application.&lt;/p&gt;
&lt;h2 id=&#34;nosql-data-models&#34;&gt;NOSQL Data Models&lt;/h2&gt;
&lt;p&gt;There are four main data models used by NOSQL systems: &lt;strong&gt;key-value&lt;/strong&gt;, &lt;strong&gt;column&lt;/strong&gt;, &lt;strong&gt;document&lt;/strong&gt;, and &lt;strong&gt;graph&lt;/strong&gt;. Each of these models has its own advantages and disadvantages. The model that is chosen depends on the application and the type of data that is being stored.&lt;/p&gt;
&lt;h3 id=&#34;key-value&#34;&gt;Key-Value&lt;/h3&gt;
&lt;p&gt;The key-value model is the simplest of the four. It is essentially a hash table where the key is used to retrieve the value. The value can be any type of data. This model is very fast and can scale to millions of objects.&lt;/p&gt;
&lt;h3 id=&#34;column&#34;&gt;Column&lt;/h3&gt;
&lt;p&gt;Tables are partitioned by columns into column families. Each column family is stored in its own files.&lt;/p&gt;
&lt;h3 id=&#34;document&#34;&gt;Document&lt;/h3&gt;
&lt;p&gt;Documents are stored in collections. Each document is stored as a JSON object. This model is very flexible and can store a variety of data types. It is also very fast and can scale to millions of objects. The documents are typically queried using their document ID, but other indices can be created to speed up queries.&lt;/p&gt;
&lt;h3 id=&#34;graph&#34;&gt;Graph&lt;/h3&gt;
&lt;p&gt;Graphs are used to represent relationships between objects. Each object is represented as a node and the relationships are represented as edges. This model is useful for applications that need to represent complex relationships between objects.&lt;/p&gt;
&lt;h2 id=&#34;cap-theorem&#34;&gt;CAP Theorem&lt;/h2&gt;
&lt;p&gt;The CAP theorem states that a distributed system can only guarantee two of the following three properties: &lt;strong&gt;consistency&lt;/strong&gt;, &lt;strong&gt;availability&lt;/strong&gt;, and &lt;strong&gt;partition tolerance&lt;/strong&gt;. Consistency means that all nodes see the same data at the same time. Availability means that every request receives a response. Partition tolerance means that the system continues to operate despite network failures.&lt;/p&gt;
&lt;h2 id=&#34;document-based-nosql-systems&#34;&gt;Document-Based NOSQL Systems&lt;/h2&gt;
&lt;p&gt;In document-based NOSQL systems, the data is &lt;strong&gt;self-describing&lt;/strong&gt; as there is no need for a schema. These sytems store &lt;strong&gt;documents&lt;/strong&gt; which are essentially JSON objects. The documents are stored in &lt;strong&gt;collections&lt;/strong&gt; which are similar to tables in a relational database. The documents are retrieved using their document ID.&lt;/p&gt;
&lt;h3 id=&#34;mongodb&#34;&gt;MongoDB&lt;/h3&gt;
&lt;p&gt;MongoDB is a document-based NOSQL database that is flexibile, scalable, and high-performance. It stores data in a JSON-like format called BSON (Binary JSON). Inidividual &lt;strong&gt;documents&lt;/strong&gt; are stored in a &lt;strong&gt;collection&lt;/strong&gt;. No schema is needed to begin storing data. The python code below will create a new collection for our RPG &lt;code&gt;Users&lt;/code&gt; with a simple command in &lt;code&gt;pymongo&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;users&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will create a new collection named &lt;code&gt;users&lt;/code&gt; with the default settings. If you want to specify additional options, call the &lt;code&gt;create_collection&lt;/code&gt; function. Common parameters include determining of a collection is capped by the storage size and maximum number of documents.&lt;/p&gt;
&lt;h4 id=&#34;representing-data&#34;&gt;Representing Data&lt;/h4&gt;
&lt;p&gt;Whenever a new item is inserted to a colletion, a unique &lt;code&gt;ObjectId&lt;/code&gt; is created and indexed. If the ID of a document should match a user-defined protocol, it can be set manually. Since there is no schema to specify a relationship, document relationships can be created by including the ~ObjectId~s of objects you wish to reference in your data.&lt;/p&gt;
&lt;p&gt;There are multiple ways to represent relationships between documents. Consider a &lt;code&gt;Character&lt;/code&gt; that holds multiple items in an &lt;code&gt;Inventory&lt;/code&gt;. The items could be referenced as an array of &lt;code&gt;Item&lt;/code&gt; objects within the &lt;code&gt;Character&lt;/code&gt; object itself. Alternatively, the &lt;code&gt;Character&lt;/code&gt; could hold an array of &lt;code&gt;ObjectId~s that reference the ~Item&lt;/code&gt; objects in the &lt;code&gt;Inventory&lt;/code&gt; collection. A third approach would have each &lt;code&gt;Item&lt;/code&gt; reference the &lt;code&gt;Character&lt;/code&gt; that owns it. The best approach depends on the application and the type of queries that will be performed.&lt;/p&gt;
&lt;h4 id=&#34;crud-operations&#34;&gt;CRUD Operations&lt;/h4&gt;
&lt;p&gt;CRUD stands for Create, Read, Update, and Delete. Single or multiple documents can be implemented with the &lt;code&gt;insert&lt;/code&gt; function. In &lt;code&gt;pymongo&lt;/code&gt;, you can use either &lt;code&gt;Collections.insert_one&lt;/code&gt; or &lt;code&gt;Collections.insert_many&lt;/code&gt;. The &lt;code&gt;insert_one&lt;/code&gt; function takes a single document as an argument and returns the &lt;code&gt;ObjectId&lt;/code&gt; of the inserted document. The &lt;code&gt;insert_many&lt;/code&gt; function takes a list of documents as an argument and returns a list of ~ObjectId~s.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;users&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;insert_one({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Naomi&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;})
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;users&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;insert_many([{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Naomi&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;}, {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;James&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;}])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Reading objects is done with the &lt;code&gt;find&lt;/code&gt; function. There are several variants of this available in &lt;code&gt;pymongo&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;find_one&lt;/code&gt; returns a single document that matches the query.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;find&lt;/code&gt; returns a cursor that can be iterated over to retrieve all documents that match the query.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;find_one_and_delete&lt;/code&gt; returns a single document that matches the query and deletes it.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;find_one_and_replace&lt;/code&gt; returns a single document that matches the query and replaces it with the specified document.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;find_one_and_update&lt;/code&gt; returns a single document that matches the query and updates it with the specified document.&lt;/li&gt;
&lt;/ul&gt;
&lt;!--listend--&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; db[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;users&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_one({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Naomi&amp;#39;&lt;/span&gt;})
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the document&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(val)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Print the name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(val[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Updating documents is done with the &lt;code&gt;update&lt;/code&gt; function. We saw an updated combined with &lt;code&gt;find&lt;/code&gt; above, but &lt;code&gt;pymongo&lt;/code&gt; also implements &lt;code&gt;update_one&lt;/code&gt; and &lt;code&gt;update_many&lt;/code&gt;. The &lt;code&gt;update_one&lt;/code&gt; function takes a query and an update document as arguments. The &lt;code&gt;update_many&lt;/code&gt; function takes a query and an update document as arguments. Both functions return a &lt;code&gt;UpdateResult&lt;/code&gt; object that contains information about the operation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;users&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;update_one({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Naomi&amp;#39;&lt;/span&gt;}, {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;$set&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;26&lt;/span&gt;}})
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Deleting documents is done with the &lt;code&gt;delete_one&lt;/code&gt; and &lt;code&gt;delete_many&lt;/code&gt; functions. Both functions take a query as an argument and return a &lt;code&gt;DeleteResult&lt;/code&gt; object that contains information about the operation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;users&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;delete_one({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Naomi&amp;#39;&lt;/span&gt;})
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;characteristics&#34;&gt;Characteristics&lt;/h4&gt;
&lt;p&gt;MongoDB uses a &lt;strong&gt;two-phase commit&lt;/strong&gt; method to ensure transaction atomicity and consistency. In the first phase of the process, a coordinator sends a message to all nodes to prepare for the transaction. Each node then responds with an acknowledgement. If all nodes respond with an acknowledgement, the coordinator sends a commit message to all nodes. If any node fails to respond with an acknowledgement, the coordinator sends a message to roll back the transaction.&lt;/p&gt;
&lt;p&gt;For data replication, a variation on the &lt;strong&gt;primary-replica&lt;/strong&gt; model is used. A primary node is chosen with at least one replica. More nodes can be added at the cost of increased time for writes. The total number of nodes for a replica set is at least 3, so if only a primary and one replica are used, an &lt;strong&gt;arbiter&lt;/strong&gt; must be chosen to break ties. In fact, any replica set with an even number of nodes must have an arbiter.&lt;/p&gt;
&lt;p&gt;All write operations mus be performed on the primary copy before being propagated to the replicas. Users can determine the &lt;strong&gt;read preference&lt;/strong&gt; for their application. The default is to read from the primary copy, but users can choose to read from the nearest copy or a specific copy. If a copy other than the primary is chosen for the read preference, it is not guaranteed that the user will get the lastest version of the data.&lt;/p&gt;
&lt;h4 id=&#34;sharding&#34;&gt;Sharding&lt;/h4&gt;
&lt;p&gt;We previously discussed that having all of the data in a single collection can lead to performance issues. Sharding is a technique that allows the data to be distributed across multiple nodes. This allows for multiple nodes to work in parallel to handle the load. Sharding splits the data into disjoint partitions which can then be stored on different nodes.&lt;/p&gt;
&lt;p&gt;The partitions can be determined via &lt;strong&gt;hash partitioning&lt;/strong&gt; or &lt;strong&gt;range partitioning&lt;/strong&gt;. In either case, a document field must be chosen to determine the partition. This partition field is called the &lt;strong&gt;shard key&lt;/strong&gt;. It must exist in every document and be indexed.&lt;/p&gt;
&lt;p&gt;When using sharding on MongoDB, a &lt;strong&gt;query router&lt;/strong&gt; keeps tracks of which nodes contain which shards. The actual query is then routed to the node containing the shard. In the event that a query is sent to a node that does not contain the shard, the query router will forward the query to all nodes.&lt;/p&gt;
&lt;h2 id=&#34;key-value-nosql-systems&#34;&gt;Key-Value NOSQL Systems&lt;/h2&gt;
&lt;p&gt;Key-value systems use a simple data model and typically do not have a query language. The data is stored as a key-value pair. The key is used to retrieve the value. The value can be any type of data. This model is very fast and can scale to millions of objects. Popular key-value stores include DynamoDB, Voldemort, Redis, and Cassandra. We will briefly discuss each of them below.&lt;/p&gt;
&lt;h3 id=&#34;dynamodb&#34;&gt;DynamoDB&lt;/h3&gt;
&lt;p&gt;DynamoDB was developed by Amazon to meet the needs of their large-scale internet applications. It is a key-value store that is highly available and scalable. It is also a managed service which means that Amazon handles the scaling and replication for you. It uses tables, items, and attributes without the need for a schema. The table itself holds multiple items which are self-describing. That is, the items have &lt;code&gt;(attribute, value)&lt;/code&gt; pairs.&lt;/p&gt;
&lt;p&gt;Tables must have &lt;strong&gt;primary keys&lt;/strong&gt; which can be either a single attribute or pair of attributes. For single attributes, DynamoDB will build a hash index on this attribute. For pairs of attribute, a &lt;strong&gt;hash and range&lt;/strong&gt; primary key is used. The primary key is the pair of attributes and the hash index is built on the first attribute. This allows for fast retrieval of items based on the first attribute. The second attribute can be used to sort the items for which the first attribute is the same.&lt;/p&gt;
&lt;h3 id=&#34;voldemort&#34;&gt;Voldemort&lt;/h3&gt;
&lt;p&gt;Voldemort is a distributed key-value store based on DynamoDB and developed by LinkedIn and Microsoft. The distribution of data is handled via &lt;strong&gt;consistent hashing&lt;/strong&gt;. Since Voldemort is based on DynamoDB, many of the characteristics described below also apply to DynamoDB.&lt;/p&gt;
&lt;h4 id=&#34;operations&#34;&gt;Operations&lt;/h4&gt;
&lt;p&gt;Like DynamoDB, key-value pairs are the primary data structure. These are kept in a data &lt;code&gt;store&lt;/code&gt;. Three basic operations are implemented: &lt;code&gt;get&lt;/code&gt;, &lt;code&gt;put&lt;/code&gt;, and &lt;code&gt;delete&lt;/code&gt;. Data is stored as a byte array.&lt;/p&gt;
&lt;h4 id=&#34;formatted-data&#34;&gt;Formatted Data&lt;/h4&gt;
&lt;p&gt;Voldemort supports multiple formats for the data. The default format is a byte array, but other formats such as JSON and Protocol Buffers are supported. It provides default serializers for these formats, but users can also implement their own. As long as a &lt;code&gt;Serializer&lt;/code&gt; class is implemented, it can be used to serialize and deserialize data.&lt;/p&gt;
&lt;h4 id=&#34;consistent-hashing&#34;&gt;Consistent Hashing&lt;/h4&gt;
&lt;p&gt;Voldemort distributes data based on a hash function that is applied to each key. The range of values on which the key is mapped corresponds to a node. The figure below shows an example of 7 regions being mapped to 3 nodes (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-11-20_10-49-02_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Consistent hashing in Voldemort.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Consistent hashing in Voldemort.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Consistent hashing naturally permits data replication and horizontal scaling. As new nodes are added, only a small subset of the data needs to be rehashed to the new node. Replicas are created by mapping the key to multiple nodes.&lt;/p&gt;
&lt;h4 id=&#34;consistency&#34;&gt;Consistency&lt;/h4&gt;
&lt;p&gt;Concurrent writes are allowed which means there can exist multiple versions of the same key at different nodes. Consistency occurs when an item is read. If the system can reconcile the different versions of the key to a single value, it will pass that final value on. Otherwise, multiple versions may be sent to the application to be resolved.&lt;/p&gt;
&lt;h3 id=&#34;redis&#34;&gt;Redis&lt;/h3&gt;
&lt;p&gt;Redis is an in-memory key-value store. This implies that is basic operations perform very quickly. However, it is not well suited for general purpose applications that require high volumes of data. A typical use-case for Redis would be caching, session management, or real-time analytics.&lt;/p&gt;
&lt;p&gt;For example, Twitter uses Redis to drive their timeline feature. The posts are indexed using an ID and stored in Redis. When a user requests their timeline, the IDs are retrieved from Redis as a chain of IDs.&lt;/p&gt;
&lt;h3 id=&#34;cassandra&#34;&gt;Cassandra&lt;/h3&gt;
&lt;p&gt;Cassandra can be used as a wide-column database (discussed below) or key-value database. It was originally developed at Facebook to handle large amounts of data across multiple commodity servers. It implements the Cassandra Query Language (CQL) which is similar to SQL. The data it partitioned similarly to other NOSQL datastores in that data is distributed in partitions across multiple nodes. CQL does not support cross-partition queries.&lt;/p&gt;
&lt;h2 id=&#34;column-based-nosql-systems&#34;&gt;Column-Based NOSQL Systems&lt;/h2&gt;
&lt;p&gt;The largest differentiator of a column-based system and key-value system is the way the key is defined. A popular implementation of this type of system is known as &lt;strong&gt;BigTable&lt;/strong&gt; which was developed by Google. It uses the &lt;strong&gt;Google File System (GFS)&lt;/strong&gt; to store data. There is an open source equivalent named &lt;strong&gt;Apache Hbase&lt;/strong&gt; which we will focus on below.&lt;/p&gt;
&lt;p&gt;Hbase organizes data using &lt;em&gt;namespaces, tables, column families, column qualifiers, columns, rows&lt;/em&gt;, and &lt;em&gt;data cells&lt;/em&gt;. A column is identified by a family and qualifier. It can store multiple versions of the same data, differentiating each version using a timestamp. Each data cell is identified by a unique key. Tables are associated with column families. When loading data, the column qualifiers must be specified.&lt;/p&gt;
&lt;p&gt;New column qualifiers can be created as needed, producing new rows of data. However, application developers must keep track of which qualifiers belnog to which family. This is a form of vertical partitioning. Since the columns belong to the same column family, they are stored in the same file.&lt;/p&gt;
&lt;p&gt;Cells are reference by their key which is a combination of the row key, column family, column qualifier, and timestamp. For relational semantics, namespaces are used to define a collection of tables.&lt;/p&gt;
&lt;p&gt;Hbase divides tables into &lt;strong&gt;regions&lt;/strong&gt; which hold a range of row keys into the table. It is for this reason that they keys must be sortable lexicographically. Each region has a number of &lt;strong&gt;stores&lt;/strong&gt; for which a column family is assigned. These regions of data are assigned to nodes in the cluster. To manage splitting and merging of regions, a &lt;strong&gt;primary server&lt;/strong&gt; is used.&lt;/p&gt;
&lt;h2 id=&#34;graph-based-nosql-systems&#34;&gt;Graph-Based NOSQL Systems&lt;/h2&gt;
&lt;p&gt;The last category of NOSQL databases discussed in these notes are Graph Databases. These databases are used to represent relationships between objects. Each object is represented as a node and the relationships are represented as edges. This model is useful for applications that need to represent complex relationships between objects. A popular implementation of this type of system is known as &lt;strong&gt;Neo4j&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Nodes and relationships can have a unique collection of properties to describe them. Nodes are labeled, and nodes with the same label are grouped into collections for querying. Relationship types are useful for grouping relationships based on a common property.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Paths&lt;/strong&gt; specify a traversal of a subgraph. They are used to specify a query and consist of nodes and relationships. The subgraph is used as a pattern to find other subgraphs that match the pattern. The query can be further refined by specifying constraints on the nodes and relationships.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Elmasri, Ramez, and Shamkant B. Navathe. 2015. &lt;i&gt;Fundamentals of Database Systems&lt;/i&gt;. 7th ed. Pearson. &lt;a href=&#34;https://www.pearson.com/en-us/subject-catalog/p/fundamentals-of-database-systems/P200000003546/9780137502523&#34;&gt;https://www.pearson.com/en-us/subject-catalog/p/fundamentals-of-database-systems/P200000003546/9780137502523&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Structured Query Language</title>
      <link>https://ajdillhoff.github.io/notes/structured_query_language/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/structured_query_language/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#history-and-development&#34;&gt;History and Development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#schemas&#34;&gt;Schemas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-types&#34;&gt;Data Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creation&#34;&gt;Creation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#constraints&#34;&gt;Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#retrieving-data&#34;&gt;Retrieving Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modifying-data&#34;&gt;Modifying Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nested-queries&#34;&gt;Nested Queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#joined-tables&#34;&gt;Joined Tables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#aggregate-functions&#34;&gt;Aggregate Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grouping&#34;&gt;Grouping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#with-clause&#34;&gt;&lt;code&gt;WITH&lt;/code&gt; Clause&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modifying-tables&#34;&gt;Modifying Tables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;history-and-development&#34;&gt;History and Development&lt;/h2&gt;
&lt;p&gt;Structured Query Language (SQL) is a database language for managing data in a relation DBMS. Its original inception was based on a paper by Edgar F. Codd in 1970 titled &lt;em&gt;A Relational Model of Data for Large Shared Data Banks&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Codd 1970&lt;/a&gt;). Two employees working at IBM in the 1970s, Donald D. Chamberlin and Raymond F. Boyce, developed the first version of SQL in 1974 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Chamberlin and Boyce 1974&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The first official standard of SQL was SQL-86, or SQL1, which was published in 1986 by the American National Standards Institute (ANSI). The following table shows the release dates of major SQL standards along with a brief description of the changes made in each version.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Standard&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SQL-86&lt;/td&gt;
&lt;td&gt;SQL1&lt;/td&gt;
&lt;td&gt;First official standard of SQL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL-89&lt;/td&gt;
&lt;td&gt;SQL2&lt;/td&gt;
&lt;td&gt;Added support for integrity constraints, views, and assertions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL-92&lt;/td&gt;
&lt;td&gt;SQL2&lt;/td&gt;
&lt;td&gt;Added support for triggers, recursive queries, and support for procedural programming&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL:1999&lt;/td&gt;
&lt;td&gt;SQL3&lt;/td&gt;
&lt;td&gt;Added support for object-relational features&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL:2003&lt;/td&gt;
&lt;td&gt;SQL3&lt;/td&gt;
&lt;td&gt;Added support for XML, window functions, and support for regular expressions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL:2006&lt;/td&gt;
&lt;td&gt;SQL3&lt;/td&gt;
&lt;td&gt;Added more XML storage features and XQuery support&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL:2008&lt;/td&gt;
&lt;td&gt;SQL3&lt;/td&gt;
&lt;td&gt;Added support for TRUNCATE TABLE and enhanced MERGE statements&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL:2011&lt;/td&gt;
&lt;td&gt;SQL3&lt;/td&gt;
&lt;td&gt;Added support for temporal data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL:2016&lt;/td&gt;
&lt;td&gt;SQL3&lt;/td&gt;
&lt;td&gt;Added support for JSON&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SQL:2023&lt;/td&gt;
&lt;td&gt;SQL3&lt;/td&gt;
&lt;td&gt;Added support for Propery Graph Queries and new JSON features&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;schemas&#34;&gt;Schemas&lt;/h2&gt;
&lt;p&gt;In our &lt;a href=&#34;https://ajdillhoff.github.io/notes/introduction_to_databases/&#34;&gt;Introduction to Databases&lt;/a&gt; we discussed the concept of a schema as a definition of the structure of a database. In SQL, a schema is a collection of database objects, such as tables, views, and indexes. A schema is owned by a database user and has the same name as the user. A database user can own multiple schemas, and a schema can be owned by multiple users. A schema can also be owned by a role, which is a collection of users. A role can own multiple schemas, and a schema can be owned by multiple roles.&lt;/p&gt;
&lt;p&gt;There are several practical reasons for which we would want to create multiple schemas. For example, a database might be used by both a Human Resources and Healthcare Management application. Creating two separate schemas would ensure that data for each application is kept secure from unauthorized users. Multiple schemas are also used for testing and development processes. Large structural changes to an application may require a new scheme to be created. New features can be developed in the new schema while the old schema is still being used by the application.&lt;/p&gt;
&lt;p&gt;The following command creates a new schema named &lt;code&gt;MedApp&lt;/code&gt; and assigns it to the user &lt;code&gt;MedAdmin&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;SCHEMA&lt;/span&gt; MedApp &lt;span style=&#34;color:#66d9ef&#34;&gt;AUTHORIZATION&lt;/span&gt; MedAdmin;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;data-types&#34;&gt;Data Types&lt;/h2&gt;
&lt;p&gt;SQL supports a wide variety of data types. The following table shows the most common data types supported by SQL.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Data Type&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CHAR(n)&lt;/td&gt;
&lt;td&gt;Fixed-length character string. The maximum length is &lt;code&gt;n&lt;/code&gt; characters.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VARCHAR(n)&lt;/td&gt;
&lt;td&gt;Variable-length character string. The maximum length is &lt;code&gt;n&lt;/code&gt; characters.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;INT&lt;/td&gt;
&lt;td&gt;Integer value. The maximum value is &lt;code&gt;2^31 - 1&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SMALLINT&lt;/td&gt;
&lt;td&gt;Integer value. The maximum value is &lt;code&gt;2^15 - 1&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DECIMAL(i,j)&lt;/td&gt;
&lt;td&gt;Fixed-point number. The maximum precision is &lt;code&gt;38&lt;/code&gt; digits. The maximum scale is &lt;code&gt;38&lt;/code&gt; digits.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NUMERIC(i,j)&lt;/td&gt;
&lt;td&gt;Fixed-point number. The maximum precision is &lt;code&gt;38&lt;/code&gt; digits. The maximum scale is &lt;code&gt;38&lt;/code&gt; digits.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;REAL&lt;/td&gt;
&lt;td&gt;Floating-point number. The maximum precision is &lt;code&gt;6&lt;/code&gt; digits.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;Floating-point number. The maximum precision is &lt;code&gt;15&lt;/code&gt; digits.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DATE&lt;/td&gt;
&lt;td&gt;Date value. The range is &lt;code&gt;1000-01-01&lt;/code&gt; to &lt;code&gt;9999-12-31&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TIME&lt;/td&gt;
&lt;td&gt;Time value. The range is &lt;code&gt;00:00:00&lt;/code&gt; to &lt;code&gt;23:59:59&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TIMESTAMP&lt;/td&gt;
&lt;td&gt;Date and time value. The range is &lt;code&gt;1000-01-01 00:00:00&lt;/code&gt; to &lt;code&gt;9999-12-31 23:59:59&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLOB(n)&lt;/td&gt;
&lt;td&gt;Specifies columns with large text values. Maximum length specified in kilobytes (K), megabytes (M), or gigabytes (G)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BIT(n)&lt;/td&gt;
&lt;td&gt;Fixed-length bit string.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BIT VARYING(n)&lt;/td&gt;
&lt;td&gt;Variable-length bit string.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BLOB(n)&lt;/td&gt;
&lt;td&gt;Binary Large Object - used for images, video, and other large items.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;creation&#34;&gt;Creation&lt;/h2&gt;
&lt;p&gt;Creating schemas, databases, and tables is done with the &lt;code&gt;CREATE&lt;/code&gt; command. The following command creates a new database named &lt;code&gt;RPG&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; RPG;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When creating a new table, we must specify the name of the table and the attributes of the table. The following command creates a new table named &lt;code&gt;Users&lt;/code&gt; with four attributes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Users (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    user_id INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    username VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    email VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    created_at &lt;span style=&#34;color:#66d9ef&#34;&gt;TIMESTAMP&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;constraints&#34;&gt;Constraints&lt;/h2&gt;
&lt;p&gt;Constraints allow us to add rules to our database that ensure the integrity of our data. There are several types of constraints that can be added to a table. For example, if a user is deleted, we may want to delete all of the user&amp;rsquo;s posts as well. This can be accomplished by adding a &lt;code&gt;CASCADE&lt;/code&gt; constraint to the &lt;code&gt;DELETE&lt;/code&gt; statement. We can also set a default value to each attribute. Constraints such as &lt;code&gt;CHECK&lt;/code&gt; and &lt;code&gt;UNIQUE&lt;/code&gt; can be added to ensure that the data is valid and unique. The following table shows the most common constraints supported by SQL.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Constraint&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;NOT NULL&lt;/td&gt;
&lt;td&gt;Ensures that a column cannot have a NULL value.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UNIQUE&lt;/td&gt;
&lt;td&gt;Ensures that all values in a column are unique.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PRIMARY KEY&lt;/td&gt;
&lt;td&gt;A combination of a NOT NULL and UNIQUE.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FOREIGN KEY&lt;/td&gt;
&lt;td&gt;Ensures that values in a column match values in another table&amp;rsquo;s column.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CHECK&lt;/td&gt;
&lt;td&gt;Ensures that all values in a column satisfy a specific condition.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DEFAULT&lt;/td&gt;
&lt;td&gt;Sets a default value for a column when no value is specified.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;INDEX&lt;/td&gt;
&lt;td&gt;Used to create and retrieve data from the database very quickly.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AUTO INCREMENT&lt;/td&gt;
&lt;td&gt;Automatically generates a unique number when a new record is inserted into a table.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When creating the &lt;code&gt;Users&lt;/code&gt; table above, we may want to ensure that the &lt;code&gt;user_id&lt;/code&gt; attribute is unique. We can do this by adding a &lt;code&gt;UNIQUE&lt;/code&gt; constraint to the &lt;code&gt;user_id&lt;/code&gt; attribute. It is also possible to have it auto increment so that we do not have to specify a value for it when inserting a new user.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Users (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    user_id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;UNIQUE&lt;/span&gt; AUTO_INCREMENT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    username VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    email VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    created_at &lt;span style=&#34;color:#66d9ef&#34;&gt;TIMESTAMP&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following command creates a new table named &lt;code&gt;Characters&lt;/code&gt; with a &lt;code&gt;VARCHAR&lt;/code&gt; attribute named &lt;code&gt;Name&lt;/code&gt; which is set to &lt;code&gt;NOT NULL&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Characters (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Name VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;NOT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;NULL&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Constraints can also be added after the initial attribute declaration. When creating the &lt;code&gt;Characters&lt;/code&gt; table, if we want to state that the &lt;code&gt;user_id&lt;/code&gt; field should be a foreign key, we can add a &lt;code&gt;FOREIGN KEY&lt;/code&gt; constraint to the &lt;code&gt;user_id&lt;/code&gt; attribute.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Characters (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;UNIQUE&lt;/span&gt; AUTO_INCREMENT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Name VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;NOT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;NULL&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    user_id INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;CONSTRAINT&lt;/span&gt; fk_user_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     &lt;span style=&#34;color:#66d9ef&#34;&gt;FOREIGN&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt; (user_id) &lt;span style=&#34;color:#66d9ef&#34;&gt;REFERENCES&lt;/span&gt; Users(user_id)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The constraint is given the name &lt;code&gt;fk_user_id&lt;/code&gt; and is added to the &lt;code&gt;user_id&lt;/code&gt; attribute. The &lt;code&gt;FOREIGN KEY&lt;/code&gt; constraint states that the &lt;code&gt;user_id&lt;/code&gt; attribute references the &lt;code&gt;user_id&lt;/code&gt; attribute in the &lt;code&gt;Users&lt;/code&gt; table.&lt;/p&gt;
&lt;h2 id=&#34;retrieving-data&#34;&gt;Retrieving Data&lt;/h2&gt;
&lt;p&gt;Retrieving data from an SQL database is done with an &lt;code&gt;SFW&lt;/code&gt; query, &lt;code&gt;SELECT-FROM-WHERE&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;attribute list&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;table&lt;/span&gt; list&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;condition&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For example, we can get the experience and level of a character named &lt;code&gt;Atticus&lt;/code&gt; from the &lt;code&gt;Characters&lt;/code&gt; table with the following query.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; experience, &lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; Name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Atticus&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The attributes we retrieve in a query are referred to as the &lt;code&gt;projection attributes&lt;/code&gt;. This query &lt;code&gt;SELECT~s a ~Character&lt;/code&gt; from all rows of the &lt;code&gt;Character&lt;/code&gt; table which satisfy the &lt;strong&gt;selection condition&lt;/strong&gt; of the &lt;code&gt;WHERE&lt;/code&gt; clause.
We can also query the e-mail addresses of all users who have a character that is a human.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; email
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users, Characters, Races
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; Users.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Characters.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; Characters.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Races.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; Races.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;WHERE&lt;/code&gt; clause in this example is an example of a &lt;strong&gt;join condition&lt;/strong&gt; since it combines attributes from multiple tables. Note that there are two tables which have a &lt;code&gt;user_id&lt;/code&gt; attribute, so we must differentiate them by prepending the table name before the attribute name. This is how ambiguities are solved in SQL.&lt;/p&gt;
&lt;p&gt;You can also use the &lt;code&gt;AS&lt;/code&gt; keyword to shorthand the table names in your query. The previous query can be rewritten as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;   Users &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;  U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;duplicate-return-values&#34;&gt;Duplicate Return Values&lt;/h3&gt;
&lt;p&gt;The previous query returns the names of all users who have a &lt;code&gt;Human&lt;/code&gt; character. If a user has multiple characters that are &lt;code&gt;Human&lt;/code&gt;, it will return their name multiple times. If we are instead only interested in the names of users who have a &lt;code&gt;Human&lt;/code&gt; character, we can use the &lt;code&gt;DISTINCT&lt;/code&gt; keyword to remove duplicate values.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;   Users &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;  U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;tables-as-sets&#34;&gt;Tables as Sets&lt;/h3&gt;
&lt;p&gt;SQL uses some set operations from set theory. It supports the &lt;code&gt;UNION&lt;/code&gt;, set difference &lt;code&gt;EXCEPT&lt;/code&gt;, and set intersection &lt;code&gt;INTERSECT&lt;/code&gt; operations. The following query returns the names of all users who have a &lt;code&gt;Human&lt;/code&gt; character or a &lt;code&gt;Gnome&lt;/code&gt; character.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;UNION&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Gnome&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we wanted to find the users who had both a &lt;code&gt;Human&lt;/code&gt; character and a &lt;code&gt;Gnome&lt;/code&gt; character, we could use the &lt;code&gt;INTERSECT&lt;/code&gt; operator instead.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;INTERSECT&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Gnome&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can also use the &lt;code&gt;EXCEPT&lt;/code&gt; operator to find the users who have a &lt;code&gt;Human&lt;/code&gt; character but not a &lt;code&gt;Gnome&lt;/code&gt; character.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;EXCEPT&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Gnome&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pattern-matching&#34;&gt;Pattern Matching&lt;/h3&gt;
&lt;p&gt;SQL supports pattern matching with the &lt;code&gt;LIKE&lt;/code&gt; operator. The &lt;code&gt;LIKE&lt;/code&gt; operator is used in the &lt;code&gt;WHERE&lt;/code&gt; clause to search for a specified pattern in a column. This is different from equality operators since it allows us to search for patterns rather than exact matches. The following table shows the most common wildcards used in SQL.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Wildcard&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;%&lt;/td&gt;
&lt;td&gt;Matches any string of zero or more characters.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;_&lt;/td&gt;
&lt;td&gt;Matches any single character.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[]&lt;/td&gt;
&lt;td&gt;Matches any single character within the brackets.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[^]&lt;/td&gt;
&lt;td&gt;Matches any single character not within the brackets.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The following query returns the names of all simple items in the &lt;code&gt;Items&lt;/code&gt; table. These can be found based on their description, since the term &lt;code&gt;simple&lt;/code&gt; is not explicitly mentioned in the name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Items
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;   description &lt;span style=&#34;color:#66d9ef&#34;&gt;LIKE&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%simple%&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can also query based on arithmetic ranges. For example, we might be interested in the items that are less than 100 gold.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Items
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;   value &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;ordering&#34;&gt;Ordering&lt;/h3&gt;
&lt;p&gt;SQL allows us to order the results of our query with the &lt;code&gt;ORDER BY&lt;/code&gt; clause. The following query returns the names of all items in the &lt;code&gt;Items&lt;/code&gt; table ordered by their value.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Items
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ORDER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; value;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can also order by multiple attributes. The following query returns the names of all items in the &lt;code&gt;Items&lt;/code&gt; table ordered by their value and then their name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Items
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ORDER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; value, name;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;modifying-data&#34;&gt;Modifying Data&lt;/h2&gt;
&lt;h3 id=&#34;inserting-data&#34;&gt;Inserting Data&lt;/h3&gt;
&lt;p&gt;We previously saw an example of inserting new data. Let&amp;rsquo;s insert a new user account to our table. If we are inserting a value for every attribute, we can omit the attribute list.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;INSERT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;INTO&lt;/span&gt; Users
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;VALUES&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Alex&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;alex.dillhoff@uta.edu&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2023-10-31 15:26:17&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we are only inserting values for some attributes, we must specify the attribute list.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;INSERT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;INTO&lt;/span&gt; Users (user_id, username, email)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;VALUES&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Alex&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;alex.dillhoff@uta.edu&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we attempt to leave out a value for an attribute that is not nullable, we will get an error. While working on our database, we may have realized that some of these important attributes should always be specified. We can add a &lt;code&gt;NOT NULL&lt;/code&gt; constraint to these attributes to ensure that they are always specified. We will look at ways of modifying tables in the next section.&lt;/p&gt;
&lt;h3 id=&#34;updating-data&#34;&gt;Updating Data&lt;/h3&gt;
&lt;p&gt;Updating data is a common task and is easily supported by the &lt;code&gt;UPDATE&lt;/code&gt; command. In an RPG, players will use items, gain experience, and level up. All of these will require modifications to existing tables. For example, if we wish to update the experience of a character, we can use the following query.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;UPDATE&lt;/span&gt; Characters
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SET&lt;/span&gt; experience &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; experience &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Atticus&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;deleting-data&#34;&gt;Deleting Data&lt;/h3&gt;
&lt;p&gt;Deleting a tuple or several tuples is straightforward in SQL. The following query deletes the user with the &lt;code&gt;user_id&lt;/code&gt; of &lt;code&gt;7&lt;/code&gt; from the &lt;code&gt;Users&lt;/code&gt; table.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;DELETE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we want to delete all tuples from a table, we can use the &lt;code&gt;TRUNCATE TABLE&lt;/code&gt; command. This command is faster than deleting all tuples with the &lt;code&gt;DELETE&lt;/code&gt; command since it does not log each deletion. However, it cannot be used if the table is referenced by a foreign key constraint.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;TRUNCATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Users;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When deleting tuples from a database, it&amp;rsquo;s important to consider any foreign key constraints that the table may have. If we delete a tuple from a table that is referenced by a foreign key constraint, we may end up with orphaned tuples. For example, if we delete a user from the &lt;code&gt;Users&lt;/code&gt; table, we may end up with a character that has no user. We can avoid this by adding a &lt;code&gt;CASCADE&lt;/code&gt; constraint to the &lt;code&gt;DELETE&lt;/code&gt; statement. This will delete all tuples that reference the tuple we are deleting.&lt;/p&gt;
&lt;h2 id=&#34;nested-queries&#34;&gt;Nested Queries&lt;/h2&gt;
&lt;p&gt;Nested queries allow us to make more complex queries on subsets of data returned from an original query. A nested query can be placed in any of the &lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;FROM&lt;/code&gt;, or &lt;code&gt;WHERE&lt;/code&gt; clauses. The query that uses the results of the nested query is called the &lt;strong&gt;outer query&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What if we wanted a list of users who had at least 1 character whose class was the least represented class across all characters? We could first make a query to identify which class is the least represented before using that to find the users who have a character with that class.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Users
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;   user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;IN&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; user_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; class_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      &lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      &lt;span style=&#34;color:#66d9ef&#34;&gt;ORDER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;ASC&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      &lt;span style=&#34;color:#66d9ef&#34;&gt;LIMIT&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;));
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The innert-most query returns the &lt;code&gt;class_id&lt;/code&gt; of the least represented class by counting the number of characters in each class and ordering them in ascending order. The middle query returns the &lt;code&gt;user_id&lt;/code&gt; of all characters whose class is the least represented class. The outer query returns the &lt;code&gt;username&lt;/code&gt; of all users who have a character with the least represented class.&lt;/p&gt;
&lt;p&gt;Pay attention to the second &lt;code&gt;WHERE&lt;/code&gt; clause that uses the &lt;code&gt;=&lt;/code&gt; operator instead of &lt;code&gt;IN&lt;/code&gt;. This is because the nested query returns a single value and single tuple. If we used the &lt;code&gt;IN&lt;/code&gt; operator, we would get an error since MySQL does not support the &lt;code&gt;LIMIT&lt;/code&gt; and &lt;code&gt;IN/ALL/ANY/SOME&lt;/code&gt; operators together.&lt;/p&gt;
&lt;h3 id=&#34;correlated-nested-queries&#34;&gt;Correlated Nested Queries&lt;/h3&gt;
&lt;p&gt;Some nested queries would have to execute for each tuple in the outer query. Consider the following query which returns the name and ID of all Human characters.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.id, &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#66d9ef&#34;&gt;IN&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; R.id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                      &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                      &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This query is an example of a &lt;strong&gt;correlated nested query&lt;/strong&gt; since the inner query is dependent on the outer query. The inner query must be executed for each tuple in the outer query. This can be inefficient if the outer query returns a large number of tuples.&lt;/p&gt;
&lt;p&gt;Since this query uses only an &lt;code&gt;IN&lt;/code&gt; operator, we can rewrite it as a single block query.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.id, &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s revisit an earlier query to introduce the &lt;code&gt;EXISTS&lt;/code&gt; operator. If we want to query the user names and IDs of all users who have an elf character, we can use the following query.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  U.id, U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;EXISTS&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;   Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;, Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; U.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                       &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Elf&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can also use the &lt;code&gt;NOT EXISTS&lt;/code&gt; operator to find the users who do not have an elf character. This works opposite to the &lt;code&gt;EXISTS&lt;/code&gt; operator.&lt;/p&gt;
&lt;h2 id=&#34;joined-tables&#34;&gt;Joined Tables&lt;/h2&gt;
&lt;p&gt;Joined tables are the result of a query that combines rows from two or more tables. The syntax itself may be easier to understand as compared to the nested queries written above. The following query returns the names of all users who have a &lt;code&gt;Human&lt;/code&gt; character.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; U.username, &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;   (Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U &lt;span style=&#34;color:#66d9ef&#34;&gt;JOIN&lt;/span&gt; Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id), Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here, the &lt;code&gt;JOIN&lt;/code&gt; function is used to combine both tables on the condition that the &lt;code&gt;user_id&lt;/code&gt; of the &lt;code&gt;Users&lt;/code&gt; table is equal to the &lt;code&gt;user_id&lt;/code&gt; of the &lt;code&gt;Characters&lt;/code&gt; table. The &lt;code&gt;WHERE&lt;/code&gt; clause is used to filter the results to only those that have a &lt;code&gt;Human&lt;/code&gt; character.&lt;/p&gt;
&lt;p&gt;This type of join is also referred to as an &lt;strong&gt;inner join&lt;/strong&gt; since it only returns rows that satisfy the join condition. There are several other types of joins that we can use to combine tables. If we wanted to return the same information along with all of the users who do not have a &lt;code&gt;Human&lt;/code&gt; character, we can use a &lt;strong&gt;left outer join&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; U.username, &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;   (Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U &lt;span style=&#34;color:#66d9ef&#34;&gt;LEFT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;OUTER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;JOIN&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        (Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;JOIN&lt;/span&gt; Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;aggregate-functions&#34;&gt;Aggregate Functions&lt;/h2&gt;
&lt;p&gt;Aggregate functions are used to perform calculations on a set of values and return a single value. The following table shows the most common aggregate functions supported by SQL.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Function&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AVG()&lt;/td&gt;
&lt;td&gt;Returns the average value of a numeric column.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;COUNT()&lt;/td&gt;
&lt;td&gt;Returns the number of rows that match a specified criteria.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAX()&lt;/td&gt;
&lt;td&gt;Returns the maximum value of a column.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MIN()&lt;/td&gt;
&lt;td&gt;Returns the minimum value of a column.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SUM()&lt;/td&gt;
&lt;td&gt;Returns the sum of all values in a column.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;These can be used in the &lt;code&gt;SELECT&lt;/code&gt; clause. The following query returns the average level of all characters.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AVG&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;   Characters;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These statistics can be used with more complex queries. The following query returns the name of the user with the highest level character.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; U.username
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;   Users &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; U, Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;  U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MAX&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                            &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the next example, the query returns the tuple of the highest level Human character.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    (Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;JOIN&lt;/span&gt; Races &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; R &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.race_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; R.id &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; R.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Human&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MAX&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                   &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;grouping&#34;&gt;Grouping&lt;/h2&gt;
&lt;p&gt;As we just saw, aggregate functions permit some preliminary data analysis. We can take this further using &lt;strong&gt;grouping&lt;/strong&gt;. For example, we calculated above the average level of all characters. What if we wanted to compute the average level of each class? We can use the &lt;code&gt;GROUP BY&lt;/code&gt; clause to group the tuples by class.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.class_id, &lt;span style=&#34;color:#66d9ef&#34;&gt;AVG&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;     Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.class_id;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the next example, we will run a similar query except we will also include the number of distinct users who have a character of that class.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.class_id, &lt;span style=&#34;color:#66d9ef&#34;&gt;AVG&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.&lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.user_id)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;     Characters &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.class_id;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;with-clause&#34;&gt;&lt;code&gt;WITH&lt;/code&gt; Clause&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s say we wanted to get the actual class name along with the users that had a character with the least represented class. We can use a nested query in the &lt;code&gt;FROM&lt;/code&gt; clause to get the class name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt;  username, Classes.name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;    Users, Classes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt;   user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;IN&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; user_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; class_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      &lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      &lt;span style=&#34;color:#66d9ef&#34;&gt;ORDER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;ASC&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      &lt;span style=&#34;color:#66d9ef&#34;&gt;LIMIT&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; Classes.id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          &lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          &lt;span style=&#34;color:#66d9ef&#34;&gt;ORDER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;ASC&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          &lt;span style=&#34;color:#66d9ef&#34;&gt;LIMIT&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This query might immediately come across as inefficient since we are making the same query multiple times. If you agree, your intuition would be right. We can use the &lt;code&gt;WITH&lt;/code&gt; clause to make this query more efficient.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WITH&lt;/span&gt; LeastUsedClass &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Characters
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;ORDER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;ASC&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;LIMIT&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; U.username, &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.name
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users U
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;JOIN&lt;/span&gt; Characters CH &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; U.user_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CH.user_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;JOIN&lt;/span&gt; Classes &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;C&lt;/span&gt;.id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CH.class_id
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; CH.class_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; class_id &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; LeastUsedClass);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;modifying-tables&#34;&gt;Modifying Tables&lt;/h2&gt;
&lt;p&gt;Modifying databases used in production is inevitable. Typically, you will modify an offline test version before deploying it, but the process is the same. The &lt;code&gt;ALTER TABLE&lt;/code&gt; command is used to modify tables. The following table shows the most common modifications that can be made to a table.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Command&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ADD&lt;/td&gt;
&lt;td&gt;Adds a new column to the table.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DROP&lt;/td&gt;
&lt;td&gt;Deletes a column from the table.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MODIFY&lt;/td&gt;
&lt;td&gt;Changes the data type of a column.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RENAME&lt;/td&gt;
&lt;td&gt;Changes the name of a column.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When we originally created the &lt;code&gt;Users&lt;/code&gt; table, we did not specify a &lt;code&gt;NOT NULL&lt;/code&gt; constraint for the &lt;code&gt;username&lt;/code&gt; attribute. We can add this constraint with the following command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ALTER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Users
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MODIFY&lt;/span&gt; username VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;NOT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;NULL&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Another mistake that was made was with the name of the ID column. We can rename this column with the following command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ALTER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Users
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;RENAME&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COLUMN&lt;/span&gt; user_id &lt;span style=&#34;color:#66d9ef&#34;&gt;TO&lt;/span&gt; id;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;scenario-updating-foreign-keys&#34;&gt;Scenario: Updating Foreign Keys&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s say we want to delete anything related to a user if that user is deleted from the &lt;code&gt;Users&lt;/code&gt; table. That means all characters and inventories associated with those characters should be deleted. Currently, attempting to delete a user will fail with the following error:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;SQL Error &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;1451&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;23000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: Cannot delete or update a parent row: a foreign key constraint fails &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;rpg&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;.&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;Inventory&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;, CONSTRAINT &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;Iventory_ibfk_1&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt; FOREIGN KEY &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;character_id&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; REFERENCES &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;Characters&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;id&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It looks like the foreign key also has a typo. Let&amp;rsquo;s recreate this foreign key so that it will delete all characters and inventories associated with a user. First we drop the current key.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ALTER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Inventory
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;DROP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FOREIGN&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt; Iventory_ibfk_1;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then we add a new one.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ALTER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Inventory
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ADD&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;CONSTRAINT&lt;/span&gt; Inventory_ibfk_1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FOREIGN&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt; (character_id) &lt;span style=&#34;color:#66d9ef&#34;&gt;REFERENCES&lt;/span&gt; Characters(id) &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DELETE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;CASCADE&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;A typical SQL query consists of a &lt;code&gt;SELECT&lt;/code&gt; clause, a &lt;code&gt;FROM&lt;/code&gt; clause, and a &lt;code&gt;WHERE&lt;/code&gt; clause. The &lt;code&gt;SELECT&lt;/code&gt; clause specifies the attributes to be returned. The &lt;code&gt;FROM&lt;/code&gt; clause specifies the tables to be queried. The &lt;code&gt;WHERE&lt;/code&gt; clause specifies the conditions that must be satisfied for a tuple to be returned.&lt;/p&gt;
&lt;p&gt;As we saw in the examples above, there are up to 6 clauses that can be used in a query. The following table shows the clauses that can be used in a query and the order in which they must appear.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Clause&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SELECT&lt;/td&gt;
&lt;td&gt;Specifies the attributes to be returned.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FROM&lt;/td&gt;
&lt;td&gt;Specifies the tables to be queried.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WHERE&lt;/td&gt;
&lt;td&gt;Specifies the conditions that must be satisfied for a tuple to be returned.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GROUP BY&lt;/td&gt;
&lt;td&gt;Groups the tuples by a specified attribute.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HAVING&lt;/td&gt;
&lt;td&gt;Specifies the conditions that must be satisfied for a group to be returned.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ORDER BY&lt;/td&gt;
&lt;td&gt;Specifies the order in which the tuples are returned.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Chamberlin, Donald D., and Raymond F. Boyce. 1974. SEQUEL: A Structured English Query Language. In &lt;i&gt;Proceedings of the 1974 ACM SIGFIDET (Now SIGMOD) Workshop on Data Description, Access and Control&lt;/i&gt;, 24964. SIGFIDET 74. New York, NY, USA: Association for Computing Machinery. &lt;a href=&#34;https://doi.org/10.1145/800296.811515&#34;&gt;https://doi.org/10.1145/800296.811515&lt;/a&gt;.&lt;/div&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_2&#34;&gt;&lt;/a&gt;Codd, E. F. 1970. A Relational Model of Data for Large Shared Data Banks. &lt;i&gt;Communications of the Acm&lt;/i&gt; 13 (6): 37787. &lt;a href=&#34;https://doi.org/10.1145/362384.362685&#34;&gt;https://doi.org/10.1145/362384.362685&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Databases</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_databases/</link>
      <pubDate>Sat, 28 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/introduction_to_databases/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#an-online-rpg-database&#34;&gt;An Online RPG Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#from-schema-to-database&#34;&gt;From Schema to Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#database-management-systems&#34;&gt;Database Management Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-our-rpg-database&#34;&gt;Creating our RPG Database&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;&lt;strong&gt;Recommended Reading: Chapters 1 and 2 from (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Databases allow us to store, retrieve, and edit different types of data. They should be scalable, secure, and reliable. They should also be able to handle concurrent access and be able to recover from failures. There are multiple types of databases that are optimized for different use cases. Tabular data, for example, is typically stored in a &lt;strong&gt;relational&lt;/strong&gt; database. Large format data such as images, videos, and audio are typically stored in a &lt;strong&gt;non-relational&lt;/strong&gt; database.&lt;/p&gt;
&lt;p&gt;Creating, deploying, and maintaining databases is facilitated through a &lt;strong&gt;database management system&lt;/strong&gt; (DBMS). A DBMS is a software system that allows us to interact with a database. It provides an interface for us to create, read, update, and delete data. It also provides a way for us to define the structure of our data and the relationships between different pieces of data. Examples of DBMSs include MySQL, PostgreSQL, and MongoDB.&lt;/p&gt;
&lt;p&gt;Once a database is deployed, we can interact with it a number of ways. Most DBMSs include a client which allows us to interact with the database through a command line interface. We can also interact with the database through a programming language such as Python or Java.&lt;/p&gt;
&lt;p&gt;It is important to emphasize that a database is not the same thing as a file system. A file system is a way to store data on a disk, whereas a database is a way to store data in a file system. File systems are good at managing unstructured data with little regard to the relationships inherit in the data itself. What if multiple people working on the same document try to save their changes at the same time? What if a user tries to delete a file that is currently being used by another user? These are problems that a file system is not designed to handle.&lt;/p&gt;
&lt;h2 id=&#34;an-online-rpg-database&#34;&gt;An Online RPG Database&lt;/h2&gt;
&lt;p&gt;To introduce some foundational terms and concepts of databases, let&amp;rsquo;s design and create a database for an online RPG. In this game, users can create accounts, make multiple characters, store items for their characters, and embark on quests to level up their characters. Even from this simple description, we can start separating our data into different &lt;strong&gt;entities&lt;/strong&gt; and &lt;strong&gt;relationships&lt;/strong&gt;. Each logical entity in our game will be represented by a &lt;strong&gt;table&lt;/strong&gt; in our database. The &lt;strong&gt;attributes&lt;/strong&gt; of each table will be represented by columns in our database. For this database, we will need &lt;em&gt;at least&lt;/em&gt; the following tables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Users&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Characters&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Items&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Inventory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Quests&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We may add or modify these depending on the finer details. If you are not familiar with online RPG games, don&amp;rsquo;t worry. We will be sure to include the necessities to get us started. Let&amp;rsquo;s start with the first table, &lt;code&gt;Users&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;users&#34;&gt;Users&lt;/h3&gt;
&lt;p&gt;A &lt;code&gt;User&lt;/code&gt; represents an online account that is unique to each person who plays the game. It should contain the &lt;code&gt;username&lt;/code&gt;, &lt;code&gt;email&lt;/code&gt;, and date that it was created, which we will call &lt;code&gt;created_at&lt;/code&gt;. This is enough information for now. Using this, we can create our first &lt;strong&gt;table&lt;/strong&gt;. There is one more attribute that wasn&amp;rsquo;t explicitly mentioned. Each &lt;code&gt;User&lt;/code&gt; in our table should have a unique identifier. This is called a &lt;strong&gt;primary key&lt;/strong&gt;. We will use a sequentially increasing number starting at 1 for our primary key. This is a common practice, but it is not the only way to do it. We will call this column &lt;code&gt;user_id&lt;/code&gt;. The full table is showing below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Users&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;user_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;username&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;email&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;created_at&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;characters&#34;&gt;Characters&lt;/h3&gt;
&lt;p&gt;It is common for users to have multiple characters so they can experience the full range of our game. This table will have more attributes than the &lt;code&gt;Users&lt;/code&gt; table since there are a wide range of stats that our characters can have, such as their name, level, experience, and health. We will also need to know which user each character belongs to. We can do this by adding a column called &lt;code&gt;user_id&lt;/code&gt; which will be a &lt;strong&gt;foreign key&lt;/strong&gt; to the &lt;code&gt;Users&lt;/code&gt; table. This will allow us to link each character to the user that created it. The full table is shown below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Characters&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;character_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;user_id&lt;/code&gt;: foreign key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;level&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;experience&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;health&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;created_at&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;items&#34;&gt;Items&lt;/h3&gt;
&lt;p&gt;As our user&amp;rsquo;s play, they will collect items such as weapons, armor, and potions. As our game evolves, our game designers will add more items to the game. A table for our items is shown below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Items&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;item_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;value&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inventory&#34;&gt;Inventory&lt;/h3&gt;
&lt;p&gt;Our users will need a way to store their items. We can do this by creating a table called &lt;code&gt;Inventory&lt;/code&gt;. This table will have a foreign key to the &lt;code&gt;Characters&lt;/code&gt; table so we can link each item to the character that owns it. It will also have a foreign key to the &lt;code&gt;Items&lt;/code&gt; table so we can link each item to the item that it represents. We will also need to know how many of each item our users have. We can do this by adding a column called &lt;code&gt;quantity&lt;/code&gt;. The full table is shown below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inventory&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;inventory_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;character_id&lt;/code&gt;: foreign key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;item_id&lt;/code&gt;: foreign key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;quantity&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;quests&#34;&gt;Quests&lt;/h3&gt;
&lt;p&gt;No RPG would be complete without quests that our player&amp;rsquo;s could embark upon. The &lt;code&gt;Quests&lt;/code&gt; table will have a name, description, and a reward. In the case of multiple rewards, we can create a separate table called &lt;code&gt;QuestRewards&lt;/code&gt; that will have a foreign key to the &lt;code&gt;Quests&lt;/code&gt; table and a foreign key to the &lt;code&gt;Items&lt;/code&gt; table. This will allow us to link each quest to the items that it rewards. This means that the &lt;code&gt;Quests&lt;/code&gt; table does not need an explicit reference to the reward item. We can look those up separately. The full table is shown below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Quests&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;quest_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;description&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reward_experience&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_level&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;QuestRewards&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;quest_reward_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;quest_id&lt;/code&gt;: foreign key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;item_id&lt;/code&gt;: foreign key&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-few-extras&#34;&gt;A Few Extras&lt;/h3&gt;
&lt;p&gt;There are a few more tables we should add to round out our characters. Most RPGs allow the users to create characters of different &lt;strong&gt;races&lt;/strong&gt;, such as a human, orc, or elf, as well as the characters &lt;strong&gt;class&lt;/strong&gt;, which defines what sort of abilities the character will have.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Race&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;race_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Class&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the addition of these two tables, let&amp;rsquo;s add &lt;em&gt;foreign keys&lt;/em&gt; to our original &lt;code&gt;Characters&lt;/code&gt; table. We will add a &lt;code&gt;race_id&lt;/code&gt; and a &lt;code&gt;class_id&lt;/code&gt;. The full table is shown below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Characters&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;character_id&lt;/code&gt;: primary key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;user_id&lt;/code&gt;: foreign key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;level&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;experience&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;health&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;race_id&lt;/code&gt;: foreign key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;class_id&lt;/code&gt;: foreign key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;created_at&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That&amp;rsquo;s it! We have all the tables we need to get us started. All tables with example data are shown below. You&amp;rsquo;ll notice that each of the primary IDs in the tables below have been renamed to &lt;code&gt;id&lt;/code&gt;. Besides giving us extra room to display the table, the primary key is always unique to the table, so we don&amp;rsquo;t need to include the table name in the column name.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Users&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\begin{array}{|r|l|l|l|}
\hline
\text{id} &amp;amp; \text{username} &amp;amp; \text{email} &amp;amp; \text{created_at} \\
\hline
1 &amp;amp; \text{Naomi} &amp;amp; \text{player1@example.com} &amp;amp; \text{2023-01-01 10:00:00} \\
2 &amp;amp; \text{Clarissa} &amp;amp; \text{player2@example.com} &amp;amp; \text{2023-01-02 11:00:00} \\
3 &amp;amp; \text{Avasarala} &amp;amp; \text{player3@example.com} &amp;amp; \text{2023-01-03 12:00:00} \\
\hline
\end{array}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Characters&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\begin{array}{|r|r|l|r|r|r|r|r|l|}
\hline
\text{id} &amp;amp; \text{user_id} &amp;amp; \text{name} &amp;amp; \text{class_id} &amp;amp; \text{race_id} &amp;amp; \text{level} &amp;amp; \text{experience} &amp;amp; \text{health} &amp;amp; \text{created_at} \\
\hline
1 &amp;amp; 1 &amp;amp; \text{Atticus} &amp;amp; 1 &amp;amp; 1 &amp;amp; 10 &amp;amp; 1000 &amp;amp; 100 &amp;amp; \text{2023-01-01 10:10:00} \\
2 &amp;amp; 1 &amp;amp; \text{Bobbie} &amp;amp; 2 &amp;amp; 2 &amp;amp; 15 &amp;amp; 1500 &amp;amp; 200 &amp;amp; \text{2023-01-01 10:20:00} \\
3 &amp;amp; 2 &amp;amp; \text{Raimi} &amp;amp; 3 &amp;amp; 3 &amp;amp; 8 &amp;amp; 800 &amp;amp; 90 &amp;amp; \text{2023-01-02 11:10:00} \\
4 &amp;amp; 3 &amp;amp; \text{Beef} &amp;amp; 4 &amp;amp; 4 &amp;amp; 12 &amp;amp; 1200 &amp;amp; 110 &amp;amp; \text{2023-01-03 12:10:00} \\
5 &amp;amp; 2 &amp;amp; \text{Demon} &amp;amp; 4 &amp;amp; 4 &amp;amp; 12 &amp;amp; 1200 &amp;amp; 110 &amp;amp; \text{2023-01-05 12:10:00} \\
\hline
\end{array}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Items&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\begin{array}{|r|l|r|r|}
\hline
\text{id} &amp;amp; \text{name} &amp;amp; \text{value} \\
\hline
1 &amp;amp; \text{Sword} &amp;amp; 100 \\
2 &amp;amp; \text{Shield} &amp;amp; 150 \\
3 &amp;amp; \text{Staff} &amp;amp; 200 \\
4 &amp;amp; \text{Bow} &amp;amp; 250 \\
\hline
\end{array}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inventory&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\begin{array}{|r|r|r|r|}
\hline
\text{id} &amp;amp; \text{character_id} &amp;amp; \text{item_id} &amp;amp; \text{quantity} \\
\hline
1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 \\
2 &amp;amp; 2 &amp;amp; 2 &amp;amp; 1 \\
3 &amp;amp; 3 &amp;amp; 3 &amp;amp; 1 \\
4 &amp;amp; 4 &amp;amp; 4 &amp;amp; 1 \\
\hline
\end{array}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Quests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\begin{array}{|r|l|l|r|l|r|}
\hline
\text{id} &amp;amp; \text{name} &amp;amp; \text{description} &amp;amp; \text{reward_experience} &amp;amp; \text{min_level} \\
\hline
1 &amp;amp; \text{Linken&amp;rsquo;s Sword} &amp;amp; \text{Desc1} &amp;amp; 100 &amp;amp; 5 \\
2 &amp;amp; \text{Mankrik&amp;rsquo;s Wife} &amp;amp; \text{Desc2} &amp;amp; 200 &amp;amp; 10 \\
3 &amp;amp; \text{The Hermit} &amp;amp; \text{Desc3} &amp;amp; 300 &amp;amp; 15 \\
4 &amp;amp; \text{The Great Masquerade} &amp;amp; \text{Desc4} &amp;amp; 400 &amp;amp; 20 \\
\hline
\end{array}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;QuestRewards&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\begin{array}{|r|r|r|}
\hline
\text{id} &amp;amp; \text{quest_id} &amp;amp; \text{item_id} \\
\hline
1 &amp;amp; 1 &amp;amp; 1 \\
2 &amp;amp; 2 &amp;amp; 2 \\
3 &amp;amp; 3 &amp;amp; 3 \\
4 &amp;amp; 4 &amp;amp; 4 \\
\hline
\end{array}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Races&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\begin{array}{|r|l|}
\hline
\text{race_id} &amp;amp; \text{name} \\
\hline
1 &amp;amp; \text{Human} \\
2 &amp;amp; \text{Elf} \\
3 &amp;amp; \text{Dwarf} \\
4 &amp;amp; \text{Orc} \\
\hline
\end{array}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Classes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\begin{array}{|r|l|}
\hline
\text{class_id} &amp;amp; \text{name} \\
\hline
1 &amp;amp; \text{Warrior} \\
2 &amp;amp; \text{Mage} \\
3 &amp;amp; \text{Rogue} \\
4 &amp;amp; \text{Paladin} \\
\hline
\end{array}&lt;/p&gt;
&lt;h2 id=&#34;from-schema-to-database&#34;&gt;From Schema to Database&lt;/h2&gt;
&lt;p&gt;What we did in the previous example is created a database &lt;strong&gt;schema&lt;/strong&gt; based on our entities. A schema does not represent the entire picture of our &lt;strong&gt;data model&lt;/strong&gt;. Relationships and other constraints are not represented in the schema. The data model itself defines the structure of a database, including data types, relationships, constraints, and a set of operations for performing basic functions like retrieving and updating data.&lt;/p&gt;
&lt;h3 id=&#34;the-three-schema-architecture&#34;&gt;The Three-Schema Architecture&lt;/h3&gt;
&lt;p&gt;The three-schema architecture is a way to separate the different aspects of a database. The three schemas are the &lt;strong&gt;external schema&lt;/strong&gt;, the &lt;strong&gt;conceptual schema&lt;/strong&gt;, and the &lt;strong&gt;internal schema&lt;/strong&gt;. The internal schema describes how the data is stored on disk. Unless we are working on the backend of the database, we typically do not need to worry about the internal level. The external schema describes how the data is viewed by the user. This is the level that we interact with when we use a DBMS. The conceptual schema is the middle layer that describes the logical structure of the data. This is the level that we are working with when we create a schema.&lt;/p&gt;
&lt;p&gt;Under this architecture, we can modify the internal schema without affecting the external schema. This is important because it allows us to change the way that the data is stored without affecting the applications that use it. We can also modify the external schema without affecting the internal schema. This allows us to change the way that the data is viewed without affecting the applications that use it. This concept of &lt;strong&gt;data independence&lt;/strong&gt; is one of the most important features of a DBMS.&lt;/p&gt;
&lt;h2 id=&#34;database-management-systems&#34;&gt;Database Management Systems&lt;/h2&gt;
&lt;p&gt;With our database defined, we can use it to make &lt;strong&gt;queries&lt;/strong&gt; about the records that it stores. How we access that database depends on the DBMS that we are using. The database itself is can be modified and changed without affecting the applications that use it. We can also create multiple &lt;strong&gt;views&lt;/strong&gt; of our data dynamically. For example, we can create a view that shows all of the items that a user has in their inventory, or show all of the characters that belong to a specific user. This is all done without modifying the underlying data. This is a powerful feature of databases that allows us to create complex applications that can be easily modified and updated.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;transaction&lt;/strong&gt; is a set of operations that are performed on a database. Transactions are typically used to ensure that the database is in a consistent state. For example, if we want to transfer money from one account to another, we need to make sure that the money is removed from one account and added to the other. If we fail to do this, we could end up with money that is neither in the original account nor the destination account. Transactions allow us to perform these operations in a way that guarantees that the database is in a consistent state.&lt;/p&gt;
&lt;p&gt;A DBMS must ensure transactional properties such as &lt;strong&gt;isolation&lt;/strong&gt;, which ensure that each transaction executes in isolation from others, and &lt;strong&gt;atomicity&lt;/strong&gt;, which ensures that either all operations in a transaction are executed or none are.&lt;/p&gt;
&lt;h3 id=&#34;dbms-languages&#34;&gt;DBMS Languages&lt;/h3&gt;
&lt;p&gt;A DBMS provides a way for us to interact with the database. Depending on the level of abstraction and the DBMS itself, a specific language is used to perform basic operations on the database. The most common languages are &lt;strong&gt;data definition languages&lt;/strong&gt; (DDLs) and &lt;strong&gt;data manipulation languages&lt;/strong&gt; (DMLs). A DDL is used to define the structure of the database, such as creating tables and defining relationships between them. A DML is used to perform operations on the data itself, such as inserting, updating, and deleting records.&lt;/p&gt;
&lt;p&gt;A common query language called Structured Query Language (SQL) defines both DDLs and DMLs. For example, to create our &lt;code&gt;User&lt;/code&gt; table from above, we can use the following SQL statement:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Users (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  user_id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIMARY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  username VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  email VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  created_at DATETIME
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that we must specify a type for each attribute in our table. SQL also provides a DML, we can use to insert records into our table:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;INSERT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;INTO&lt;/span&gt; Users (user_id, username, email, created_at)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;VALUES&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Naomi&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;player1@example.com&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2023-01-01 10:00:00&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;dbms-interfaces&#34;&gt;DBMS Interfaces&lt;/h3&gt;
&lt;p&gt;A DBMS provides an interface for us to interact with the database. This interface can be a command line interface, a graphical user interface, or a programming language interface. Other interfaces using natural language or voice can also be found in the wild. With the rapid advancement of machine learning, these interfaces are becoming more and more common. &lt;a href=&#34;https://github.com/kulltc/chatgpt-sql&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Here&lt;/a&gt; is an example of a chatbot that can be used to query a database.&lt;/p&gt;
&lt;h2 id=&#34;creating-our-rpg-database&#34;&gt;Creating our RPG Database&lt;/h2&gt;
&lt;p&gt;For this example, we will be using MySQL. We only want to make sure that we have MySQL installed and are able to interface with the command line. You can find a thorough installation guide &lt;a href=&#34;https://dev.mysql.com/doc/mysql-installation-excerpt/5.7/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;. Once it is installed and configured, start the MySQL server and log in using the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mysql -u root -p
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should be prompted for a password. If you have not set a password, you can leave it blank. Once you are logged in, you should see a prompt that looks like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mysql&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s create a database for our RPG. We can do this with the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; rpg;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can verify that the database was created by listing all of the databases on the server:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SHOW&lt;/span&gt; DATABASES;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see the &lt;code&gt;rpg&lt;/code&gt; database in the list. We can now use this database to create our tables. We can do this with the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;USE rpg;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will tell MySQL to use the &lt;code&gt;rpg&lt;/code&gt; database for all subsequent commands. We can now create our &lt;code&gt;Users&lt;/code&gt; table:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Users (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  user_id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIMARY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  username VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  email VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  created_at DATETIME
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can verify that the table was created by listing all of the tables in the database:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SHOW&lt;/span&gt; TABLES;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see the &lt;code&gt;Users&lt;/code&gt; table in the list. We can now insert some data into the table:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;INSERT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;INTO&lt;/span&gt; Users (user_id, username, email, created_at)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;VALUES&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Naomi&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;player1@example.com&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2023-01-01 10:00:00&amp;#39;&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Clarissa&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;player2@example.com&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2023-01-02 11:00:00&amp;#39;&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Avasarala&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;player3@example.com&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2023-01-03 12:00:00&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can verify that the data was inserted by querying the table:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; Users;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see the data that we inserted in the table. We can now create the rest of our tables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Characters (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  character_id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIMARY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  user_id INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;level&lt;/span&gt; INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  experience INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  health INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  created_at DATETIME
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Items (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  item_id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIMARY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  value INT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Inventory (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  inventory_id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIMARY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  character_id INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  item_id INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  quantity INT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; Quests (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  quest_id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIMARY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  description VARCHAR(&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  reward_experience INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  min_level INT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; QuestRewards (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  quest_reward_id INT &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIMARY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;KEY&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  quest_id INT,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  item_id INT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Try creating the tables for the &lt;code&gt;Races&lt;/code&gt; and &lt;code&gt;Classes&lt;/code&gt; yourself. Once you are done, you can insert some data into the tables. Use the samples from above or create your own. Once you are done, you can query the tables to verify that the data was inserted correctly.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Elmasri, Ramez, and Shamkant B. Navathe. 2015. &lt;i&gt;Fundamentals of Database Systems&lt;/i&gt;. 7th ed. Pearson. &lt;a href=&#34;https://www.pearson.com/en-us/subject-catalog/p/fundamentals-of-database-systems/P200000003546/9780137502523&#34;&gt;https://www.pearson.com/en-us/subject-catalog/p/fundamentals-of-database-systems/P200000003546/9780137502523&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Minimum Spanning Trees</title>
      <link>https://ajdillhoff.github.io/notes/minimum_spanning_trees/</link>
      <pubDate>Sat, 21 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/minimum_spanning_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#definition&#34;&gt;Definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#finding-the-minimum-spanning-tree&#34;&gt;Finding the Minimum Spanning Tree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kruskal-s-algorithm&#34;&gt;Kruskal&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prim-s-algorithm&#34;&gt;Prim&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;Minimum spanning trees are undirected graphs that connect all of the vertices such that there are no redundant edges and the total weight is minimized. They are useful for finding the shortest path between two points in a graph. Useful application of MSTs include&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;network design&lt;/strong&gt;: it is useful to know the least expensive path with respect to either latency or resource cost for telecommunications networks, transportation networks, or electrical grids.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;approximation algorithms&lt;/strong&gt;: MSTs can be used to approximate the solution to the traveling salesman problem.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;clustering&lt;/strong&gt;: MSTs can be used to cluster data points in a graph.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;image segmentation&lt;/strong&gt;: MSTs can be used to segment images into smaller regions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;
&lt;p&gt;Let \(G\) be a connected, undirected graph with edges \(E\), vertices \(V\), and edge weights \(w\). A &lt;strong&gt;minimum spanning tree&lt;/strong&gt; is a subset \(T \subseteq E\) that connects all of the vertices such that the total weight is minimized. The original graph \(G\) is shown below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-21_18-46-30_undirected_original.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;An undirected graph with redundant edges.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;An undirected graph with redundant edges.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The minimum spanning tree of the above graph is show below. All of the redundant edges have been removed, but there is still a path between each pair of nodes.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-21_18-56-15_mst.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;The minimum spanning tree of (G).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;The minimum spanning tree of (G).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;As described in &lt;em&gt;Introduction to Algorithms&lt;/em&gt; there are two greedy algorithms for finding the minimum spanning tree of a graph (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;). These notes will review both of these, but first let&amp;rsquo;s look at a general algorithm for finding the minimum spanning tree of a graph.&lt;/p&gt;
&lt;h2 id=&#34;finding-the-minimum-spanning-tree&#34;&gt;Finding the Minimum Spanning Tree&lt;/h2&gt;
&lt;p&gt;The general algorithm for finding the minimum spanning tree of a graph grows a set of edges \(T\) from an empty set. At each step, the algorithm adds the edge with the smallest weight that does not create a cycle. The algorithm terminates when \(T\) is a complete tree.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;T = {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;while T is not a spaning tree
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    find the edge e with the smallest weight that does not create a cycle
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    T = T union {e}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Each edge \(e\) that is added must result in a tree that is a subset of the minimum spanning tree. The challenge of this algorithm is actually finding such an edge. How would we know such an edge if we saw it? We first need to define a few properties which will shine light on this.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;cut&lt;/strong&gt; of a graph \(G\) is a partition of the vertices \(V\) into two disjoint sets \(S\) and \(V - S\). An edge \(e\) &lt;strong&gt;crosses&lt;/strong&gt; the cut if one of its endpoints is in \(S\) and the other is in \(V - S\). If no edge in a given set \(E\) crosses the cut, then that cut &lt;strong&gt;respects&lt;/strong&gt; \(E\). An edge that is the minimum weight edge that crosses a cut is called a &lt;strong&gt;light edge&lt;/strong&gt;. With these definitions, we can now formally define how to find a &lt;strong&gt;safe edge&lt;/strong&gt;, which is an edge that can be added to the current set of edges \(T\) without creating a cycle.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Theorem 21.1 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let \(G = (V, E)\) be a connected, undirected graph with a real-valued weight function \(w\) defined on \(E\). Let \(A\) be a subset of \(E\) that is included in some minimum spanning tree for \(G\), let \((S, V - S)\) be any cut of \(G\) that respects \(A\), and let \(e\) be a light edge crossing \((S, V - S)\). Then, edge \(e\) is safe for \(A\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-22_13-10-51_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Visual proof of Theorem 21.1 (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Cormen et al. 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Visual proof of Theorem 21.1 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Proof&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The two sets in the figure above represent vertices in \(S\) (orange) and vertices in \(V - S\) (tan). \(T\) is the original MST depicted in the figure. The dotted line is the new edge \((u, v)\) to consider. \(A\) is a subset of edges in \(T\) represented by the blue lines. If the safe edge \((u, v)\) is already in the original MST \(T\), then we are done.&lt;/p&gt;
&lt;p&gt;The vertices \(u\) and \(v\) lie on opposite sides of the cut. The edge \((u, v)\) would introduce a cycle since there is already a path from \(u\) to \(v\) in \(T\) that crosses the cut via \((x, y)\). Since both \((u, v)\) and \((x, y)\) are light edges that cross the cut, then it must be that \(w(u, v) \leq w(x, y)\).&lt;/p&gt;
&lt;p&gt;Let \(T&amp;rsquo;\) be the minimum spanning tree with \((x, y)\) replaced by \((u, v)\). That is \(T&amp;rsquo; = T - \{(x, y)\} \cup \{(u, v)\}\). Since \(T\) is a minimum spanning tree, then \(w(T) \leq w(T&amp;rsquo;)\). Since \(w(T) = w(T&amp;rsquo;)\), then \(T&amp;rsquo;\) is also a minimum spanning tree. Therefore, \((u, v)\) is safe for \(A\).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Corollary 21.2 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can also view this in terms of &lt;strong&gt;connected components&lt;/strong&gt;, which are subsets of vertices that are connected by a path. If \(C\) and \(C&amp;rsquo;\) are two connected components in \(T\) and \((u, v)\) is a light edge connecting \(C\) and \(C&amp;rsquo;\), then \((u, v)\) is safe for \(T\).&lt;/p&gt;
&lt;p&gt;The figure below shows a graph with two individual components. If the edge \((u, v)\) is a light edge, then it is safe to add it to the set of edges \(T\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-22_15-39-37_connected_components.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;Two connected components from a graph (left). Adding a safe edge (right).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;Two connected components from a graph (left). Adding a safe edge (right).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h2 id=&#34;kruskal-s-algorithm&#34;&gt;Kruskal&amp;rsquo;s Algorithm&lt;/h2&gt;
&lt;p&gt;The first solution to the minimum spanning tree that we will study is called &lt;strong&gt;Kruskal&amp;rsquo;s algorithm&lt;/strong&gt;. This algorithm grows a forest of trees from an empty set. At each step, the algorithm adds the lightest edge that does not create a cycle. The algorithm terminates when the forest is a single tree. This can be viewed as an agglomerative clustering algorithm. The algorithm starts with each vertex in its own cluster. At each step, the algorithm merges the two clusters that are closest together. The algorithm terminates when there is only one cluster.&lt;/p&gt;
&lt;p&gt;The algorithm is given below (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Kruskal&amp;rsquo;s Algorithm&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A = {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;for each vertex v in G.V
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    MAKE-SET(v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sort the edges of G.E into nondecreasing order by weight w
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;for each edge (u, v) in G.E, taken in nondecreasing order by weight
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    if FIND-SET(u) != FIND-SET(v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A = A union {(u, v)}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        UNION(u, v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;return A
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A step-by-step example of an implementation in Python is available &lt;a href=&#34;https://github.com/ajdillhoff/python-examples/blob/main/data_structures/graphs/kruskals_algorithm.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;The running time is dependent on how the disjoint-set of vertices is implemented. In the best known case, a &lt;em&gt;disjoint-set-forest&lt;/em&gt; implementation should be used (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;). Creating a list of edges takes \(O(E)\) time. Sorting the edges takes \(O(E \log E)\) time. The &lt;code&gt;for&lt;/code&gt; loop iterates over each edge, which is \(O(E)\). All disjoin-set operations take \(O((V + E)\alpha(V))\) time. Since the graph is connected, \(E \geq V - 1\), so the total running time is \(O(E \log E + E + E \alpha(V)) = O(E \log E + E \alpha(V)) = O(E \log V)\).&lt;/p&gt;
&lt;h2 id=&#34;prim-s-algorithm&#34;&gt;Prim&amp;rsquo;s Algorithm&lt;/h2&gt;
&lt;p&gt;The second solution starts at an arbitrary vertex in a set \(A\) and adds a new vertex to \(A\) in a greedy fashion. To efficiently select a new edge to add, Prim&amp;rsquo;s algorithm uses a priority queue to keep track of the lightest edge that crosses the cut. The algorithm terminates when \(A\) is a complete tree. The full algorithm is given below. We will step through it in more detail after.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Prim&amp;rsquo;s Algorithm&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A = {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;for each vertex v in G.V
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    key[v] = infinity
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pi[v] = NIL
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;key[r] = 0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Q = G.V
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;while Q is not empty
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    u = EXTRACT-MIN(Q)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    A = A union {u}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    for each vertex v in G.Adj[u]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        if v in Q and w(u, v) &amp;lt; key[v]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            pi[v] = u
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            key[v] = w(u, v)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You might look at this and wonder how the MST is represented. Prim&amp;rsquo;s algorithm implicitly maintains the set \(A = \{(v, v.\pi) : v \in V - \{r\} - Q\}\). When the &lt;code&gt;while&lt;/code&gt; loop terminates, \(A = \{(v, v.\pi) : v \in V - \{r\}\}\), since the queue is empty. The critical part of this is to understand how the algorith changes the key values.&lt;/p&gt;
&lt;p&gt;A step-by-step example of an implementation in Python is available &lt;a href=&#34;https://github.com/ajdillhoff/python-examples/blob/main/data_structures/graphs/prims_algorithm.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;Prim&amp;rsquo;s algorithm uses a priority queue to keep track of the lightest edge that crosses the cut. If the priority queue is implemented as a &lt;a href=&#34;https://www.cs.cmu.edu/~tcortina/15-121sp10/Unit06B.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;min-heap&lt;/a&gt;, which has a worst-case running time of \(O(\log V)\) for both &lt;code&gt;EXTRACT-MIN&lt;/code&gt; and &lt;code&gt;DECREASE-KEY&lt;/code&gt;. The algorithm calls &lt;code&gt;EXTRACT-MIN&lt;/code&gt; once for each vertex, which is \(O(V \log V)\). The algorithm calls &lt;code&gt;DECREASE-KEY&lt;/code&gt; once for each edge, which is \(O(E \log V)\). The total running time is \(O(V \log V + E \log V) = O(E \log V)\).&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Cormen, Thomas H., Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 2022. &lt;i&gt;Introduction to Algorithms&lt;/i&gt;. 4th ed. MIT Press. &lt;a href=&#34;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&#34;&gt;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Single-Source Shortest Paths</title>
      <link>https://ajdillhoff.github.io/notes/single_source_shortest_paths/</link>
      <pubDate>Sat, 21 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/single_source_shortest_paths/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#definition&#34;&gt;Definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bellman-ford&#34;&gt;Bellman-Ford&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dijkstra-s-algorithm&#34;&gt;Dijkstra&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;When you hear the term &lt;em&gt;shortest path&lt;/em&gt;, you may think of the shortest physical distance between your current location and wherever it is you&amp;rsquo;re going. Finding the most optimal route via GPS is one of the most widely used mobile applications. Physical paths are not the only types we may wish to find a shortest path for. Other examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Network Routing&lt;/strong&gt;: To improve network performance, it is critical to know the shortest path from one system to another in terms of latency.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Puzzle Solving&lt;/strong&gt;: For puzzles such as a Rubik&amp;rsquo;s cube, the vertices could represents states of the cube and edges could correspond to a single move.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Robotics&lt;/strong&gt;: Shortest paths in terms of robotics have a lot to do with physical distances, but it could also relate the completing a task efficiently.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These notes will cover classical single-source shortest path algorithms, but first we must formally define the problem.&lt;/p&gt;
&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;
&lt;p&gt;Given a weighted, directed graph \(G = (V, E)\) with weight function \(w: E \rightarrow \mathbb{R}\), a source vertex \(s \in V\), and a destination vertex \(t \in V\), find the shortest path from \(s\) to \(t\). The weight of a path is defined as the sum of the weights of its edges:&lt;/p&gt;
&lt;p&gt;\[
w(p) = \sum_{e \in p} w(e).
\]&lt;/p&gt;
&lt;p&gt;The shortest-path weight between two vertices \(u\) and \(v\) is given by&lt;/p&gt;
&lt;p&gt;\[
\delta(u, v) = \begin{cases}
\min_{p \in P(u, v)} w(p) &amp;amp; \text{if } P(u, v) \neq \emptyset \\
\infty &amp;amp; \text{otherwise}
\end{cases}
\]&lt;/p&gt;
&lt;p&gt;where \(P(u, v)\) is the set of all paths from \(u\) to \(v\). The shortest-path weight from \(s\) to \(t\) is given by \(\delta(s, t)\).&lt;/p&gt;
&lt;p&gt;Shortest-path algorithms rely on an optimal substructure property that is defined by Lemma 22.1 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lemma 22.1&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Given a weighted, directed graph \(G = (V,E)\) with weight function \(w: E \rightarrow \mathbb{R}\), let \(p = \langle v_0, v_1, \dots, v_k \rangle\) be a shortest path from vertex \(v_0\) to vertex \(v_k\). For any \(i\) and \(j\) such that \(0 \leq i \leq j \leq k\), let \(p_{ij} = \langle v_i, v_{i+1}, \dots, v_j \rangle\) be the subpath of \(p\) from vertex \(v_i\) to vertex \(v_j\). Then, \(p_{ij}\) is a shortest path from \(v_i\) to \(v_j\).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is also important to note here that a shortest path should contain no cycles. Some shortest-path algorithms require that the edge weights be strictly positive. For those that do not, they may have some mechanism for detecting negative-weight cycles. In any case, a cycle of any kind cannot be included in a shortest path. This is because if a cycle were included, we could simply traverse the cycle as many times as we wanted to reduce the weight of the path. For positive-weight cycles, if a shortest path included a cycle, then surely we could remove the cycle to get a lower weight.&lt;/p&gt;
&lt;p&gt;As we build a shortest path, we need to keep track of which vertices lead us from the source to the destination. Some algorithms maintain this by keeping a &lt;strong&gt;predecessor&lt;/strong&gt; attribute for each vertex in the path. Solutions such as the Viterbi algorithm keep an array of indices that correspond to the vertices in the path. In any case, we will need to keep track of the vertices in the path as we build it.&lt;/p&gt;
&lt;h3 id=&#34;relaxation&#34;&gt;Relaxation&lt;/h3&gt;
&lt;p&gt;There is one more important property to define before discussing specific algorithms: &lt;strong&gt;relaxation&lt;/strong&gt;. Relaxing an edge \((u, v)\) is to test whether going through vertex \(u\) improves the shortest path to \(v\). If so, we update the shortest-path estimate and predecessor of \(v\) to reflect the new shortest path. Relaxation requires that we maintain the shortest-path estimate and processor for each vertex. This is initialized as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;initialize_single_source&lt;/span&gt;(G, s):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;V:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; float(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;inf&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When the values are changed, we say that the vertex has been &lt;strong&gt;relaxed&lt;/strong&gt;. Relaxing an edge \((u, v)\) is done as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relax&lt;/span&gt;(u, v, w):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; w(u, v):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; w(u, v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; u
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;properties&#34;&gt;Properties&lt;/h4&gt;
&lt;p&gt;Relaxation has the following properties.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If the shortest-path estimate of a vertex is not \(\infty\), then it is always an upper bound on the weight of a shortest path from the source to that vertex.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The shortest-path estimate of a vertex will either stay the same or decrease as the algorithm progresses.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once a vertex&amp;rsquo;s shortest-path estimate is finalized, it will never change.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The shortest-path estimate of a vertex is always greater than or equal to the actual shortest-path weight.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After \(i\) iterations of relaxing on all \((u, v)\), if the shortest path to \(v\) has \(i\) edges, then \(v.d = \delta(s, v)\).&lt;/p&gt;
&lt;p&gt;Following &lt;em&gt;Introduction to Algorithms&lt;/em&gt;, we will first discuss the Bellman-Ford algorithm, which has a higher runtime but works with graphs that have negative edge weights. Then, we will discuss Dijkstra&amp;rsquo;s algorithm, which has a lower runtime but only works with graphs that have non-negative edge weights.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bellman-ford&#34;&gt;Bellman-Ford&lt;/h2&gt;
&lt;p&gt;The Bellman-Ford algorithm is a dynamic programming algorithm that solves the single-source shortest-paths problem in the general case in which edge weights may be negative. If a negative-weight cycle is reachable from the source, then the algorithm will report its existence. Otherwise, it will report the shortest-path weights and predecessors. It works by relaxing edges, decreasing the shortest-path estimate on the weight of a shortest path from \(s\) to each vertex \(v\) until it reaches the shortest-path weight.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bellman_ford&lt;/span&gt;(G, w, s):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    initialize_single_source(G, s)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;V)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (u, v) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;E:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            relax(u, v, w)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (u, v) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;E:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; w(u, v):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;
&lt;p&gt;In the figure below, graph (a) shows the original graph before iterating over the edges. Graphs (b)-(e) show the result of looping over both edges originating from \(s\). Depending on the implementation, the first iteration of the vertices would result directly in graph (c). You can find a Python implementation of this example &lt;a href=&#34;https://github.com/ajdillhoff/python-examples/blob/main/data_structures/graphs/bellman_ford_algorithm.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-24_21-05-33_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Step-by-step execution of Bellman-Ford on a graph with negative-weight edges (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Cormen et al. 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Step-by-step execution of Bellman-Ford on a graph with negative-weight edges (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;Using an adjacency list representation, the runtime of Bellman-Ford is \(O(V^2 + VE)\). The initialization takes \(\Theta(V)\). Each of the \(|V| - 1\) iterations over the edges takes \(\Theta(V + E)\), and the final check for negative-weight cycles takes \(\Theta(V + E)\). If the number of edges and vertices is such that the number of vertices are a lower bound on the edges, then the runtime is \(O(VE)\).&lt;/p&gt;
&lt;h2 id=&#34;dijkstra-s-algorithm&#34;&gt;Dijkstra&amp;rsquo;s Algorithm&lt;/h2&gt;
&lt;p&gt;Dijkstra&amp;rsquo;s algorithm also solves the single-source shortest path problem on a weighted, directed graph \(G = (V,E)\) but requires nonnegative weights on all edges. It works in a breadth-first manner. A minimum priority queue is utilized to keep track of the vertices that have not been visited based on their current minimum shortest-path estimate. The algorithm works by relaxing edges, decreasing the shortest-path estimate on the weight of a shortest path from \(s\) to each vertex \(v\) until it reaches the shortest-path weight.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dijkstra&lt;/span&gt;(G, w, s):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    initialize_single_source(G, s)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    S &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Q &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;V
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; Q:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; extract_min(Q)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        S&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(u)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;adj[u]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            prev_d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            relax(u, v, w)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; prev_d:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                decrease_key(Q, v)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;
&lt;p&gt;A Python example of the figure below is available &lt;a href=&#34;https://github.com/ajdillhoff/python-examples/blob/main/data_structures/graphs/dijkstras_algorithm.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-25_08-21-04_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;A step-by-step execution of Dijkstra&amp;#39;s algorithm on a graph with non-negative edge weights (&amp;lt;a href=&amp;#34;#citeproc_bib_item_1&amp;#34;&amp;gt;Cormen et al. 2022&amp;lt;/a&amp;gt;).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;A step-by-step execution of Dijkstra&amp;rsquo;s algorithm on a graph with non-negative edge weights (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;See Chapter 22 of &lt;em&gt;Introduction to Algorithms&lt;/em&gt; for a detailed analysis of Dijkstra&amp;rsquo;s algorithm. Inserting the nodes and then extracting them from the queue yields \(O(V \log V)\). After extracting a node, its edges are iterated with a possible update to the queue. This takes \(O(E \log V)\). The total runtime is \(O((V + E) \log V)\).&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Cormen, Thomas H., Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 2022. &lt;i&gt;Introduction to Algorithms&lt;/i&gt;. 4th ed. MIT Press. &lt;a href=&#34;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&#34;&gt;http://mitpress.mit.edu/9780262046305/introduction-to-algorithms/&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Graph Theory</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_graph_theory/</link>
      <pubDate>Tue, 17 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/introduction_to_graph_theory/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what-are-graphs&#34;&gt;What are Graphs?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#graph-traversal-algorithms&#34;&gt;Graph Traversal Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;what-are-graphs&#34;&gt;What are Graphs?&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;graph&lt;/strong&gt; is a data structure that is used to represent pairwise relationships between objects. Graphs are used in many applications, such as social networks, maps, and routing algorithms. These notes accompany the series of lectures on graphs for my &lt;em&gt;Foundations of Computing&lt;/em&gt; course at the University of Texas - Arlington.&lt;/p&gt;
&lt;h3 id=&#34;definitions&#34;&gt;Definitions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A &lt;strong&gt;directed graph&lt;/strong&gt; \(G\) is represented as a pair \((V, E)\) of a set of vertices \(V\) and edges \(E\). Edges are represented as ordered pairs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An &lt;strong&gt;undirected graph&lt;/strong&gt; \(G\) is represented as a pair \((V, E)\) of a set of vertices \(V\) and edges \(E\). The edges are represented as unordered pairs, as it does not matter which direction the edge is going.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let \((u, v)\) be an edge in a graph \(G\). If \(G\) is a directed graph, then the edge is &lt;strong&gt;incident from&lt;/strong&gt; \(u\) and is &lt;strong&gt;incident to&lt;/strong&gt; \(v\). In this case, \(v\) is also &lt;strong&gt;adjacent&lt;/strong&gt; to \(u\). If \(G\) is an undirected graph, then the edge is &lt;strong&gt;incident on&lt;/strong&gt; \(u\) and \(v\). For undirected graphs, the &lt;strong&gt;adjacency&lt;/strong&gt; relation is symmetric.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;degree&lt;/strong&gt; is a graph is the number of edges incident on a vertex. For directed graphs, the &lt;strong&gt;in-degree&lt;/strong&gt; is the number of edges incident to a vertex, and the &lt;strong&gt;out-degree&lt;/strong&gt; is the number of edges incident from a vertex.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;strong&gt;path&lt;/strong&gt; from a vertex \(u\) to another vertex \(v\) is a sequence of edges that starts at \(u\) and ends at \(v\). This definition can include duplicates. A &lt;strong&gt;simple path&lt;/strong&gt; is a path that does not repeat any vertices. A &lt;strong&gt;cycle&lt;/strong&gt; is a path that starts and ends at the same vertex. If a path exists from \(u\) to \(v\), then \(u\) is &lt;strong&gt;reachable&lt;/strong&gt; from \(v\).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;strong&gt;connected graph&lt;/strong&gt; is a graph where there is a path between every pair of vertices. A &lt;strong&gt;strongly connected graph&lt;/strong&gt; is a directed graph where there is a path between every pair of vertices. The &lt;strong&gt;connected components&lt;/strong&gt; of a graph are the subgraphs in which each pair of nodes is connected by a path. In image processing, connected-component labeling is used to find regions of connected pixels in a binary image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let \(G = (V, E)\) and \(G&amp;rsquo; = (V&amp;rsquo;, E&amp;rsquo;)\). \(G\) and \(G&amp;rsquo;\) are &lt;strong&gt;isomorphic&lt;/strong&gt; if there is a bijection between their vertices such that \((u, v) \in E\) if and only if \((f(u), f(v)) \in E&amp;rsquo;\).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;strong&gt;complete graph&lt;/strong&gt; is an undirected graph in which every pair of vertices is adjacent. A &lt;strong&gt;bipartite graph&lt;/strong&gt; is an undirected graph in which the vertices can be partitioned into two sets such that every edge connects a vertex in one set to a vertex in the other set.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;strong&gt;multi-graph&lt;/strong&gt; is a graph that allows multiple edges between the same pair of vertices. These are commonly in social network analysis, where multiple edges between two people can represent different types of relationships.&lt;/p&gt;
&lt;p&gt;TODO: Add figures demonstrating the above definitions&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;representations&#34;&gt;Representations&lt;/h3&gt;
&lt;p&gt;Graphs can be represented in many different ways. The most common representations are adjacency lists and adjacency matrices. Adjacency lists are more space-efficient for sparse graphs, while adjacency matrices are more space-efficient for dense graphs. Adjacency lists are also more efficient for finding the neighbors of a vertex, while adjacency matrices are more efficient for checking if an edge exists between two vertices.&lt;/p&gt;
&lt;h4 id=&#34;example-adjacency-matrix-and-reachability&#34;&gt;Example: Adjacency Matrix and Reachability&lt;/h4&gt;
&lt;p&gt;Consider the graph in the figure below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-17_21-08-29_directed_graph.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;A directed graph&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;A directed graph
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The adjacency matrix for this graph is:&lt;/p&gt;
&lt;p&gt;\begin{bmatrix}
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\
\end{bmatrix}&lt;/p&gt;
&lt;p&gt;The rows and columns represent the vertices in the graph. The value at row \(i\) and column \(j\) is 1 if there is an edge from vertex \(i\) to vertex \(j\). Otherwise, the value is 0. Let \(A\) be the adjacency matrix for a graph \(G\). The matrix \(A^k\) represents the number of paths of length \(k\) between each pair of vertices. For example, \(A^2\) for the above graph is:&lt;/p&gt;
&lt;p&gt;\begin{bmatrix}
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\
\end{bmatrix}&lt;/p&gt;
&lt;p&gt;The value at row \(i\) and column \(j\) is the number of paths of length 2 from vertex \(i\) to vertex \(j\). For example, is a path from vertex 0 to vertex 6 via 0 -&amp;gt; 3 -&amp;gt; 6.&lt;/p&gt;
&lt;h2 id=&#34;graph-traversal-algorithms&#34;&gt;Graph Traversal Algorithms&lt;/h2&gt;
&lt;h3 id=&#34;breadth-first-search&#34;&gt;Breadth First Search&lt;/h3&gt;
&lt;p&gt;We previously studied breadth-first search in the context of binary search trees. The algorithm is the same when applied on general graphs, but our perspective is slightly different now. The function studied before did not use node coloring. Let&amp;rsquo;s investigate the algorithm given by Cormen et al. in &lt;em&gt;Introduction to Algorithms&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The algorithm adds a color to each node to keep track of its state. The colors are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WHITE: The node has not been discovered yet.&lt;/li&gt;
&lt;li&gt;GRAY: The node has been discovered, but not all of its neighbors have been discovered.&lt;/li&gt;
&lt;li&gt;BLACK: The node has been discovered, and all of its neighbors have been discovered.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, every vertex is painted white and the distance is set to \(\infty\). The first node &lt;code&gt;s&lt;/code&gt; is immediately set to have 0 distance. The queue then starts with &lt;code&gt;s&lt;/code&gt;. While there are any grey vertices, dequeue the next available node and add its adjacent vertices to the queue. The distance of each adjacent vertex is set to the distance of the current vertex plus one. Once all of its neighbors have been discovered, the current vertex is painted black.&lt;/p&gt;
&lt;p&gt;The algorithm and an example run from Cormen et al. are shown below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bfs&lt;/span&gt;(G, s):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; u &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;V:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; WHITE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GRAY
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Q &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Queue()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Q&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;enqueue(s)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; Q&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;empty():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dequeue()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;adj[u]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; WHITE:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GRAY
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; u
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                Q&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;enqueue(v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;





&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-17_20-11-28_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Breadth First Search from Cormen et al.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Breadth First Search from Cormen et al.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h4 id=&#34;analysis&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;The running time of BFS is \(O(V + E)\), where \(V\) is the number of vertices and \(E\) is the number of edges. Each vertex is queued and dequeued once, so the queue operations take \(O(V)\) time. Each edge is examined once, so the edge operations take \(O(E)\) time. The total running time is \(O(V + E)\).&lt;/p&gt;
&lt;h3 id=&#34;depth-first-search&#34;&gt;Depth First Search&lt;/h3&gt;
&lt;p&gt;Like the BFS algorithm presented in &lt;em&gt;Introduction to Algorithms&lt;/em&gt; by Cormen et al., the DFS algorithm also uses colors to keep track of the state of each node. The colors are similar to the BFS algorithm, but the meaning is slightly different:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WHITE: The node has not been discovered yet.&lt;/li&gt;
&lt;li&gt;GRAY: The node has been visited for the first time.&lt;/li&gt;
&lt;li&gt;BLACK: The adjacency list of the node has been examined completely.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, all vertices are colored white. The time is set to 0. The function &lt;code&gt;dfs_visit&lt;/code&gt; is called on each vertex. The function is defined as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dfs_visit&lt;/span&gt;(G, u):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    time &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GRAY
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; G&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;adj[u]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; WHITE:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; u
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            dfs_visit(G, v)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    time &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When a node is discovered via &lt;code&gt;dfs_visit&lt;/code&gt;, the time is recorded and the color is changed to gray. The start and finish times are useful in understanding the structure of the graph. After all of the node&amp;rsquo;s neighbors have been discovered, the color is changed to black and the finish time is recorded. That is, the depth from the current node must be fully explored before it is considered finished. The figure below shows the progress of DFS on a directed graph.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-17_20-25-40_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Depth First Search from Cormen et al.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Depth First Search from Cormen et al.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Red-Black Trees</title>
      <link>https://ajdillhoff.github.io/notes/red_black_trees/</link>
      <pubDate>Sun, 15 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/red_black_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#definition&#34;&gt;Definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#operations&#34;&gt;Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exercises&#34;&gt;Exercises&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;Red-Black Trees are modified &lt;a href=&#34;https://ajdillhoff.github.io/notes/binary_search_trees/&#34;&gt;Binary Search Trees&lt;/a&gt; that maintain a balanced structure in order to guarantee that operations like search, insert, and delete run in \(O(\log n)\) time.&lt;/p&gt;
&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;
&lt;p&gt;A red-black tree is a binary search tree with the following properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Every node is either red or black.&lt;/li&gt;
&lt;li&gt;The root is black.&lt;/li&gt;
&lt;li&gt;Every &lt;code&gt;NULL&lt;/code&gt; leaf is black.&lt;/li&gt;
&lt;li&gt;If a node is red, then both its children are black.&lt;/li&gt;
&lt;li&gt;For each node, all simple paths from the node to descendant leaves contain the same number of black nodes.&lt;/li&gt;
&lt;/ol&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-15_11-50-31_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Red-Black Tree from CLRS Chapter 13.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Red-Black Tree from CLRS Chapter 13.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The only structural addition we need to make over a BST is the addition of a &lt;code&gt;color&lt;/code&gt; attribute to each node. This attribute can be either &lt;code&gt;RED&lt;/code&gt; or &lt;code&gt;BLACK&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Property 5 implies that the &lt;em&gt;black-height&lt;/em&gt; of a tree is an important property. This property is used to prove that the height of a red-black tree with \(n\) internal nodes is at most \(2 \log(n + 1)\).&lt;/p&gt;
&lt;h2 id=&#34;operations&#34;&gt;Operations&lt;/h2&gt;
&lt;h3 id=&#34;rotate&#34;&gt;Rotate&lt;/h3&gt;
&lt;p&gt;If a &lt;Binary Search Tree&gt; is balanced, then searching for a node takes \(O(\log n)\) time. However, if the tree is unbalanced, then searching can take \(O(n)\) time. When items are inserted or deleted from a tree, it can become unbalanced. Without any way to correct for this, a BST is less desirable unless the data will not change.&lt;/p&gt;
&lt;p&gt;When nodes are inserted or deleted into a red-black tree, the &lt;strong&gt;&lt;strong&gt;rotation&lt;/strong&gt;&lt;/strong&gt; operation is used in functions that maintain the red-black properties. This ensures that the tree remains balanced and that operations like search, insert, and delete run in \(O(\log n)\) time. The figure below shows the two types of rotations that can be performed on a red-black tree.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-15_17-28-19_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Rotations in a red-black tree (CLRS Figure 13.2).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Rotations in a red-black tree (CLRS Figure 13.2).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Python implementations of both left and right rotations are given below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;left_rotate&lt;/span&gt;(self, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;right_rotate&lt;/span&gt;(self, y):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Cormen et al. Figure 13.3 (below) shows the result of performing a left rotation on node \(x\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-15_18-07-53_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Left rotation on node (x) (CLRS Figure 13.3).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Left rotation on node (x) (CLRS Figure 13.3).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;A rotation only changes pointer assignments, so it takes \(O(1)\) time.&lt;/p&gt;
&lt;h3 id=&#34;insert&#34;&gt;Insert&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;insert&lt;/code&gt; operation in a red-black tree starts off identically to the &lt;code&gt;insert&lt;/code&gt; operation in a BST. The new node is inserted into the tree as a leaf node. Since the &lt;code&gt;NULL&lt;/code&gt; leaf nodes must be black by definition, the added node is colored red. The function in Python is shown below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insert&lt;/span&gt;(self, z):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;insert_fixup(z)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By adding the node and setting its color to red, we have possibly violated properties 2 and 4. Property 2 is violated if &lt;code&gt;z&lt;/code&gt; is the root. Property 4 is violated if the parent of the new node is also red. The final line of the function calls &lt;code&gt;insert_fixup&lt;/code&gt; to restore the red-black properties. It is defined as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insert_fixup&lt;/span&gt;(self, z):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; RED:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; RED:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left_rotate(z)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right_rotate(z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; RED:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right_rotate(z)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left_rotate(z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;case-1&#34;&gt;Case 1&lt;/h4&gt;
&lt;p&gt;Inside the &lt;code&gt;while&lt;/code&gt; loop, the first and second conditions are symmetric. One considers the case where &lt;code&gt;z&lt;/code&gt;&amp;rsquo;s parent is a left child, and the other considers the case where &lt;code&gt;z&lt;/code&gt;&amp;rsquo;s parent is a right child. Further, if &lt;code&gt;z&lt;/code&gt;&amp;rsquo;s parent is a left child, then we start by setting &lt;code&gt;y&lt;/code&gt; to &lt;code&gt;z&lt;/code&gt;&amp;rsquo;s &lt;em&gt;aunt&lt;/em&gt;. Let&amp;rsquo;s investigate the first &lt;code&gt;if&lt;/code&gt; statement, where &lt;code&gt;y&lt;/code&gt; is &lt;code&gt;RED&lt;/code&gt;. In this case, both &lt;code&gt;z&lt;/code&gt;&amp;rsquo;s parent and aunt are &lt;code&gt;RED&lt;/code&gt;. We can fix this by setting both to &lt;code&gt;BLACK&lt;/code&gt; and setting &lt;code&gt;z&lt;/code&gt;&amp;rsquo;s grandparent to &lt;code&gt;RED&lt;/code&gt;. This may violate property 2, so we set &lt;code&gt;z&lt;/code&gt; to its grandparent and repeat the loop.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; RED:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;case-2&#34;&gt;Case 2&lt;/h4&gt;
&lt;p&gt;If &lt;code&gt;y&lt;/code&gt; is &lt;code&gt;BLACK&lt;/code&gt;, then we need to consider the case where &lt;code&gt;z&lt;/code&gt; is a right child. In this case, we set &lt;code&gt;z&lt;/code&gt; to its parent and perform a left rotation. This automatically results in the third case, where &lt;code&gt;z&lt;/code&gt; is a left child.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left_rotate(z)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;case-3&#34;&gt;Case 3&lt;/h4&gt;
&lt;p&gt;If &lt;code&gt;z&lt;/code&gt; is a left child, then we set &lt;code&gt;z&lt;/code&gt;&amp;rsquo;s parent to &lt;code&gt;BLACK&lt;/code&gt; and its grandparent to &lt;code&gt;RED&lt;/code&gt;. Then we perform a right rotation on the grandparent.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right_rotate(z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Figure 13.4 from Cormen et al. demonstrates the addition of a node to a red-black tree. The node is inserted as a leaf node and colored red. Then &lt;code&gt;insert_fixup&lt;/code&gt; is called to restore the red-black properties.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-15_20-41-14_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;Inserting a node into a red-black tree (CLRS Figure 13.4).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;Inserting a node into a red-black tree (CLRS Figure 13.4).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The &lt;code&gt;insert&lt;/code&gt; operation takes \(O(\log n)\) time since it performs a constant number of rotations.&lt;/p&gt;
&lt;h3 id=&#34;delete&#34;&gt;Delete&lt;/h3&gt;
&lt;p&gt;Like the &lt;code&gt;delete&lt;/code&gt; operation of a BST, the &lt;code&gt;delete&lt;/code&gt; operation of a RBT uses a &lt;code&gt;transplant&lt;/code&gt; operation to replace the deleted node with its child. The &lt;code&gt;transplant&lt;/code&gt; operation is defined as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;transplant&lt;/span&gt;(self, u, v):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nil:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; u &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The full &lt;code&gt;delete&lt;/code&gt; operation follows a similar structure to that of its BST counterpart. There are a few distinct differences based on the color of the node being deleted. The function begins as follows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete&lt;/span&gt;(self, z):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y_original_color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The first line sets &lt;code&gt;y&lt;/code&gt; to the node to be deleted. The second line saves the color of &lt;code&gt;y&lt;/code&gt;. This is necessary because &lt;code&gt;y&lt;/code&gt; will be replaced by another node, and we need to know the color of the replacement node. The first two conditionals check if &lt;code&gt;z&lt;/code&gt; has any children. If there is right child, then the &lt;code&gt;z&lt;/code&gt; is replaced by the left child. If there is a left child, then &lt;code&gt;z&lt;/code&gt; is replaced by the right child. If &lt;code&gt;z&lt;/code&gt; has no children, then &lt;code&gt;z&lt;/code&gt; is replaced by &lt;code&gt;NULL&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transplant(z, z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transplant(z, z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If &lt;code&gt;z&lt;/code&gt; has two children, then we find the successor of &lt;code&gt;z&lt;/code&gt; and set &lt;code&gt;y&lt;/code&gt; to it. The successor is the node with the smallest key in the right subtree of &lt;code&gt;z&lt;/code&gt;. The successor is guaranteed to have at most one child, so we can use the code above to replace &lt;code&gt;y&lt;/code&gt; with its child. Then we replace &lt;code&gt;z&lt;/code&gt; with &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;minimum(z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y_original_color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right: &lt;span style=&#34;color:#75715e&#34;&gt;# y is farther down the tree&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transplant(y, y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transplant(z, y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The procedure kept track of &lt;code&gt;y_original_color&lt;/code&gt; to see if any violations occurred. This would happen if &lt;code&gt;y&lt;/code&gt; was originally &lt;code&gt;BLACK&lt;/code&gt; because the &lt;code&gt;transplant&lt;/code&gt; operation, or the deletion itself, could have violated the red-black properties. If &lt;code&gt;y_original_color&lt;/code&gt; is &lt;code&gt;BLACK&lt;/code&gt;, then we call &lt;code&gt;delete_fixup&lt;/code&gt; to restore the properties.&lt;/p&gt;
&lt;h3 id=&#34;delete-fixup&#34;&gt;Delete Fixup&lt;/h3&gt;
&lt;p&gt;If the node being deleted is &lt;code&gt;BLACK&lt;/code&gt;, then the following scenarios can occur. If &lt;code&gt;y&lt;/code&gt; is the root and a &lt;code&gt;RED&lt;/code&gt; child of &lt;code&gt;y&lt;/code&gt; becomes the new root, property 2 is violated. Let &lt;code&gt;x&lt;/code&gt; be a &lt;code&gt;RED&lt;/code&gt; child of &lt;code&gt;y&lt;/code&gt;, if a new parent of &lt;code&gt;x&lt;/code&gt; is &lt;code&gt;RED&lt;/code&gt;, then property 4 is violated. Lastly, removing &lt;code&gt;y&lt;/code&gt; may have caused a violation of property 5, since any path containing &lt;code&gt;y&lt;/code&gt; has 1 less &lt;code&gt;BLACK&lt;/code&gt; node in it.&lt;/p&gt;
&lt;p&gt;Correcting violation 5 can be done by &lt;em&gt;transferring&lt;/em&gt; the &lt;code&gt;BLACK&lt;/code&gt; property from &lt;code&gt;y&lt;/code&gt; to &lt;code&gt;x&lt;/code&gt;, the node that moves into &lt;code&gt;y&lt;/code&gt;&amp;rsquo;s original position. This requires us to allow nodes to take on multiple counts of colors. That is, if &lt;code&gt;x&lt;/code&gt; was already &lt;code&gt;BLACK&lt;/code&gt;, it becomes double &lt;code&gt;BLACK&lt;/code&gt;. If it was &lt;code&gt;RED&lt;/code&gt;, it becomes &lt;code&gt;RED-AND-BLACK&lt;/code&gt;. There is a good reason to this extension, as it will help us decide which case of &lt;code&gt;delete_fixup&lt;/code&gt; to use.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;delete_fixup&lt;/code&gt; function will restore violations of properties 1, 2, and 4. It is called after the &lt;code&gt;delete&lt;/code&gt; operation, and it takes a single argument, &lt;code&gt;x&lt;/code&gt;, which is the node that replaced the deleted node. It performs a series of rotations and color changes to restore the violated properties.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at the &lt;code&gt;delete_fixup&lt;/code&gt; function from the ground up. It is a little more complex than &lt;code&gt;insert_fixup&lt;/code&gt; because it has to handle the case where the node being deleted is &lt;code&gt;BLACK&lt;/code&gt;. In total, there are 4 distinct cases per side. Like &lt;code&gt;insert_fixup&lt;/code&gt;, it is enough to understand the first half, as the second is symmetric. The function begins as follows, where &lt;code&gt;x&lt;/code&gt; is a left child.&lt;/p&gt;
&lt;h4 id=&#34;case-1&#34;&gt;Case 1&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete_fixup&lt;/span&gt;(self, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; RED:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left_rotate(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the first case, &lt;code&gt;x&lt;/code&gt;&amp;rsquo;s sibling &lt;code&gt;w&lt;/code&gt; is &lt;code&gt;RED&lt;/code&gt;. If this is true, then &lt;code&gt;w&lt;/code&gt; must have two &lt;code&gt;BLACK&lt;/code&gt; subnodes. The colors of &lt;code&gt;w&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt;&amp;rsquo;s parent are then switched, and a left rotation is performed on &lt;code&gt;x&lt;/code&gt;&amp;rsquo;s parent. The result of case 1 converts to one of cases 2, 3, or 4. The figure below shows the result of the first case.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-15_22-07-04_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 5: &amp;lt;/span&amp;gt;Case 1 of `delete_fixup` (CLRS Figure 13.7).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 5: &lt;/span&gt;Case 1 of &lt;code&gt;delete_fixup&lt;/code&gt; (CLRS Figure 13.7).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h4 id=&#34;case-2&#34;&gt;Case 2&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If both of &lt;code&gt;w&lt;/code&gt;&amp;rsquo;s subnodes are &lt;code&gt;BLACK&lt;/code&gt; and both &lt;code&gt;w&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; are also black (actually, &lt;code&gt;x&lt;/code&gt; is doubly &lt;code&gt;BLACK&lt;/code&gt;), then there is an extra &lt;code&gt;BLACK&lt;/code&gt; node on the path from &lt;code&gt;w&lt;/code&gt; to the leaves. The colors of both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;w&lt;/code&gt; are switched, which leaves &lt;code&gt;x&lt;/code&gt; with a single &lt;code&gt;BLACK&lt;/code&gt; count and &lt;code&gt;w&lt;/code&gt; as &lt;code&gt;RED&lt;/code&gt;. The extra &lt;code&gt;BLACK&lt;/code&gt; property is transferred to &lt;code&gt;x&lt;/code&gt;&amp;rsquo;s parent. The figure below shows the result of the second case.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-16_07-57-36_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 6: &amp;lt;/span&amp;gt;Case 2 of `delete_fixup` (CLRS Figure 13.7).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 6: &lt;/span&gt;Case 2 of &lt;code&gt;delete_fixup&lt;/code&gt; (CLRS Figure 13.7).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h4 id=&#34;case-3&#34;&gt;Case 3&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right_rotate(w)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If &lt;code&gt;w&lt;/code&gt; is &lt;code&gt;BLACK&lt;/code&gt;, its left child is &lt;code&gt;RED&lt;/code&gt;, and its right child is &lt;code&gt;BLACK&lt;/code&gt;, then the colors of &lt;code&gt;w&lt;/code&gt; and its left child are switched. Then a right rotation is performed on &lt;code&gt;w&lt;/code&gt;. This rotation moves the &lt;code&gt;BLACK&lt;/code&gt; node to &lt;code&gt;w&lt;/code&gt;&amp;rsquo;s position, which is now the new sibling of &lt;code&gt;x&lt;/code&gt;. This leads directly to case 4. A visualization of case 3 is shown below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-16_08-01-26_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 7: &amp;lt;/span&amp;gt;Case 3 of `delete_fixup` (CLRS Figure 13.7).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 7: &lt;/span&gt;Case 3 of &lt;code&gt;delete_fixup&lt;/code&gt; (CLRS Figure 13.7).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h4 id=&#34;case-4&#34;&gt;Case 4&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left_rotate(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;At this point, &lt;code&gt;w&lt;/code&gt; is &lt;code&gt;BLACK&lt;/code&gt; and its right child is &lt;code&gt;RED&lt;/code&gt;. Also remember that &lt;code&gt;x&lt;/code&gt; still holds an extra &lt;code&gt;BLACK&lt;/code&gt; count. This last case performs color changes and a left rotation which remedy the extra &lt;code&gt;BLACK&lt;/code&gt; count. The figure below shows the result of case 4.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-16_08-12-46_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 8: &amp;lt;/span&amp;gt;Case 4 of `delete_fixup` (CLRS Figure 13.7).&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 8: &lt;/span&gt;Case 4 of &lt;code&gt;delete_fixup&lt;/code&gt; (CLRS Figure 13.7).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The full &lt;code&gt;delete_fixup&lt;/code&gt; function is shown below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete_fixup&lt;/span&gt;(self, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; RED:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left_rotate(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right_rotate(w)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left_rotate(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; RED:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right_rotate(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; BLACK:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RED
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left_rotate(w)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right_rotate(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;p)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BLACK
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;delete&lt;/code&gt; operation takes \(O(\log n)\) time since it performs a constant number of rotations. The &lt;code&gt;delete_fixup&lt;/code&gt; operation also takes \(O(\log n)\) time since it performs a constant number of color changes and at most 3 rotations. Case 2 of &lt;code&gt;delete_fixup&lt;/code&gt; could move the violation up the tree, but this would happen no more than \(O(\log n)\) times. In total, the &lt;code&gt;delete&lt;/code&gt; operation takes \(O(\log n)\) time.&lt;/p&gt;
&lt;h2 id=&#34;exercises&#34;&gt;Exercises&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Create a red-black tree class in Python that supports the operations discussed in these notes.&lt;/li&gt;
&lt;li&gt;Using the created class from exercise 1, implement a Hash Map class that uses a red-black tree for collision resolution via chaining.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Binary Search Trees</title>
      <link>https://ajdillhoff.github.io/notes/binary_search_trees/</link>
      <pubDate>Tue, 10 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/binary_search_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#binary-search-trees&#34;&gt;Binary Search Trees&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#operations&#34;&gt;Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#analysis&#34;&gt;Analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;A $n$-ary tree is a graph-based data structure in which each node has up to \(n\) subnodes. It is supported by the following operations (not exclusive):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Search&lt;/li&gt;
&lt;li&gt;Insert&lt;/li&gt;
&lt;li&gt;Delete&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tree-based data structures are defined by the following properties.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;&lt;strong&gt;size&lt;/strong&gt;&lt;/strong&gt; of a tree \(T\) is determined by the total number of nodes in \(T\).&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;&lt;strong&gt;root&lt;/strong&gt;&lt;/strong&gt; of a tree \(T\) is the starting point of \(T\).&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;&lt;strong&gt;leaf node&lt;/strong&gt;&lt;/strong&gt; of a tree \(T\) is a node that has no sub-nodes.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;&lt;strong&gt;height&lt;/strong&gt;&lt;/strong&gt; of a tree is determined by the length of the shortest path between the root of \(T\) and the lowest leaf node of \(T\).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we limit the number of subnodes each node may have to 2, the structure becomes known as a &lt;strong&gt;&lt;strong&gt;binary tree&lt;/strong&gt;&lt;/strong&gt;. Limiting the structure in this way is of interest to us because of the efficiency benefits seen in operations applied to binary trees. If we narrow the scope of these trees further, we can define a &lt;strong&gt;&lt;strong&gt;binary search tree&lt;/strong&gt;&lt;/strong&gt; whose search operation, as the name might suggest, runs in \(\Theta(lg n)\) worst-case time.&lt;/p&gt;
&lt;h2 id=&#34;binary-search-trees&#34;&gt;Binary Search Trees&lt;/h2&gt;
&lt;p&gt;A binary search tree is a regular binary tree with references to the left, right, and parent nodes, defined by the following property:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Let \(x\) be a node in a binary search tree. If \(y\) is a node in the left subtree of \(x\), then \(y.key \leq x.key\). If \(y\) is a node in the right subtree of \(x\), then \(y.key \geq x.key\).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Under this definition, operations such as search, insert, and delete can be performed in \(\Theta(lg n)\) worst-case time assuming that the tree is balanced. Later, we will explore a variant of the binary search tree that guarantees a balanced tree.&lt;/p&gt;
&lt;p&gt;A tree node implemented in Python might look like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Node&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self, key):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;operations&#34;&gt;Operations&lt;/h2&gt;
&lt;h3 id=&#34;traversals&#34;&gt;Traversals&lt;/h3&gt;
&lt;p&gt;Like any other graph-based structure, a tree can be traversed using either depth-first or breadth-first search. Only an inorder depth-first search is of interest for a binary search tree, as we will see below. Consider the given tree in the figure below. Performing an inorder traversal on this tree yields the keys in sorted order from smallest to largest.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;inorder_tree_walk&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        inorder_tree_walk(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        print(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        inorder_tree_walk(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Traversing the entire tree takes \(\Theta(n)\) time, as each node must be visited once. &lt;em&gt;Searching&lt;/em&gt; a tree, however, only takes \(\Theta(lg n)\) time. The search algorithm is defined recursively as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tree_search&lt;/span&gt;(x, k):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; k &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; k &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tree_search(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left, k)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tree_search(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right, k)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Consider the balanced tree shown in the figure below. If we search for the key 15, notice that after the first comparison with the root, the search space goes from 15 nodes to 7 nodes. After the second comparison, the search space goes from 7 nodes to 3 nodes. After the third comparison, the search space goes from 3 nodes to 1 node. This is the essence of binary search, and it is why the search operation runs in \(\Theta(lg n)\) time.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-10_20-05-13_binary_tree_full.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;A balanced binary search tree&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;A balanced binary search tree
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;minimum&#34;&gt;Minimum&lt;/h3&gt;
&lt;p&gt;In a BST, the minimum value is the leftmost node. Finding the minimum is as easy as traversing down the left branch until a leaf node is reached.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tree_minimum&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;maximum&#34;&gt;Maximum&lt;/h3&gt;
&lt;p&gt;In a BST, the maximum value is the rightmost node. Finding the maximum is as easy as traversing down the right branch until a leaf node is reached.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tree_maximum&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;successor&#34;&gt;Successor&lt;/h3&gt;
&lt;p&gt;The successor and predecessor operations are useful for the delete operation defined below. The successor of a node \(x\) is the node with the smallest key greater than \(x.key\). If \(x\) has a right subtree, then the successor of \(x\) is the minimum of the right subtree. If \(x\) has no right subtree, then the successor of \(x\) is the lowest ancestor of \(x\) whose left child is also an ancestor of \(x\).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tree_successor&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tree_minimum(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;predecessor&#34;&gt;Predecessor&lt;/h3&gt;
&lt;p&gt;The predecessor of a node \(x\) is the node with the largest key less than \(x.key\). If \(x\) has a left subtree, then the predecessor of \(x\) is the maximum of the left subtree. If \(x\) has no left subtree, then the predecessor of \(x\) is the lowest ancestor of \(x\) whose right child is also an ancestor of \(x\).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tree_predecessor&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tree_maximum(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;insert&#34;&gt;Insert&lt;/h3&gt;
&lt;p&gt;Inserting an item into a binary search tree follows the same logic as traversal. Starting at the root, the key is compared to see if it is greater than the root&amp;rsquo;s key. If so, recursively traverse down the right branch. If not, recursively traverse down the left branch. This process continues until a leaf node is reached, at which point the new node is inserted as a child of the leaf node.&lt;/p&gt;
&lt;p&gt;This process will not necessarily result in a balanced tree. In fact, if the keys are inserted in sorted order, the tree will be a linked list. This is the worst-case scenario for a binary search tree, as the search operation will then run in \(\Theta(n)\) time.&lt;/p&gt;
&lt;p&gt;The full algorithm is given below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tree_insert&lt;/span&gt;(T, z):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; T&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        T&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;delete&#34;&gt;Delete&lt;/h3&gt;
&lt;p&gt;Deleting a node is not a straightforward as insert. Depending on the structure of the subtree, one of three cases must be considered.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If \(z\) has no subnodes, simply remove \(z\) from the tree.&lt;/li&gt;
&lt;li&gt;If \(z\) has one subnode, replace \(z\) with its subnode.&lt;/li&gt;
&lt;li&gt;If \(z\) has two subnodes, replace \(z\) with its successor. It is a bit more complicated than this, as we explore below.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In case 3, node \(z\) has both a left and right subnode. The first step is to find the successor of \(z\), \(y\). Since \(z\) has 2 subnodes, its successor has no left subnode (&lt;strong&gt;&lt;strong&gt;convince yourself of this&lt;/strong&gt;&lt;/strong&gt;). Likewise, its predecessor has no right subnode. If \(y\) is the right subnode of \(z\), replace \(z\) by \(y\).&lt;/p&gt;
&lt;p&gt;If \(y\) is not the right subnode of \(z\), it is somewhere further down the right branch. In this case, replace \(y\) by its right subnode before replacing \(z\) by \(y\). The figure below shows the removal of node 12 from the tree in the figure above.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-10_23-03-23_binary_tree_delete.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Deleting node 12 from the tree&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Deleting node 12 from the tree
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Even though only 1 node was moved (13 to 12&amp;rsquo;s old position), the process of deleting a node actually involves &lt;strong&gt;&lt;strong&gt;transplanting&lt;/strong&gt;&lt;/strong&gt; a subtree to a new position. This is defined algorithmically as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;transplant&lt;/span&gt;(T, u, v):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        T&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;root &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; u &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        v&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the code above, &lt;code&gt;u&lt;/code&gt; is the node to be replaced, and &lt;code&gt;v&lt;/code&gt; is the node to replace it. Updating &lt;code&gt;v&lt;/code&gt;&amp;rsquo;s left and right subnodes are done in the calling function &lt;code&gt;tree_delete&lt;/code&gt;, as seen below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tree_delete&lt;/span&gt;(T, z):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:  &lt;span style=&#34;color:#75715e&#34;&gt;# Case 1 and 2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        transplant(T, z, z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;: &lt;span style=&#34;color:#75715e&#34;&gt;# Also case 1 and 2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        transplant(T, z, z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;: &lt;span style=&#34;color:#75715e&#34;&gt;# Case 3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tree_minimum(z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right) &lt;span style=&#34;color:#75715e&#34;&gt;# get successor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            transplant(T, y, y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        transplant(T, z, y)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; z&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;analysis&#34;&gt;Analysis&lt;/h2&gt;
&lt;p&gt;Insert, delete, and search all run in \(\Theta(h)\) time, where \(h\) is the height of the tree. If the tree is balanced, \(h = \Theta(lg n)\), and all operations run in \(\Theta(lg n)\) time. If the tree is not balanced, \(h = \Theta(n)\), and all operations run in \(\Theta(n)\) time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Data Structures</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_data_structures/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/introduction_to_data_structures/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction-to-data-structures&#34;&gt;Introduction to Data Structures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#review-pointers&#34;&gt;Review: Pointers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#arrays&#34;&gt;Arrays&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#matrices&#34;&gt;Matrices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#multi-dimensional-arrays&#34;&gt;Multi-Dimensional Arrays&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#stacks&#34;&gt;Stacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#queues&#34;&gt;Queues&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;introduction-to-data-structures&#34;&gt;Introduction to Data Structures&lt;/h2&gt;
&lt;p&gt;Data structures are fundamental concepts in computer science that allow us to organize and store data in a way that enables efficient access and modification. They are essential building blocks for creating efficient and sophisticated computer programs and databases. Different types of data structures include arrays, linked lists, stacks, queues, trees, graphs, and many more, each serving a specific purpose and suited to specific applications.&lt;/p&gt;
&lt;p&gt;Understanding data structures is therefore important because they are used in almost every software application. For instance, social media applications use data structures to store user information and their connections, while search engines use them to index and retrieve web pages quickly. The choice of the right data structure significantly impacts the performance, scalability, and resource utilization of software applications.&lt;/p&gt;
&lt;p&gt;Having a strong grasp of data structures and their properties is critical for anyone working with software or data in general. Through studying the benefits and limitations of each data structure, you will be equipped to analyze the efficacy of existing systems as well as make the right choice when developing new ones.&lt;/p&gt;
&lt;h3 id=&#34;why-do-we-need-so-many&#34;&gt;Why Do We Need So Many?&lt;/h3&gt;
&lt;p&gt;There are many data structures available because no single dataset works best for all cases. Each data structure has its unique characteristics, advantages, and disadvantages. These differences can often be evaluated quantitatively, providing rigorous backing when selecting the appropriate one for the task at hand.&lt;/p&gt;
&lt;p&gt;For example, arrays are excellent when the size of the data is known and constant, but they are not efficient when it comes to frequent insertions and deletions. Linked lists, on the other hand, allow for efficient insertions and deletions but are not as quick as arrays when it comes to accessing elements. Trees are invaluable when we need to maintain a sorted list of data and perform quick searches, insertions, and deletions, while hash tables are optimal for scenarios where we need to perform fast lookups.&lt;/p&gt;
&lt;h2 id=&#34;review-pointers&#34;&gt;Review: Pointers&lt;/h2&gt;
&lt;h3 id=&#34;what-are-pointers&#34;&gt;What are Pointers?&lt;/h3&gt;
&lt;p&gt;Pointers are variables in programming that store the memory address of another variable. They are a powerful feature in many programming languages, including C and C++, allowing programmers to directly access memory locations and manipulate data efficiently. Pointers are crucial for implementing dynamic data structures like linked lists, trees, and graphs.&lt;/p&gt;
&lt;p&gt;In Python, pointers are not exposed explicitly as in languages like C, but references, which are similar to pointers, are used to hold the memory address of objects. Understanding the concept of pointers and references is essential for managing memory effectively and avoiding issues like memory leaks and dangling pointers in languages that allow direct memory manipulation. Even if we are not dealing with pointers directly, studying them is beneficial for understanding algorithms and data structures in general.&lt;/p&gt;
&lt;h3 id=&#34;how-are-they-represented&#34;&gt;How are They Represented?&lt;/h3&gt;
&lt;p&gt;In languages like C, pointers are represented using the asterisk (*) symbol, and the address operator (&amp;amp;) is used to retrieve the memory address of a variable. For example, &lt;code&gt;int *p;&lt;/code&gt; declares a pointer to an integer, and &lt;code&gt;p = &amp;amp;x;&lt;/code&gt; assigns the address of the variable &lt;code&gt;x&lt;/code&gt; to the pointer &lt;code&gt;p&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In Python, pointers are not explicitly represented, but references to objects are used to achieve similar functionality. For instance, when a list is assigned to a new variable, the new variable holds a reference to the same list object, not a copy of the list. Any modifications made through one variable are reflected in the other.&lt;/p&gt;
&lt;h2 id=&#34;arrays&#34;&gt;Arrays&lt;/h2&gt;
&lt;h3 id=&#34;how-are-arrays-represented-in-memory&#34;&gt;How are Arrays Represented in Memory?&lt;/h3&gt;
&lt;p&gt;Arrays are fundamental data structures that store elements of the same type in contiguous memory locations. The elements can be accessed randomly by indexing into the array. In memory, an array is represented as a block of memory cells, each holding an element of the array placed side by side. The size of each cell is determined by the size of the array&amp;rsquo;s element type.&lt;/p&gt;
&lt;p&gt;The base address of the array is the memory address of the first element (index 0), and it is used, along with the index and the size of each element, to calculate the address of any element in the array. For example, if the base address is `B`, the size of each element is `S`, and the index of the element is `i`, the address of the element can be calculated as `B + (i * S)`.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-02_17-50-19_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Memory layout of an integer array of size 8.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Memory layout of an integer array of size 8.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;how-many-bytes-does-each-element-use&#34;&gt;How Many Bytes Does Each Element Use?&lt;/h3&gt;
&lt;p&gt;The number of bytes used by each element in an array depends on the data type of the elements. For example, in most systems, an &lt;code&gt;int&lt;/code&gt; uses 4 bytes, a &lt;code&gt;char&lt;/code&gt; uses 1 byte, and a &lt;code&gt;double&lt;/code&gt; uses 8 bytes. When an array is declared, the total memory allocated for the array is the product of the number of elements and the size of each element.&lt;/p&gt;
&lt;p&gt;In Python, the &lt;code&gt;sys&lt;/code&gt; module can be used to find the size of an object in bytes. However, Pythons dynamic typing and object-oriented nature mean that the size of an array element can vary significantly, as each element is an object that can have additional overhead and can hold references to other objects.&lt;/p&gt;
&lt;p&gt;Since Python does not expose pointers explicitly, we can safely program efficient programs without worrying about making common mistakes related to pointers and memory management.&lt;/p&gt;
&lt;h3 id=&#34;how-are-arrays-indexed&#34;&gt;How are Arrays Indexed?&lt;/h3&gt;
&lt;p&gt;Arrays are indexed using a zero-based indexing system, where the first element is accessed using index 0, the second element with index 1, and so on. To access an element at a specific index, the address of the element is calculated using the base address of the array, the size of each element, and the index of the element.&lt;/p&gt;
&lt;p&gt;In languages that support pointers, the address of an element in an array can be calculated using pointer arithmetic. If &lt;code&gt;p&lt;/code&gt; is a pointer to the base address of the array, and &lt;code&gt;i&lt;/code&gt; is the index of the element, the address of the element can be calculated as &lt;code&gt;p + i&lt;/code&gt;, where &lt;code&gt;i&lt;/code&gt; is automatically scaled by the size of the array&amp;rsquo;s element type.&lt;/p&gt;
&lt;h2 id=&#34;matrices&#34;&gt;Matrices&lt;/h2&gt;
&lt;h3 id=&#34;fixed-sized-arrays-vs-dot-ragged-arrays&#34;&gt;Fixed-sized Arrays vs. Ragged Arrays&lt;/h3&gt;
&lt;p&gt;Matrices are two-dimensional arrays that can be represented using fixed-sized arrays or ragged arrays. A fixed-sized array is a regular matrix where each row has the same number of columns, and it is represented in memory as a contiguous block. It allows for efficient access to elements using row and column indices but can waste memory if the matrix is sparse.&lt;/p&gt;
&lt;p&gt;A ragged array, on the other hand, is an irregular matrix where each row can have a different number of columns. It is represented using an array of pointers, where each pointer points to a one-dimensional array representing a row of the matrix. Ragged arrays are more memory-efficient for sparse matrices but can be more complex to manage and traverse.&lt;/p&gt;
&lt;p&gt;Choosing between fixed-sized and ragged arrays depends on the requirements of the application, the characteristics of the matrix, and the trade-offs between memory efficiency and complexity. Understanding the differences between the two representations is crucial for implementing matrices effectively and optimizing memory usage.&lt;/p&gt;
&lt;h3 id=&#34;flat-indexing-back-and-forth&#34;&gt;Flat Indexing, Back and Forth&lt;/h3&gt;
&lt;p&gt;Flat indexing is a technique used to represent a two-dimensional array or matrix using a one-dimensional array. In this representation, the elements of the matrix are stored in a single array in row-major or column-major order, and the two-dimensional indices (row and column) are mapped to a single index in the one-dimensional array.&lt;/p&gt;
&lt;p&gt;For a matrix with &lt;code&gt;M&lt;/code&gt; rows and &lt;code&gt;N&lt;/code&gt; columns, the mapping from two-dimensional indices to a one-dimensional index in row-major order is done using the formula &lt;code&gt;index = (row * N) + column&lt;/code&gt;, and in column-major order using the formula &lt;code&gt;index = (column * M) + row&lt;/code&gt;. Flat indexing allows for efficient memory utilization and easy serialization of matrices but requires conversion between one-dimensional and two-dimensional indices.&lt;/p&gt;
&lt;h3 id=&#34;python-example-of-matrices&#34;&gt;Python Example of Matrices&lt;/h3&gt;
&lt;p&gt;In Python, matrices can be represented using lists of lists, where each inner list represents a row of the matrix. Elements can be accessed and modified using two indices, one for the row and one for the column. For example, to create a 2x3 matrix and access the element in the second row and third column, you can do the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;element &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; matrix[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# access value 6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;NumPy also provides support for multi-dimensional arrays and matrices along with a host of functions to perform operations on them. Using Numpy, you can create a matrix and access its elements as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;element &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; matrix[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# access value 6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;multi-dimensional-arrays&#34;&gt;Multi-Dimensional Arrays&lt;/h2&gt;
&lt;h3 id=&#34;introduction-to-multi-dimensional-arrays&#34;&gt;Introduction to Multi-Dimensional Arrays&lt;/h3&gt;
&lt;p&gt;Multi-dimensional arrays are arrays of more than 1 dimension. They are used to represent complex data structures like matrices, tensors, and tables. They are crucial for various applications, including scientific computing, image processing, and machine learning, where data is often multi-dimensional.&lt;/p&gt;
&lt;p&gt;In a multi-dimensional array, each element is identified by multiple indices, one for each dimension of the array. For example, in a two-dimensional array representing a matrix, each element is identified by two indices representing the row and column of the element. The number of dimensions and the size of each dimension determine the structure and capacity of the array.&lt;/p&gt;
&lt;p&gt;Different languages have different approaches to handling multi-dimensional arrays. C, for example, arranges the memory of any array contiguously. Java and Python use jagged arrays, where the row lengths can differ in size. The data in each row might be contiguous, but the entire array is not.&lt;/p&gt;
&lt;h3 id=&#34;numpy-arrays-and-their-representation&#34;&gt;NumPy Arrays and Their Representation&lt;/h3&gt;
&lt;p&gt;A NumPy array is represented in memory as a contiguous block, and it allows for efficient access and manipulation of elements using multiple indices. The shape of the array, represented as a tuple of integers, determines the number of dimensions and the size of each dimension of the array.&lt;/p&gt;
&lt;p&gt;To determine how to index the contiguous stream of values represented as an $n$-dimensional array, each &lt;code&gt;np.array&lt;/code&gt; specifies the &lt;code&gt;strides&lt;/code&gt; for each dimension. Consider the following array with shape &lt;code&gt;(2, 3, 4)&lt;/code&gt; and data type &lt;code&gt;int32&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;               [&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;               [&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              [[&lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;               [&lt;span style=&#34;color:#ae81ff&#34;&gt;17&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;               [&lt;span style=&#34;color:#ae81ff&#34;&gt;21&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;]]], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;strides&lt;/code&gt; of the array are &lt;code&gt;(48, 16, 4)&lt;/code&gt;, which means that to move to the next depth, we need to move 48 bytes, to move to the next row, we need to move 16 bytes, and to move to the next column, we need to move 4 bytes. The &lt;code&gt;strides&lt;/code&gt; are calculated based on the size of each element and the shape of the array.&lt;/p&gt;
&lt;h3 id=&#34;python-example-with-numpy&#34;&gt;Python Example with NumPy&lt;/h3&gt;
&lt;p&gt;Heres an example of how to create a two-dimensional array (matrix) using Numpy and how to access its elements:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Creating a 2x3 Numpy array&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Accessing the element in the second row and third column&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;element &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; array[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# element will be 6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;NumPy also provides various functions to perform operations on arrays, such as reshaping, transposing, and aggregating. For example, to calculate the sum of all elements in the array, you can use the &lt;code&gt;np.sum&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;total &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(array)  &lt;span style=&#34;color:#75715e&#34;&gt;# total will be 21&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;stacks&#34;&gt;Stacks&lt;/h2&gt;
&lt;h3 id=&#34;how-are-stacks-represented-with-an-array&#34;&gt;How are Stacks Represented with an Array?&lt;/h3&gt;
&lt;p&gt;A stack is a linear data structure that follows the Last In First Out (LIFO) principle, meaning the last element added to the stack is the first one to be removed. Stacks can be easily implemented using arrays, where elements are added and removed from one end of the array, known as the top of the stack.&lt;/p&gt;
&lt;p&gt;When representing a stack with an array, one must keep track of the index of the top of the stack. Elements are added to the stack by placing them at the position indicated by the top index and then incrementing the top index. Elements are removed from the stack by decrementing the top index and then accessing the element at that position.&lt;/p&gt;
&lt;h3 id=&#34;difference-between-using-the-beginning-or-the-end-of-the-array-as-the-top&#34;&gt;Difference Between Using the Beginning or the End of the Array as the Top&lt;/h3&gt;
&lt;p&gt;When implementing a stack using an array, one can choose to use either the beginning or the end of the array as the top of the stack. The choice affects the implementation of the push and pop operations and the way the top index is managed.&lt;/p&gt;
&lt;p&gt;If the beginning of the array is used as the top, elements are added and removed from the first position of the array, and the other elements must be shifted to make room or fill the gap. This can lead to higher time complexity for push and pop operations. If the end of the array is used as the top, elements are added and removed from the last position of the array, allowing for constant-time push and pop operations without the need to shift other elements.&lt;/p&gt;
&lt;h3 id=&#34;python-example-of-stack-with-array&#34;&gt;Python Example of Stack with Array&lt;/h3&gt;
&lt;p&gt;Heres an example of how to implement a stack using a Python list, with the end of the list as the top of the stack:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stack &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []  &lt;span style=&#34;color:#75715e&#34;&gt;# Initializing an empty stack&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stack&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# Pushing an element onto the stack&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stack&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# Pushing another element onto the stack&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;top_element &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stack&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()  &lt;span style=&#34;color:#75715e&#34;&gt;# Popping the top element from the stack, top_element will be 2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This implementation allows for efficient and simple push and pop operations, with constant time complexity. However, the size of the stack is limited by the available memory, and care must be taken to handle underflow and overflow conditions.&lt;/p&gt;
&lt;p&gt;Understanding how to implement and use stacks is crucial for solving problems that involve reversing, balancing, or processing data in a LIFO manner. Stacks are a versatile and fundamental data structure used in various applications, including expression evaluation, syntax parsing, and undo mechanisms.&lt;/p&gt;
&lt;h2 id=&#34;queues&#34;&gt;Queues&lt;/h2&gt;
&lt;h3 id=&#34;how-are-queues-represented-with-an-array&#34;&gt;How are Queues Represented with an Array?&lt;/h3&gt;
&lt;p&gt;A queue is a linear data structure that follows the First In First Out (FIFO) principle, meaning the first element added to the queue is the first one to be removed. Queues can be implemented using arrays, where elements are added at the rear and removed from the front.&lt;/p&gt;
&lt;p&gt;When representing a queue with an array, two indices are maintained, one for the front and one for the rear of the queue. Elements are enqueued by placing them at the position indicated by the rear index and then incrementing the rear index. Elements are dequeued by accessing the element at the front index and then incrementing the front index.&lt;/p&gt;
&lt;h3 id=&#34;downside-to-using-one-side-of-the-array-as-the-front-and-the-other-as-the-rear&#34;&gt;Downside to Using One Side of the Array as the Front and the Other as the Rear&lt;/h3&gt;
&lt;p&gt;When implementing a queue using an array, using one side of the array as the front and the other as the rear can lead to inefficient use of space. Once elements are dequeued from the front, the space they occupied cannot be reused, and overflow can occur even if there is free space at the front of the array.&lt;/p&gt;
&lt;p&gt;To overcome this limitation, a circular queue can be implemented, where the front and rear indices wrap around to the beginning of the array when they reach the end. This allows for efficient use of space and avoids overflow as long as there is free space in the array. However, it requires more complex index management and can be harder to implement correctly.&lt;/p&gt;
&lt;h3 id=&#34;more-efficient-approach-by-using-a-reference-to-a-head-and-tail&#34;&gt;More Efficient Approach by Using a Reference to a Head and Tail&lt;/h3&gt;
&lt;p&gt;A more efficient approach to implementing a queue is to use a linked list, where each element holds a reference to the next element in the queue. This allows for dynamic resizing of the queue and efficient enqueue and dequeue operations, without the need for complex index management or wasted space.&lt;/p&gt;
&lt;p&gt;In this approach, two pointers are maintained, one for the head (front) and one for the tail (rear) of the queue. Elements are enqueued by adding them at the position pointed to by the tail pointer and updating the tail pointer to the new element. Elements are dequeued by accessing the element pointed to by the head pointer and updating the head pointer to the next element.&lt;/p&gt;
&lt;p&gt;This same approach can be done by using indices for the head and tail. The data itself is &amp;ldquo;circular&amp;rdquo; in the sense that the indices wrap around to the beginning of the array when they reach the end. This allows for efficient use of space and avoids overflow as long as there is free space in the array.&lt;/p&gt;
&lt;h3 id=&#34;python-example-of-a-queue-using-an-array&#34;&gt;Python Example of a Queue using an Array&lt;/h3&gt;
&lt;p&gt;Heres an example of how to implement a simple queue using a Python list, with the front at the beginning of the list and the rear at the end of the list:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; collections &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; deque
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;queue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deque()  &lt;span style=&#34;color:#75715e&#34;&gt;# Initializing an empty queue&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;queue&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# Enqueueing an element&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;queue&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# Enqueueing another element&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;front_element &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; queue&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;popleft()  &lt;span style=&#34;color:#75715e&#34;&gt;# Dequeueing the front element from the queue, front_element will be 1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This implementation uses the &lt;code&gt;deque&lt;/code&gt; class from the &lt;code&gt;collections&lt;/code&gt; module, which allows for efficient appending and popping from both ends of the list. It provides a simple and versatile way to implement a queue in Python, with dynamic resizing and constant-time enqueue and dequeue operations.&lt;/p&gt;
&lt;p&gt;Understanding how to implement and use queues is essential for solving problems that involve processing data in a FIFO manner. Queues are a fundamental and versatile data structure used in various applications, including task scheduling, order processing, and breadth-first search.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linked Lists</title>
      <link>https://ajdillhoff.github.io/notes/linked_lists/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/linked_lists/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#singly-linked-lists&#34;&gt;Singly-Linked Lists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#doubly-linked-lists&#34;&gt;Doubly-Linked Lists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#operations&#34;&gt;Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exercises&#34;&gt;Exercises&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;p&gt;A linked list is a &lt;strong&gt;dynamic&lt;/strong&gt; and &lt;strong&gt;aggregate&lt;/strong&gt; data structure made up of a collection of nodes. The nodes of a linked list can store any data type and are not enforced to contain the same data type. A basic &lt;code&gt;node&lt;/code&gt; structure may be defined as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; node {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;data;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; node &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;next;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;};
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;singly-linked-lists&#34;&gt;Singly-Linked Lists&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;singly-linked list&lt;/strong&gt;, the most basic form, has a reference to the first node in the list, called the head, and a single link between each node.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-10-03_16-52-48_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Diagram of a linked list with 3 nodes. The top sections contain data and the bottom sections contain pointers to the next node.&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Diagram of a linked list with 3 nodes. The top sections contain data and the bottom sections contain pointers to the next node.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The definition of a linked list node allows the list to grow dynamically. Nodes can be added at any time to any position in the node, as long as a reference to the node before the new one is known. The last node in a list points to &lt;code&gt;NULL&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;doubly-linked-lists&#34;&gt;Doubly-Linked Lists&lt;/h2&gt;
&lt;p&gt;More commonly, linked lists are &lt;strong&gt;doubly-linked&lt;/strong&gt; in that there is a link to the next node and a link to the previous node. This allows for more flexibility in traversing the list, but requires more memory to store the extra link. A standard implementation will also keep a reference to both the head and the tail of the list. This permits efficient insertion and deletion at both ends of the list.&lt;/p&gt;
&lt;h2 id=&#34;operations&#34;&gt;Operations&lt;/h2&gt;
&lt;h3 id=&#34;insertion&#34;&gt;Insertion&lt;/h3&gt;
&lt;p&gt;A new node can be inserted either at the beginning, the end, or somewhere in between. Inserting at the beginning or end is a constant time operation, but inserting in the middle requires traversing the list to find the correct position. To insert at the beginning, the new node&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is updated to the old head and the head is updated to the new node.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insert_at_beginning&lt;/span&gt;(head, data):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Node(data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; head
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    head &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To insert at the end without a reference to the tail, the list must be traversed to find the last node. The new node&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is set to &lt;code&gt;NULL&lt;/code&gt; and the last node&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is set to the new node.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insert_at_end&lt;/span&gt;(head, data):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Node(data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        head &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        last_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; head
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            last_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To insert at the end with a reference to the tail, the new node&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is set to &lt;code&gt;NULL&lt;/code&gt; and the tail&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is set to the new node. The tail is then updated to the new node.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insert_at_end&lt;/span&gt;(head, tail, data):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Node(data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        head &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        tail &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        tail&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        tail &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To insert in the middle, the list must be traversed to find the correct position. The new node&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is set to the next node and the previous node&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is set to the new node.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insert_in_middle&lt;/span&gt;(head, data, position):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    new_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Node(data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        head &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        current_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; head
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(position &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            current_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; current_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        new_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; current_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        current_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;searching&#34;&gt;Searching&lt;/h3&gt;
&lt;p&gt;Searching a linked list is a linear time operation. The list is traversed until the desired node is found or the end of the list is reached.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;search&lt;/span&gt;(head, data):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    current_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; head
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; current_node &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; current_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; data:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; current_node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        current_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; current_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;deletion&#34;&gt;Deletion&lt;/h3&gt;
&lt;p&gt;Deletion is similar to insertion. A node can be deleted from the beginning, the end, or somewhere in between. Deleting at the beginning or end is a constant time operation, but deleting in the middle requires traversing the list to find the correct position. To delete at the beginning, the head is updated to the second node and the first node is deleted.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete_at_beginning&lt;/span&gt;(head):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        head &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; head&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To delete at the end without a reference to the tail, the list must be traversed to find the last node. The second to last node&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is set to &lt;code&gt;NULL&lt;/code&gt; and the last node is deleted.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete_at_end&lt;/span&gt;(head):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            head &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            last_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; head
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                last_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To delete at the end with a reference to the tail, the tail is updated to the second to last node and the last node is deleted.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete_at_end&lt;/span&gt;(head, tail):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            head &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            tail &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            last_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; head
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                last_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            last_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            tail &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; last_node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To delete in the middle, the list must be traversed to find the correct position. The previous node&amp;rsquo;s &lt;code&gt;next&lt;/code&gt; reference is set to the next node and the current node is deleted.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete_in_middle&lt;/span&gt;(head, position):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; head &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        current_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; head
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(position &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            current_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; current_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        current_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; current_node&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;next
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;exercises&#34;&gt;Exercises&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Reverse a singly-linked list in linear time and constant space.&lt;/li&gt;
&lt;li&gt;Implement a queue using a linked list.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Complexity Analysis</title>
      <link>https://ajdillhoff.github.io/notes/complexity_analysis/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/complexity_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-notation-of-complexity-analysis&#34;&gt;The notation of complexity analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#formal-definition-of-asymptotic-notation&#34;&gt;Formal Definition of Asymptotic Notation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#common-functions&#34;&gt;Common Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;the-notation-of-complexity-analysis&#34;&gt;The notation of complexity analysis&lt;/h2&gt;
&lt;h3 id=&#34;o-notation&#34;&gt;$O$-notation&lt;/h3&gt;
&lt;p&gt;$O$-notation, often referred to as &amp;ldquo;Big Oh&amp;rdquo; notation, describes an upper bound on the behavior of a function. It really means that the function &lt;em&gt;will not grow faster&lt;/em&gt; than the a given rate. This rate is typically the highest-order term in the function, and is often referred to as the &amp;ldquo;dominant term&amp;rdquo; or &amp;ldquo;dominant function&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;For example, the function \(f(n) = 3n^2 + 2n + 1\) has a dominant term of \(n^2\), and so we would say that \(f(n) = O(n^2)\). We could also accurately describe \(f(n)\) as \(O(n^3)\) since it technically does not grow at a faster rate than \(n^3\), but this is less common as it misleads the reader into thinking that the function is bounded at \(n^3\).&lt;/p&gt;
&lt;h3 id=&#34;and-omega-notation&#34;&gt;$$-notation&lt;/h3&gt;
&lt;p&gt;$$-notation is used to describe the lower bound on the asymptotic behavior of a function. Specifically, it means that the function grows &lt;em&gt;at least as fast&lt;/em&gt; as the given rate. The function \(f(n) = 3n^2 + 2n + 1\) grows at least as fast as \(n^2\), so we would say that \(f(n) = \Omega(n^2)\). It does not grow as fast as \(n^3\), however.&lt;/p&gt;
&lt;p&gt;Just like $O$-notation, we can abuse this definition and say that something that grows at least as fast as \(n^2\) also grows as fast as \(n\). This would lead the reader to believe that the function is bounded at \(n\), which is not true. For this reason, we typically use the tightest bound possible.&lt;/p&gt;
&lt;h3 id=&#34;and-theta-notation&#34;&gt;$$-notation&lt;/h3&gt;
&lt;p&gt;$$-notation gives a tightly bound characterization of a function&amp;rsquo;s behavior. It gives the rate of growth within a constant factor bounded above as well as constant factor bounded below.&lt;/p&gt;
&lt;p&gt;To show that a function is \(\Theta(f(n))\), we must show that it is both \(O(f(n))\) and \(\Omega(f(n))\). Taking our example from above, the function \(f(n) = 3n^2 + 2n + 1\) is \(\Theta(n^2)\).&lt;/p&gt;
&lt;h3 id=&#34;example-insertion-sort&#34;&gt;Example: Insertion Sort&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s put this notation to work and characterize the running time of insertion sort. We&amp;rsquo;ll start by writing out the pseudocode for the algorithm:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insertion_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(A)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; A[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[j]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;From our &lt;a href=&#34;https://ajdillhoff.github.io/notes/introduction_to_complexity_analysis/&#34;&gt;Introduction to Algorithms&lt;/a&gt; lecture, we already know that the outer loop runs \((n-1)\) times (although the loop is checked \(n\) times). This is not dependent on the order of the \(n\) inputs either. The inner loop is dependent on the values of our input. It could run anywhere between 0 and \(i-1\) times. In the worst case, we saw that it would run \(n-1\) times as well. With this, we concluded that the running time of insertion sort is \(O(n^2)\). Since this was derived for the worst-case, it is reasonable to say that insertion sort is \(O(n^2)\) for all cases.&lt;/p&gt;
&lt;p&gt;The key to the number of operations that the inner loop takes is &lt;code&gt;A[j + 1] = A[j]&lt;/code&gt;, or the number of times a value is shifted to the right. Given an input of \(n\) elements in the worst-case scenario, we can split the input into 3 partitions where the largest \(\lfloor\frac{n}{4}\rfloor\) values are in the first partition. The second partition has size \(\lceil\frac{n}{2}\rceil\), and the last partition has size \(\lfloor\frac{n}{4}\rfloor\). By using the floor and ceiling functions, we can accommodate for odd values of \(n\).&lt;/p&gt;
&lt;p&gt;When the array is finally sorted, the largest \(\lfloor\frac{n}{4}\rfloor\) values will be in the last partition. That means that they would have passed through the middle \(\lceil\frac{n}{2}\rceil\) values one at a time. Therefore, we can state that the worst-case is proportional to&lt;/p&gt;
&lt;p&gt;\[
\left(\left\lfloor\frac{n}{4}\right\rfloor\right)\left(\left\lceil\frac{n}{2}\right\rceil\right) \leq \frac{n^2}{8}.
\]&lt;/p&gt;
&lt;p&gt;This is \(\Omega(n^2)\), so we can conclude that insertion sort is \(\Theta(n^2)\).&lt;/p&gt;
&lt;h3 id=&#34;bonus-example-selection-sort&#34;&gt;Bonus Example: Selection Sort&lt;/h3&gt;
&lt;p&gt;Use a similar analysis to show that the worst-case for selection sort is \(\Theta(n^2)\). As a reminder, selection sort is defined as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;selection_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(A)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        min_j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(A)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; A[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; A[min_j]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                min_j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[i], A[min_j] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[min_j], A[i]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We have already observed that the outer loop iterates \(n-1\) times. Even in the best case, the inner loop runs proportional to \(n\) times. This is sufficient to conclude that the running time is \(O(n^2)\) for all cases.&lt;/p&gt;
&lt;p&gt;For showing that the worst case is \(\Omega(n^2)\), we could use the same argument as insertion sort. However, that isn&amp;rsquo;t necessary. In &lt;em&gt;any&lt;/em&gt; case, the inner loop will run proportional to \(n\) times. It is not dependent on any specific arrangement of the input as selection sort is. Therefore, we can conclude that the worst-case is \(\Omega(n^2)\), and so selection sort is \(\Theta(n^2)\).&lt;/p&gt;
&lt;h2 id=&#34;formal-definition-of-asymptotic-notation&#34;&gt;Formal Definition of Asymptotic Notation&lt;/h2&gt;
&lt;p&gt;Now that we have established some understanding of the notation, let&amp;rsquo;s define it formally. We typically use functions whose domains are over the set of natural or real numbers.&lt;/p&gt;
&lt;h3 id=&#34;o-notation&#34;&gt;$O$-notation&lt;/h3&gt;
&lt;p&gt;We previously established that $O$-notation described as &lt;strong&gt;asymptotic upper bound&lt;/strong&gt;. It was briefly mentioned that this bound holds within a constant factor, which we will now define more thoroughly. For a function \(g(n)\), \(O(g(n)) = \{f(n) : \exists c &amp;gt; 0, n_0 &amp;gt; 0 \text{ such that } 0 \leq f(n) \leq cg(n) \text{ for all } n \geq n_0\}\). It might make more sense to visualize this definition.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-09-26_17-43-51_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Visualization of $O$-notation (source: Cormen et al.)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Visualization of $O$-notation (source: Cormen et al.)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Notice that the function \(f(n)\) is bounded above by \(cg(n)\) for all \(n \geq n_0\) in the figure above.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s put this definition to the test with an example. Given a function \(f(n) = 3n^2 + 200n + 1000\), show that \(f(n) = O(n^2)\). The goal is to find positive constants \(c\) and \(n_0\) such that \(3n^2 + 200n + 1000 \leq cn^2\) for all \(n \geq n_0\). Dividing both sides by \(n^2\) yields&lt;/p&gt;
&lt;p&gt;\[
3 + \frac{200}{n} + \frac{1000}{n^2} \leq c.
\]&lt;/p&gt;
&lt;p&gt;This equation has many possible solutions. Let&amp;rsquo;s choose \(n_0 = 2\), then&lt;/p&gt;
&lt;p&gt;\[
3 + \frac{200}{2} + \frac{1000}{2^2} = 3 + 100 + 250 = 353 \leq c.
\]&lt;/p&gt;
&lt;p&gt;Therefore, we can conclude that \(f(n) = O(n^2)\).&lt;/p&gt;
&lt;h3 id=&#34;and-omega-notation&#34;&gt;$$-notation&lt;/h3&gt;
&lt;p&gt;The notation used to describe an &lt;strong&gt;asymptotic lower bound&lt;/strong&gt; is formally defined as \(\Omega(g(n)) = \{f(n) : \exists c &amp;gt; 0, n_0 &amp;gt; 0 \text{ such that } 0 \leq cg(n) \leq f(n) \text{ for all } n \geq n_0\}\). Again, it is helpful to visualize this.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-09-26_18-17-07_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Visualization of $&amp;amp;Omega;$-notation (source: Cormen et al.)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Visualization of $$-notation (source: Cormen et al.)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Notice that the function \(f(n)\) is bounded below by \(cg(n)\) for all \(n \geq n_0\) in the figure above.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s revisit our function from above and show that \(f(n) = \Omega(n^2)\). The goal is to find positive constants \(c\) and \(n_0\) such that \(3n^2 + 200n + 1000 \geq cn^2\) for all \(n \geq n_0\). Dividing both sides by \(n^2\) yields&lt;/p&gt;
&lt;p&gt;\[
3 + \frac{200}{n} + \frac{1000}{n^2} \geq c.
\]&lt;/p&gt;
&lt;p&gt;This holds when \(c = 3\) and \(n_0\) is any positive integer. To see this, think about what happens to this function as \(n\) approaches infinity. The first term will always be 3, and the second and third terms will approach 0. Therefore, we can conclude that \(f(n) = \Omega(n^2)\).&lt;/p&gt;
&lt;h3 id=&#34;and-theta-notation&#34;&gt;$$-notation&lt;/h3&gt;
&lt;p&gt;Lastly, the notation used for an &lt;strong&gt;asymptotically tight bound&lt;/strong&gt; is \(\Theta(g(n)) = \{f(n) : \exists c_1, c_2 &amp;gt; 0, n_0 &amp;gt; 0 \text{ such that } 0 \leq c_1g(n) \leq f(n) \leq c_2g(n) \text{ for all } n \geq n_0\}\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-09-26_18-23-25_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Visualization of $&amp;amp;Theta;$-notation (source: Cormen et al.)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Visualization of $$-notation (source: Cormen et al.)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;We had mentioned previously that if \(f(n) = \Omega(g(n))\) and \(f(n) = O(g(n))\), then \(f(n) = \Theta(g(n))\). This is formalized in the following theorem, as stated in Cormen et al.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For any two functions \(f(n)\) and \(g(n)\), we have \(f(n) = \Theta(g(n))\) if and only if \(f(n) = O(g(n))\) and \(f(n) = \Omega(g(n))\).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;function-properties&#34;&gt;Function Properties&lt;/h3&gt;
&lt;p&gt;The following properties are useful when analyzing the asymptotic behavior of functions.&lt;/p&gt;
&lt;h4 id=&#34;transitivity&#34;&gt;Transitivity&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;If \(f(n) = O(g(n))\) and \(g(n) = O(h(n))\), then \(f(n) = O(h(n))\).&lt;/li&gt;
&lt;li&gt;If \(f(n) = \Omega(g(n))\) and \(g(n) = \Omega(h(n))\), then \(f(n) = \Omega(h(n))\).&lt;/li&gt;
&lt;li&gt;If \(f(n) = \Theta(g(n))\) and \(g(n) = \Theta(h(n))\), then \(f(n) = \Theta(h(n))\).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reflexivity&#34;&gt;Reflexivity&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\(f(n) = O(f(n))\)&lt;/li&gt;
&lt;li&gt;\(f(n) = \Omega(f(n))\)&lt;/li&gt;
&lt;li&gt;\(f(n) = \Theta(f(n))\)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;symmetry&#34;&gt;Symmetry&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\(f(n) = \Theta(g(n))\) if and only if \(g(n) = \Theta(f(n))\).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;transpose-symmetry&#34;&gt;Transpose Symmetry&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\(f(n) = O(g(n))\) if and only if \(g(n) = \Omega(f(n))\).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;common-functions&#34;&gt;Common Functions&lt;/h2&gt;
&lt;p&gt;The functions used to describe both time and space complexity are visualized below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-09-26_19-11-32_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;Common functions used in complexity analysis (source: Wikipedia)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;Common functions used in complexity analysis (source: Wikipedia)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Introduction to Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_complexity_analysis/</link>
      <pubDate>Tue, 19 Sep 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/introduction_to_complexity_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction-to-algorithms&#34;&gt;Introduction to Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#insertion-sort&#34;&gt;Insertion Sort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-sorting-numbers&#34;&gt;Example: Sorting Numbers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#worst-case-analysis&#34;&gt;Worst-Case Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#best-case-analysis&#34;&gt;Best-Case Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rate-of-growth&#34;&gt;Rate of Growth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-analysis-of-selection-sort&#34;&gt;Example: Analysis of Selection Sort&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;introduction-to-algorithms&#34;&gt;Introduction to Algorithms&lt;/h2&gt;
&lt;p&gt;One of the major goals of computer science is to solve important problems. In order to do that, we must be able to express those solutions both mathematically and in a way that can be executed by a computer. Further, those solutions need to be aware of the resources that are available to them. It does us no good to come up with a solution that could never be run by current hardware or executed in a reasonable amount of time.&lt;/p&gt;
&lt;p&gt;There are of course other considerations besides runtime. How much memory does the solution require? Does it require a lot of data to be stored on disk? What about distributed solutions that can be run on multiple machines? Some solutions can be so complex, that we must also consider their environmental impact. For example, Meta&amp;rsquo;s Llama 2 large language models required 3,311,616 combined GPU hours to train. They report that their total carbon emissions from training were 539 tons of CO2 equivalent (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Touvron et al. 2023&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;We begin our algorithmic journey by studying a simple sorting algorithm, insertion sort. First, we need to formally define the problem of sorting. Given a sequence of \(n\) objects \(A = \langle a_1, a_2, \ldots, a_n \rangle\), we want to rearrange the elements such that \(a_1&amp;rsquo; \leq a_2&amp;rsquo; \leq \ldots \leq a_n&amp;rsquo;\). We will assume that the elements are comparable, meaning that we can use the operators \(&amp;lt;\) and \(&amp;gt;\) to compare them. Some sets, such as the set of all real numbers, have a natural ordering. A useful programming language would provide the required comparison operators. For other types of elements, such as strings, this may not be the case. For example, how would you compare the strings &amp;ldquo;apple&amp;rdquo; and &amp;ldquo;banana&amp;rdquo;? In these cases, we will need to define our own comparison operators. Either way, we will assume that the comparison operators are available to us.&lt;/p&gt;
&lt;p&gt;This example follows the one given in Chapter 2 of Cormen et al. (2009).&lt;/p&gt;
&lt;h2 id=&#34;insertion-sort&#34;&gt;Insertion Sort&lt;/h2&gt;
&lt;p&gt;Insertion sort is defined as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insertion_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(A)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; A[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[j]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;example-sorting-numbers&#34;&gt;Example: Sorting Numbers&lt;/h2&gt;
&lt;p&gt;TODO: Add a step-by-step example of sorting a list of numbers.&lt;/p&gt;
&lt;h2 id=&#34;worst-case-analysis&#34;&gt;Worst-Case Analysis&lt;/h2&gt;
&lt;p&gt;Given the definition from above, we can compute \(T(n)\), the running time of the algorithm on an input of size \(n\). To do this, we need to sum the products of the cost of each statement and the number of times each statement is executed.&lt;/p&gt;
&lt;p&gt;At first glance, the first statement &lt;code&gt;for i in range(1, len(A))&lt;/code&gt; appears to execute \(n-1\) times since it starts at 1 and only goes up to, but not including, \(n\). Remember that the &lt;code&gt;for&lt;/code&gt; statement must be checked to see if it should exit, so the test is executed one more time than the number of iterations. Therefore, the first statement is executed \(n\) times. If we say that the cost to execute each check is \(c_1\), then the total cost of the first statement is \(c_1 n\).&lt;/p&gt;
&lt;p&gt;With the exception of the &lt;code&gt;while&lt;/code&gt; loop, the statement inside the &lt;code&gt;for&lt;/code&gt; loop is executed once per iteration. The cost of executing statement \(i\) is \(c_i\). Therefore, the total cost of the second statement is \(c_2 n\). The costs are updated in the code below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insertion_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(A)): &lt;span style=&#34;color:#75715e&#34;&gt;# c_1 n&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[i] &lt;span style=&#34;color:#75715e&#34;&gt;# c_2 n&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# c_3 n&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; A[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[j]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key &lt;span style=&#34;color:#75715e&#34;&gt;# c_7 n&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For the &lt;code&gt;while&lt;/code&gt; loop, we can denote the number of times it runs by \(t_i\), where \(i\) is the iteration of the &lt;code&gt;for&lt;/code&gt; loop. If the &lt;code&gt;while&lt;/code&gt; condition check costs \(c_4\) and is executed \(t_i\) times for each &lt;code&gt;for&lt;/code&gt; loop iteration, the total cost is given as \(c_4 \sum_{i=1}^{n-1} t_i\).&lt;/p&gt;
&lt;p&gt;The statement inside the &lt;code&gt;while&lt;/code&gt; loop are executed 1 fewer times than the number of times the condition check is executed. Therefore, the total cost of the statements inside the &lt;code&gt;while&lt;/code&gt; loop is \(c_5 \sum_{i=1}^{n-1} (t_i - 1) + c_5 \sum_{i=1}^{n-1} (t_i - 1)\). The cost of the &lt;code&gt;while&lt;/code&gt; loop is updated in the code below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insertion_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(A)): &lt;span style=&#34;color:#75715e&#34;&gt;# c_1 * n&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[i] &lt;span style=&#34;color:#75715e&#34;&gt;# c_2 * (n-1)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# c_3 * (n-1)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; A[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; key: &lt;span style=&#34;color:#75715e&#34;&gt;# c_4 * [t_i for i in range(1, len(A))]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[j] &lt;span style=&#34;color:#75715e&#34;&gt;# c_5 * [t_i - 1 for i in range(1, len(A))]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# c_6 * [t_i - 1 for i in range(1, len(A))]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key &lt;span style=&#34;color:#75715e&#34;&gt;# c_7 * (n-1)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To get the total running time \(T(n)\), we sum up all of the costs.&lt;/p&gt;
&lt;p&gt;\begin{align}
T(n) &amp;amp;= c_1 n + c_2 (n-1) + c_3 (n-1) + c_4 \sum_{i=1}^{n-1} t_i + c_5 \sum_{i=1}^{n-1} (t_i - 1) + c_6 \sum_{i=1}^{n-1} (t_i - 1) + c_7 (n-1) \\
\end{align}&lt;/p&gt;
&lt;p&gt;This analysis is a good start, but it doesn&amp;rsquo;t paint the whole picture. The number of actual executions will depend on the input that is given. For example, what if the input is already sorted, or given in reverse order? It is common to express the worst-case runtime for a particular algorithm. For insertion sort, that is when the input is in reverse order. In this case, each element \(A[i]\) is compared to every other element in the sorted subarray. This means that \(t_i = i\) for every iteration of the &lt;code&gt;for&lt;/code&gt; loop. Therefore, the worst-case runtime is given as&lt;/p&gt;
&lt;p&gt;\begin{align}
T(n) &amp;amp;= c_1 n + c_2 (n-1) + c_3 (n-1) + c_4 \sum_{i=1}^{n-1} i + c_5 \sum_{i=1}^{n-1} (i - 1) + c_6 \sum_{i=1}^{n-1} (i - 1) + c_7 (n-1) \\
\end{align}&lt;/p&gt;
&lt;p&gt;To express this runtime solely in terms of \(n\), we can use the fact that \(\sum_{i=1}^{n-1} i = (\sum_{i=0}^{n-1} i) - 1 =  \frac{n(n-1)}{2} - 1\) and \(\sum_{i=1}^{n-1} (i - 1) = \sum_{i=0}^{n-2} i = \frac{n(n-1)}{2}\). This gives us&lt;/p&gt;
&lt;p&gt;\begin{align}
T(n) &amp;amp;= c_1 n + c_2 (n-1) + c_3 (n-1) + c_4 \left(\frac{n(n-1)}{2} - 1\right)\\
&amp;amp;+ c_5 \left(\frac{n(n-1)}{2}\right) + c_6 \left(\frac{n(n-1)}{2}\right) + c_7 (n-1) \\
&amp;amp;= \left(\frac{c_4}{2} + \frac{c_5}{2} + \frac{c_6}{2}\right)n^2 + \left(c_1 + c_2 + c_3 + \frac{c_4}{2} - \frac{c_5}{2} - \frac{c_6}{2} + c_7\right)n - (c_2 + c_3 + c_4 + c_7) \\
\end{align}&lt;/p&gt;
&lt;p&gt;With the appropriate choice of constants, we can express this as a quadratic function \(an^2 + bn + c\).&lt;/p&gt;
&lt;h2 id=&#34;best-case-analysis&#34;&gt;Best-Case Analysis&lt;/h2&gt;
&lt;p&gt;The best-case runtime for insertion sort is when the input is already sorted. In this case, the &lt;code&gt;while&lt;/code&gt; check is executed only once per iteration of the &lt;code&gt;for&lt;/code&gt; loop. That is, \(t_i = 1\) for every iteration of the &lt;code&gt;for&lt;/code&gt; loop. Therefore, the best-case runtime is given as&lt;/p&gt;
&lt;p&gt;\begin{align}
T(n) &amp;amp;= c_1 n + c_2 (n-1) + c_3 (n-1) + c_4 (n-1) + c_7 (n-1) \\
&amp;amp;= (c_1 + c_2 + c_3 + c_4 + c_7)n - (c_2 + c_3 + c_4 + c_7) \\
\end{align}&lt;/p&gt;
&lt;p&gt;Let \(a = c_1 + c_2 + c_3 + c_4 + c_7\) and $b = -(c_2 + c_3 + c_4 + c_7)$Then the best-case runtime is given as \(an + b\), a linear function of \(n\).&lt;/p&gt;
&lt;h2 id=&#34;rate-of-growth&#34;&gt;Rate of Growth&lt;/h2&gt;
&lt;p&gt;We can simplify how we express the runtime of both these cases by considering only the highest-order term. Consider the worst-case, \(T(n) = an^2 + bn + c\). As \(n\) grows, the term \(an^2\) will dominate the runtime, rendering the others insignificant by comparison. This simplification is typically expressed using \(\Theta\) notation. For the worst-case, we say that \(T(n) = \Theta(n^2)\). It is a compact way of stating that the runtime is proportional to \(n^2\) for large values of \(n\).&lt;/p&gt;
&lt;h2 id=&#34;example-analysis-of-selection-sort&#34;&gt;Example: Analysis of Selection Sort&lt;/h2&gt;
&lt;p&gt;Based on the analysis above, let&amp;rsquo;s check our understanding and see if we can characterize the runtime of another sorting algorithm, selection sort. Selection sort is defined as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;selection_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(A) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        min_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(A)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; A[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; A[min_index]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                min_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[i], A[min_index] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[min_index], A[i]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The first statement &lt;code&gt;for i in range(0, len(A) - 1)&lt;/code&gt; will be evaluated \(n\) times. With the exception of the inner &lt;code&gt;for&lt;/code&gt; loop, the rest of the statements in the scope of the first &lt;code&gt;for&lt;/code&gt; loop are executed once per iteration. Their costs are \(c_2\) and \(c_6\), respectively.&lt;/p&gt;
&lt;p&gt;The inner &lt;code&gt;for&lt;/code&gt; loop will be checked \(n-i\) times for each iteration of the outer &lt;code&gt;for&lt;/code&gt; loop. The cost of the condition check is \(c_3\). The cost of the statements inside the &lt;code&gt;for&lt;/code&gt; loop are \(c_4\) and \(c_5\). The &lt;code&gt;if&lt;/code&gt; check is evaluated for every iteration of the inner loop, but the statements inside the &lt;code&gt;if&lt;/code&gt; are only executed when the condition is true. We can denote this as \(t_i\), the number of times the &lt;code&gt;if&lt;/code&gt; condition is true for each iteration of the inner &lt;code&gt;for&lt;/code&gt; loop. The cost of the inner loop is given as&lt;/p&gt;
&lt;p&gt;\begin{align}
c_3 \sum_{i=1}^{n-1} (n-i) + c_4 \sum_{i=0}^{n-1} (n-i-1) + c_5 \sum_{i=0}^{n-1} t_i\\
\end{align}&lt;/p&gt;
&lt;p&gt;Combining this with the cost of the outer &lt;code&gt;for&lt;/code&gt; loop, we get&lt;/p&gt;
&lt;p&gt;\begin{align}
T(n) &amp;amp;= c_1 n + c_2 (n-1) + c_6 (n-1) + c_3 \sum_{i=0}^{n-1} (n-i) + c_4 \sum_{i=0}^{n-1} (n-i-1) + c_5 \sum_{i=0}^{n-1} t_i\\
\end{align}&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;style&gt;.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}&lt;/style&gt;&lt;div class=&#34;csl-bib-body&#34;&gt;
  &lt;div class=&#34;csl-entry&#34;&gt;&lt;a id=&#34;citeproc_bib_item_1&#34;&gt;&lt;/a&gt;Touvron, Hugo, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv. &lt;a href=&#34;https://doi.org/10.48550/arXiv.2307.09288&#34;&gt;https://doi.org/10.48550/arXiv.2307.09288&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
