<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Science on Alex Dillhoff</title>
    <link>https://ajdillhoff.github.io/tags/computer-science/</link>
    <description>Recent content in Computer Science on Alex Dillhoff</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 02 Feb 2025 00:00:00 -0500</lastBuildDate>
    <atom:link href="https://ajdillhoff.github.io/tags/computer-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AVL Trees</title>
      <link>https://ajdillhoff.github.io/notes/avl_trees/</link>
      <pubDate>Thu, 31 Oct 2024 13:30:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/avl_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rebalancing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rebalancing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;&#xA;&lt;p&gt;An AVL tree is a binary search tree that is self-balancing based on the height of the tree. It manages this by adding a balance factor property to each node. Given a node \(X\), the balance factor is defined as:&lt;/p&gt;</description>
    </item>
    <item>
      <title>NP-Completeness</title>
      <link>https://ajdillhoff.github.io/notes/np_completeness/</link>
      <pubDate>Thu, 25 Apr 2024 11:03:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/np_completeness/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#reductions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Reductions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#clique-problem&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Clique Problem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#vertex-cover-problem&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Vertex Cover Problem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Most of the algorithms discussed in a typical algorithms course run in polynomial time. This focus is reasonable since algorithms that run worse than polynomial time have little practical use. To simplify this notion: a problem for which a polynomial-time algorithm exists is &amp;ldquo;easy&amp;rdquo; and a problem for which no polynomial-time algorithm exists is &amp;ldquo;hard&amp;rdquo;. Knowing how to determine whether a problem is easy or hard is extremely useful. If one can identify a hard problem, then an approximate solution may be the best that can be achieved.&lt;/p&gt;</description>
    </item>
    <item>
      <title>All-Pairs Shortest Paths</title>
      <link>https://ajdillhoff.github.io/notes/all_pairs_shortest_paths/</link>
      <pubDate>Sat, 20 Apr 2024 11:32:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/all_pairs_shortest_paths/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#problem-representation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Problem Representation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#a-naive-solution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;A Naive Solution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-floyd-warshall-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Floyd-Warshall Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;TychoLink is a telecommunications company looking to optimize its network for the fastest and most efficient data transfer possible. The network consists of multiple routers, each connected by various types of links that differ in latency and bandwidth. The company wants to ensure that data packets can travel from any router to any other router in the network using the path that offers the best balance between low latency and high bandwidth. There are three objectives in total:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Maximum Flow</title>
      <link>https://ajdillhoff.github.io/notes/maximum_flow/</link>
      <pubDate>Fri, 12 Apr 2024 18:51:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/maximum_flow/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#objective-questions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Objective Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#maximum-flow&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Maximum Flow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#a-polynomial-time-solution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;A polynomial time solution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;A flow network is a directed graph in which the edges begin at a node that produces the flow and the adjacent nodes are the ones that receive it. &lt;em&gt;Flow&lt;/em&gt; in this context could take on many meanings, such as the amount of water that can flow through a pipe, the amount of data that can be sent through a network, or the amount of traffic that can be sent through a road network. The goal of a flow network is to maximize the flow from the source to the sink.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Topological Sort</title>
      <link>https://ajdillhoff.github.io/notes/topological_sort/</link>
      <pubDate>Thu, 04 Apr 2024 10:21:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/topological_sort/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#topological-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Topological Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#strongly-connected-components&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Strongly Connected Components&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#application-recommender-graphs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Application: Recommender Graphs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;topological-sort&#34;&gt;Topological Sort&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;topological sort&lt;/strong&gt; of a directed acyclic graph \(G = (V, E)\) is a linear ordering of all its vertices such that for every directed edge \((u, v) \in E\), vertex \(u\) comes before vertex \(v\) in the ordering.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Recursion Tree Method</title>
      <link>https://ajdillhoff.github.io/notes/recursion_tree_method/</link>
      <pubDate>Mon, 18 Mar 2024 22:10:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/recursion_tree_method/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-4-dot-13-from-clrs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example 4.13 from CLRS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Visualizing the characteristics of an algorithm is a great way to build intuition about its runtime. Although it can be used to prove a recurrence, it is often a good jumping off point for the &lt;a href=&#34;https://ajdillhoff.github.io/notes/substitution_method/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Substitution Method&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Greedy Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/greedy_algorithms/</link>
      <pubDate>Mon, 18 Mar 2024 14:45:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/greedy_algorithms/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#activity-selection&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Activity Selection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#properties-of-greedy-solutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Properties of Greedy Solutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#huffman-codes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Huffman Codes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Greedy algorithms are a class of algorithms that yield &lt;em&gt;locally&lt;/em&gt; optimal solutions. In cases where the local optimum is also the global optimum, greedy algorithms are ideal. Even in cases where the global solution is more elusive, a local solution may be sufficient.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hash Tables</title>
      <link>https://ajdillhoff.github.io/notes/hash_tables/</link>
      <pubDate>Thu, 14 Mar 2024 15:16:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/hash_tables/</guid>
      <description>&lt;p&gt;See &lt;a href=&#34;https://ajdillhoff.github.io/teaching/dasc5300/lectures/hash_maps.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;these slides&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dynamic Programming</title>
      <link>https://ajdillhoff.github.io/notes/dynamic_programming/</link>
      <pubDate>Thu, 14 Mar 2024 10:40:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/dynamic_programming/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rod-cutting&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rod Cutting&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#matrix-chain-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Matrix-chain Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#applying-dynamic-programming&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Applying Dynamic Programming&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#longest-common-subsequence&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Longest Common Subsequence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Dynamic programming is a technique for solving problems by breaking them down into simpler subproblems, very much like divide and conquer algorithms. One primary difference is that the subproblems are designed in such a way that they do not need to be recomputed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Medians and Order Statistics</title>
      <link>https://ajdillhoff.github.io/notes/medians_and_order_statistics/</link>
      <pubDate>Tue, 12 Mar 2024 13:17:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/medians_and_order_statistics/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#order-statistics&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Order Statistics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#minimum-and-maximum&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Minimum and Maximum&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#selection-in-expected-linear-time&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Selection in expected linear time&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#problems-and-exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Problems and Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;We briefly touched on a median finding algorithm when discussing &lt;a href=&#34;https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Divide and Conquer Algorithms&lt;/a&gt;. This section will be a bit of a review, but the point is to touch on the topic of order statistics more generally.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sorting in Linear Time</title>
      <link>https://ajdillhoff.github.io/notes/sorting_in_linear_time/</link>
      <pubDate>Mon, 11 Mar 2024 17:10:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/sorting_in_linear_time/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#establishing-a-lower-bound-on-comparison-sorts&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Establishing a Lower Bound on Comparison Sorts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#counting-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Counting Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#radix-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Radix Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bucket-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bucket Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#questions-and-exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Questions and Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These are my personal notes for Chapter 8 of &lt;em&gt;Introduction to Algorithms&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;). Readers should reference the book for more details when necessary.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Substitution Method</title>
      <link>https://ajdillhoff.github.io/notes/substitution_method/</link>
      <pubDate>Tue, 27 Feb 2024 19:12:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/substitution_method/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-from-clrs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example from CLRS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#making-the-wrong-guess&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Making the Wrong Guess&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;The &lt;strong&gt;substitution method&lt;/strong&gt; is a technique for solving recurrences. It works in two steps:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Quicksort</title>
      <link>https://ajdillhoff.github.io/notes/quicksort/</link>
      <pubDate>Sun, 25 Feb 2024 17:24:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/quicksort/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#basic-quicksort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Basic Quicksort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#performance&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Performance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#randomized-quicksort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Randomized Quicksort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#paranoid-quicksort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Paranoid Quicksort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Quicksort is a popular sorting algorithm implemented in many language libraries that has a worst-case running time of \(\Theta(n^2)\). &lt;strong&gt;Why would anyone choose this as the default sorting algorithm if one like mergesort has better worst-case performance?&lt;/strong&gt; As you will see, the devil is in the details. Quicksort is often faster in practice. It also has a small memory footprint and is easy to implement.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Priority Queues</title>
      <link>https://ajdillhoff.github.io/notes/priority_queues/</link>
      <pubDate>Sat, 24 Feb 2024 14:10:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/priority_queues/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#quick-facts&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Quick Facts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#implementation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Implementation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;quick-facts&#34;&gt;Quick Facts&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Time Complexity&lt;/strong&gt;&lt;/strong&gt;: \(O(\lg n)\)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Space Complexity&lt;/strong&gt;&lt;/strong&gt;: \(O(n)\)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Besides being the primary data structure for &lt;a href=&#34;https://ajdillhoff.github.io/notes/heapsort/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Heapsort&lt;/a&gt;, a heap is also used to implement a priority queue. A priority queue is a key-value data structure in which the keys are used to determine the priority of each element in the queue. There are two variants, maximum and minimum, and they support the following operations:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Master Theorem</title>
      <link>https://ajdillhoff.github.io/notes/master_theorem/</link>
      <pubDate>Sun, 04 Feb 2024 17:49:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/master_theorem/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-merge-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Merge Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-matrix-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-median-finding&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Median Finding&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-cormen-et-al-dot-exercise-4-dot-5-2&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Cormen et al. Exercise 4.5-2&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;In the study of &lt;a href=&#34;https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Divide and Conquer Algorithms&lt;/a&gt;, a recurrence tree can be used to determine the runtime complexity. These notes focus on the &lt;strong&gt;master theorem&lt;/strong&gt;, a blueprint for solving any recurrence of the form&lt;/p&gt;</description>
    </item>
    <item>
      <title>Divide and Conquer Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/</link>
      <pubDate>Tue, 23 Jan 2024 08:38:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#solving-recurrences&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Solving Recurrences&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-merge-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Merge Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-multiplying-square-matrices&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Multiplying Square Matrices&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-convex-hull&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Convex Hull&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-median-search&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Median Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;&#xA;&lt;p&gt;Divide and conquer algorithms are a class of algorithms that solve a problem by breaking it into smaller subproblems, solving the subproblems recursively, and then combining the solutions to the subproblems to form a solution to the original problem. Problems that can be solved in this manner are typically highly parallelizable. These notes investigate a few examples of classic divide and conquer algorithms and their analysis.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Pattern: Stencils</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_stencils/</link>
      <pubDate>Mon, 22 Jan 2024 19:39:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_stencils/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#differential-equations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Differential Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#stencils&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Stencils&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-basic-stencil&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Basic Stencil&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tiled-stencil&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tiled Stencil&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#thread-coarsening&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Thread Coarsening&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#register-tiling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Register Tiling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#questions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Used in differential equations&lt;/li&gt;&#xA;&lt;li&gt;Frequently use higher precision&lt;/li&gt;&#xA;&lt;li&gt;Some similarity to convolutions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;differential-equations&#34;&gt;Differential Equations&lt;/h2&gt;&#xA;&lt;p&gt;Any computational problem requires discretization of data or equations so that they can be solved numerically. This is fundamental in numerical analysis, where differential equations need to be approximated.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Pattern: Convolution</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_convolution/</link>
      <pubDate>Mon, 15 Jan 2024 21:35:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_convolution/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#convolution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Convolution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#properties-of-convolutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Properties of Convolutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#implementing-a-convolution-kernel&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Implementing a Convolution Kernel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#constant-memory-and-caching&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Constant Memory and Caching&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tiled-convolutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tiled Convolutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#caching-the-halo-cells&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Caching the Halo Cells&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;This pattern involves tiling and input data staging.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Performance Basics</title>
      <link>https://ajdillhoff.github.io/notes/gpu_performance_basics/</link>
      <pubDate>Sun, 14 Jan 2024 13:31:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_performance_basics/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-coalescing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Coalescing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#hiding-memory-latency&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Hiding Memory Latency&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#thread-coarsening&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Thread Coarsening&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#optimization-checklist&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Optimization Checklist&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#identifying-bottlenecks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Identifying Bottlenecks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These notes are on &amp;ldquo;Chapter 6: Performance Considerations&amp;rdquo; from the book &lt;em&gt;Programming Massively Parallel Processors&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>CUDA Memory Architecture</title>
      <link>https://ajdillhoff.github.io/notes/cuda_memory_architecture/</link>
      <pubDate>Thu, 11 Jan 2024 15:07:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/cuda_memory_architecture/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-access&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Access&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-types&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Types&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tiling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tiling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-tiled-matrix-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Tiled Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#boundary-checking&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Boundary Checking&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-use-and-occupancy&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Use and Occupancy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dynamically-changing-the-block-size&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dynamically Changing the Block Size&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;So far, the kernels we have used assume everything is on global memory. Even though there are thousands of cores that can effectively hide the latency of transferring data to and from global memory, we will see this delay will become a bottleneck in many applications. These notes explore the different types of memory available on the GPU and how to use them effectively.&lt;/p&gt;</description>
    </item>
    <item>
      <title>CUDA Architecture</title>
      <link>https://ajdillhoff.github.io/notes/cuda_architecture/</link>
      <pubDate>Mon, 08 Jan 2024 20:49:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/cuda_architecture/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#architecture&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#block-scheduling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Block Scheduling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#synchronization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Synchronization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#warps&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Warps&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#control-divergence&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Control Divergence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#warp-scheduling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Warp Scheduling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resource-partitioning&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resource Partitioning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dynamic-launch-configurations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dynamic Launch Configurations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;&#xA;&lt;p&gt;A GPU consists of chip that is composed of several &lt;strong&gt;streaming multiprocessors&lt;/strong&gt; (SMs). Each SM has a number of cores that execute instructions in parallel. The H100, seen below, has 144 SMs (you can actually count them by eye). Each SM has 128 FP32 cores for a total of 18,432 cores. Historically, CUDA has used DDR memory, but newer architectures use high-bandwidth memory (HBM). This is closely integrated with the GPU for faster data transfer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multidimensional Grids and Data</title>
      <link>https://ajdillhoff.github.io/notes/multidimensional_grids_and_data/</link>
      <pubDate>Fri, 05 Jan 2024 11:56:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/multidimensional_grids_and_data/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multidimensional-grid-organization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multidimensional Grid Organization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-color-to-grayscale&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Color to Grayscale&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#no-longer-embarrassing-overlapping-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;No longer embarrassing: overlapping data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#matrix-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-s-next&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What&amp;rsquo;s Next?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;The CUDA Programming model allows us to organize our data in a multidimensional grid. The purpose of this is primarily for our own convenience, but it also allows us to take advantage of the GPU&amp;rsquo;s memory hierarchy. In Lab 0, we only required a single dimension for our grid as well as each block since the input was a vector. When performing computations on multidimensional data like matrices, we can match the dimensions of our launch configuration to the dimensions of our data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Heterogeneous Data Parallel Computing</title>
      <link>https://ajdillhoff.github.io/notes/heterogeneous_data_parallel_computing/</link>
      <pubDate>Sat, 30 Dec 2023 14:41:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/heterogeneous_data_parallel_computing/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cuda-c-programs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;CUDA C Programs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-vector-addition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Vector Addition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#error-checking&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Error Checking&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;  &#xA;&#xA;  &#xA;  &#xA;&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;&#xA;&#xA;&lt;div class=&#34;notice info&#34;&gt;&#xA;  &lt;div class=&#34;notice-head&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; fill=&#34;none&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;1.5&#34; stroke=&#34;currentColor&#34; width=&#34;22&#34; height=&#34;22&#34;&gt;&#xA;        &lt;path stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; d=&#34;m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z&#34; /&gt;&#xA;      &lt;/svg&gt;&lt;p&gt;Terms &amp;amp; Concepts&lt;/p&gt;</description>
    </item>
    <item>
      <title>MapReduce</title>
      <link>https://ajdillhoff.github.io/notes/mapreduce/</link>
      <pubDate>Fri, 24 Nov 2023 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/mapreduce/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-is-mapreduce&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What is MapReduce?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#hadoop-distributed-file-system--hdfs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Hadoop Distributed File System (HDFS)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mapreduce-overview&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;MapReduce Overview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#hadoop-v2-aka-yarn&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Hadoop v2 AKA YARN&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These are my personal notes from the book &lt;em&gt;Fundamentals of Database Systems&lt;/em&gt; by (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;). I highly recommend reading the original source material. The contents of the article should only serve as a brief overview of the topic.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Distributed Databases</title>
      <link>https://ajdillhoff.github.io/notes/distributed_databases/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/distributed_databases/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#overview&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Overview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#data-fragmentation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Data Fragmentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#data-replication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Data Replication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#data-concurrency&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Data Concurrency&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Distributed systems excel at partitioning large problems into smaller chunks that can be processed in parallel. This requires parallel thinking instead of serial thinking. Many algorithms and solutions that run serially may be easier to adapt to parallel applications than others.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NOSQL</title>
      <link>https://ajdillhoff.github.io/notes/nosql/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/nosql/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#nosql-characteristics-for-distributed-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;NOSQL Characteristics for Distributed Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#nosql-data-models&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;NOSQL Data Models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cap-theorem&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;CAP Theorem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#document-based-nosql-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Document-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#key-value-nosql-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Key-Value NOSQL Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#column-based-nosql-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Column-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#graph-based-nosql-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Graph-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;&lt;strong&gt;NOSQL&lt;/strong&gt; refers to Not Only SQL. A NOSQL system is commonly a distributed one that focuses on semi-structured data storage, high performance, availability, replication and scalability. These type of systems developed to meet the needs of large-scale internet applications where a traditional SQL database could not.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Structured Query Language</title>
      <link>https://ajdillhoff.github.io/notes/structured_query_language/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/structured_query_language/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#history-and-development&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;History and Development&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#schemas&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Schemas&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#data-types&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Data Types&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#creation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Creation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#constraints&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#retrieving-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Retrieving Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#modifying-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Modifying Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#nested-queries&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Nested Queries&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#joined-tables&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Joined Tables&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#aggregate-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Aggregate Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#grouping&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Grouping&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#with-clause&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;&lt;code&gt;WITH&lt;/code&gt; Clause&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#modifying-tables&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Modifying Tables&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;history-and-development&#34;&gt;History and Development&lt;/h2&gt;&#xA;&lt;p&gt;Structured Query Language (SQL) is a database language for managing data in a relation DBMS. Its original inception was based on a paper by Edgar F. Codd in 1970 titled &lt;em&gt;A Relational Model of Data for Large Shared Data Banks&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Codd 1970&lt;/a&gt;). Two employees working at IBM in the 1970s, Donald D. Chamberlin and Raymond F. Boyce, developed the first version of SQL in 1974 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Chamberlin and Boyce 1974&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Databases</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_databases/</link>
      <pubDate>Sat, 28 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_databases/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#an-online-rpg-database&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;An Online RPG Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#from-schema-to-database&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;From Schema to Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#database-management-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Database Management Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#creating-our-rpg-database&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Creating our RPG Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;&lt;strong&gt;Recommended Reading: Chapters 1 and 2 from (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;)&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Minimum Spanning Trees</title>
      <link>https://ajdillhoff.github.io/notes/minimum_spanning_trees/</link>
      <pubDate>Sat, 21 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/minimum_spanning_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#finding-the-minimum-spanning-tree&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Finding the Minimum Spanning Tree&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#kruskal-s-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Kruskal&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#prim-s-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Prim&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Minimum spanning trees are undirected graphs that connect all of the vertices such that there are no redundant edges and the total weight is minimized. They are useful for finding the shortest path between two points in a graph. Useful application of MSTs include&lt;/p&gt;</description>
    </item>
    <item>
      <title>Single-Source Shortest Paths</title>
      <link>https://ajdillhoff.github.io/notes/single_source_shortest_paths/</link>
      <pubDate>Sat, 21 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/single_source_shortest_paths/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bellman-ford&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bellman-Ford&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#shortest-paths-on-a-dag&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Shortest Paths on a DAG&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dijkstra-s-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dijkstra&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;When you hear the term &lt;em&gt;shortest path&lt;/em&gt;, you may think of the shortest physical distance between your current location and wherever it is you&amp;rsquo;re going. Finding the most optimal route via GPS is one of the most widely used mobile applications. Physical paths are not the only types we may wish to find a shortest path for. Other examples include:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Graph Theory</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_graph_theory/</link>
      <pubDate>Tue, 17 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_graph_theory/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-are-graphs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What are Graphs?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#graph-traversal-algorithms&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Graph Traversal Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#breadth-first-search&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Breadth First Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#depth-first-search&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Depth First Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;what-are-graphs&#34;&gt;What are Graphs?&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;graph&lt;/strong&gt; is a data structure that is used to represent pairwise relationships between objects. Graphs are used in many applications, such as social networks, maps, and routing algorithms. These notes accompany the series of lectures on graphs for my &lt;em&gt;Foundations of Computing&lt;/em&gt; course at the University of Texas - Arlington.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Red-Black Trees</title>
      <link>https://ajdillhoff.github.io/notes/red_black_trees/</link>
      <pubDate>Sun, 15 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/red_black_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Red-Black Trees are modified &lt;a href=&#34;https://ajdillhoff.github.io/notes/binary_search_trees/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Binary Search Trees&lt;/a&gt; that maintain a balanced structure in order to guarantee that operations like search, insert, and delete run in \(O(\log n)\) time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Binary Search Trees</title>
      <link>https://ajdillhoff.github.io/notes/binary_search_trees/</link>
      <pubDate>Tue, 10 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/binary_search_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#binary-search-trees&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Binary Search Trees&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;A $n$-ary tree is a graph-based data structure in which each node has up to \(n\) subnodes. It is supported by the following operations (not exclusive):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Data Structures</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_data_structures/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_data_structures/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction-to-data-structures&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction to Data Structures&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#review-pointers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Review: Pointers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#arrays&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Arrays&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#matrices&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Matrices&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multi-dimensional-arrays&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multi-Dimensional Arrays&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#stacks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Stacks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#queues&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Queues&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction-to-data-structures&#34;&gt;Introduction to Data Structures&lt;/h2&gt;&#xA;&lt;p&gt;Data structures are fundamental concepts in computer science that allow us to organize and store data in a way that enables efficient access and modification. They are essential building blocks for creating efficient and sophisticated computer programs and databases. Different types of data structures include arrays, linked lists, stacks, queues, trees, graphs, and many more, each serving a specific purpose and suited to specific applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linked Lists</title>
      <link>https://ajdillhoff.github.io/notes/linked_lists/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/linked_lists/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#singly-linked-lists&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Singly-Linked Lists&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#doubly-linked-lists&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Doubly-Linked Lists&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;A linked list is a &lt;strong&gt;dynamic&lt;/strong&gt; and &lt;strong&gt;aggregate&lt;/strong&gt; data structure made up of a collection of nodes. The nodes of a linked list can store any data type and are not enforced to contain the same data type. A basic &lt;code&gt;node&lt;/code&gt; structure may be defined as&lt;/p&gt;</description>
    </item>
    <item>
      <title>Complexity Analysis</title>
      <link>https://ajdillhoff.github.io/notes/complexity_analysis/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/complexity_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-notation-of-complexity-analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The notation of complexity analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#formal-definition-of-asymptotic-notation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Formal Definition of Asymptotic Notation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#common-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Common Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;the-notation-of-complexity-analysis&#34;&gt;The notation of complexity analysis&lt;/h2&gt;&#xA;&lt;h3 id=&#34;o-notation&#34;&gt;$O$-notation&lt;/h3&gt;&#xA;&lt;p&gt;$O$-notation, often referred to as &amp;ldquo;Big Oh&amp;rdquo; notation, describes an upper bound on the behavior of a function. It really means that the function &lt;em&gt;will not grow faster&lt;/em&gt; than the a given rate. This rate is typically the highest-order term in the function, and is often referred to as the &amp;ldquo;dominant term&amp;rdquo; or &amp;ldquo;dominant function&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_complexity_analysis/</link>
      <pubDate>Tue, 19 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_complexity_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction-to-algorithms&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction to Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#insertion-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Insertion Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-sorting-numbers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Sorting Numbers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#correctness&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Correctness&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#worst-case-analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Worst-Case Analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#best-case-analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Best-Case Analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rate-of-growth&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rate of Growth&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-analysis-of-selection-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Analysis of Selection Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction-to-algorithms&#34;&gt;Introduction to Algorithms&lt;/h2&gt;&#xA;&lt;p&gt;One of the major goals of computer science is to solve important problems. In order to do that, we must be able to express those solutions both mathematically and in a way that can be executed by a computer. Further, those solutions need to be aware of the resources that are available to them. It does us no good to come up with a solution that could never be run by current hardware or executed in a reasonable amount of time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stereo Vision</title>
      <link>https://ajdillhoff.github.io/notes/stereo_vision/</link>
      <pubDate>Wed, 23 Mar 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/stereo_vision/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#epipolar-geometry&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Epipolar Geometry&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#calibration-with-known-intrinsic-parameters-and-world-points&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Calibration with Known Intrinsic Parameters and World Points&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#estimating-depth&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Estimating Depth&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Binocular vision permits depth perception.&#xA;It is an important part of many tasks such as robotic vision, pose estimation, and scene understanding.&#xA;The goal of steropsis is to reconstruct a 3D representation of the world given correspondences between two or more cameras.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
