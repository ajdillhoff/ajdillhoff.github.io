<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CUDA on Alex Dillhoff</title>
    <link>http://localhost:1313/tags/cuda/</link>
    <description>Recent content in CUDA on Alex Dillhoff</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Tue, 21 Jan 2025 00:00:00 -0500</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/cuda/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Dynamic Parallelism</title>
      <link>http://localhost:1313/notes/dynamic_parallelism/</link>
      <pubDate>Fri, 19 Apr 2024 16:52:00 -0500</pubDate>
      <guid>http://localhost:1313/notes/dynamic_parallelism/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Dynamic Parallelism&lt;/strong&gt; is an extension to CUDA that enables kernels to directly call other kernels. Earlier versions of CUDA only allowed kernels to be launched from the host code. When we studied &lt;GPU Pattern: Parallel Scan&gt;, the segmented approach required multiple kernel calls.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Profiling CUDA Applications</title>
      <link>http://localhost:1313/notes/profiling_cuda_applications/</link>
      <pubDate>Mon, 15 Jan 2024 14:48:00 -0600</pubDate>
      <guid>http://localhost:1313/notes/profiling_cuda_applications/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#overview-of-nsight&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Overview of Nsight&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#getting-started-with-nsight&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Getting Started with Nsight&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#case-study-matrix-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Case Study: Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tips-and-best-practices&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tips and Best Practices&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#ocl-notes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;OCL Notes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;overview-of-nsight&#34;&gt;Overview of Nsight&lt;/h2&gt;&#xA;&lt;p&gt;NVIDIA NSight Compute is a profiling tool for CUDA kernels. It features an expert system that can help you identify performance bottlenecks in your code. It is essential for methodically optimizing your code. These notes will cover the basics of using Nsight Compute to profile your CUDA applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to GPGPU Programming</title>
      <link>http://localhost:1313/notes/introduction_to_gpgpu_programming/</link>
      <pubDate>Wed, 20 Dec 2023 00:00:00 -0600</pubDate>
      <guid>http://localhost:1313/notes/introduction_to_gpgpu_programming/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#structure-of-the-course&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Structure of the Course&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#heterogeneous-parallel-computing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Heterogeneous Parallel Computing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#measuring-speedup&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Measuring Speedup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gpu-programming-history&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;GPU Programming History&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#applications&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Applications&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-to-expect-from-this-course&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What to expect from this course&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;structure-of-the-course&#34;&gt;Structure of the Course&lt;/h2&gt;&#xA;&lt;p&gt;The primary of this goal is of course to learn how to program GPUs. A key skill that will be developed is the ability to think in parallel. We will start with simple problems that are &lt;em&gt;embarrassingly parallel&lt;/em&gt; and then move on to more complex problems that require synchronization. One of the biggest challenges will be in converting processes that are simple to reason about in serial to parallel processes.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
