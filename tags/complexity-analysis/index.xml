<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>complexity analysis on Alex Dillhoff</title>
    <link>https://ajdillhoff.github.io/tags/complexity-analysis/</link>
    <description>Recent content in complexity analysis on Alex Dillhoff</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; {year}</copyright>
    <lastBuildDate>Mon, 25 Sep 2023 00:00:00 -0500</lastBuildDate>
    
	    <atom:link href="https://ajdillhoff.github.io/tags/complexity-analysis/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Complexity Analysis</title>
      <link>https://ajdillhoff.github.io/notes/complexity_analysis/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 -0500</pubDate>
      
      <guid>https://ajdillhoff.github.io/notes/complexity_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;
&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-notation-of-complexity-analysis&#34;&gt;The notation of complexity analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#formal-definition-of-asymptotic-notation&#34;&gt;Formal Definition of Asymptotic Notation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#common-functions&#34;&gt;Common Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!--endtoc--&gt;
&lt;h2 id=&#34;the-notation-of-complexity-analysis&#34;&gt;The notation of complexity analysis&lt;/h2&gt;
&lt;h3 id=&#34;o-notation&#34;&gt;$O$-notation&lt;/h3&gt;
&lt;p&gt;$O$-notation, often referred to as &amp;ldquo;Big Oh&amp;rdquo; notation, describes an upper bound on the behavior of a function. It really means that the function &lt;em&gt;will not grow faster&lt;/em&gt; than the a given rate. This rate is typically the highest-order term in the function, and is often referred to as the &amp;ldquo;dominant term&amp;rdquo; or &amp;ldquo;dominant function&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;For example, the function \(f(n) = 3n^2 + 2n + 1\) has a dominant term of \(n^2\), and so we would say that \(f(n) = O(n^2)\). We could also accurately describe \(f(n)\) as \(O(n^3)\) since it technically does not grow at a faster rate than \(n^3\), but this is less common as it misleads the reader into thinking that the function is bounded at \(n^3\).&lt;/p&gt;
&lt;h3 id=&#34;and-omega-notation&#34;&gt;$Ω$-notation&lt;/h3&gt;
&lt;p&gt;$Ω$-notation is used to describe the lower bound on the asymptotic behavior of a function. Specifically, it means that the function grows &lt;em&gt;at least as fast&lt;/em&gt; as the given rate. The function \(f(n) = 3n^2 + 2n + 1\) grows at least as fast as \(n^2\), so we would say that \(f(n) = \Omega(n^2)\). It does not grow as fast as \(n^3\), however.&lt;/p&gt;
&lt;p&gt;Just like $O$-notation, we can abuse this definition and say that something that grows at least as fast as \(n^2\) also grows as fast as \(n\). This would lead the reader to believe that the function is bounded at \(n\), which is not true. For this reason, we typically use the tightest bound possible.&lt;/p&gt;
&lt;h3 id=&#34;and-theta-notation&#34;&gt;$Θ$-notation&lt;/h3&gt;
&lt;p&gt;$Θ$-notation gives a tightly bound characterization of a function&amp;rsquo;s behavior. It gives the rate of growth within a constant factor bounded above as well as constant factor bounded below.&lt;/p&gt;
&lt;p&gt;To show that a function is \(\Theta(f(n))\), we must show that it is both \(O(f(n))\) and \(\Omega(f(n))\). Taking our example from above, the function \(f(n) = 3n^2 + 2n + 1\) is \(\Theta(n^2)\).&lt;/p&gt;
&lt;h3 id=&#34;example-insertion-sort&#34;&gt;Example: Insertion Sort&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s put this notation to work and characterize the running time of insertion sort. We&amp;rsquo;ll start by writing out the pseudocode for the algorithm:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;insertion_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(A)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; A[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; key:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[j]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;From our &lt;a href=&#34;https://ajdillhoff.github.io/notes/introduction_to_complexity_analysis/&#34;&gt;Introduction to Algorithms&lt;/a&gt; lecture, we already know that the outer loop runs \((n-1)\) times (although the loop is checked \(n\) times). This is not dependent on the order of the \(n\) inputs either. The inner loop is dependent on the values of our input. It could run anywhere between 0 and \(i-1\) times. In the worst case, we saw that it would run \(n-1\) times as well. With this, we concluded that the running time of insertion sort is \(O(n^2)\). Since this was derived for the worst-case, it is reasonable to say that insertion sort is \(O(n^2)\) for all cases.&lt;/p&gt;
&lt;p&gt;The key to the number of operations that the inner loop takes is &lt;code&gt;A[j + 1] = A[j]&lt;/code&gt;, or the number of times a value is shifted to the right. Given an input of \(n\) elements in the worst-case scenario, we can split the input into 3 partitions where the largest \(\lfloor\frac{n}{4}\rfloor\) values are in the first partition. The second partition has size \(\lceil\frac{n}{2}\rceil\), and the last partition has size \(\lfloor\frac{n}{4}\rfloor\). By using the floor and ceiling functions, we can accommodate for odd values of \(n\).&lt;/p&gt;
&lt;p&gt;When the array is finally sorted, the largest \(\lfloor\frac{n}{4}\rfloor\) values will be in the last partition. That means that they would have passed through the middle \(\lceil\frac{n}{2}\rceil\) values one at a time. Therefore, we can state that the worst-case is proportional to&lt;/p&gt;
&lt;p&gt;\[
\left(\left\lfloor\frac{n}{4}\right\rfloor\right)\left(\left\lceil\frac{n}{2}\right\rceil\right) \leq \frac{n^2}{8}.
\]&lt;/p&gt;
&lt;p&gt;This is \(\Omega(n^2)\), so we can conclude that insertion sort is \(\Theta(n^2)\).&lt;/p&gt;
&lt;h3 id=&#34;bonus-example-selection-sort&#34;&gt;Bonus Example: Selection Sort&lt;/h3&gt;
&lt;p&gt;Use a similar analysis to show that the worst-case for selection sort is \(\Theta(n^2)\). As a reminder, selection sort is defined as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;selection_sort&lt;/span&gt;(A):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(A)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        min_j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(A)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; A[j] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; A[min_j]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                min_j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; j
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        A[i], A[min_j] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[min_j], A[i]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We have already observed that the outer loop iterates \(n-1\) times. Even in the best case, the inner loop runs proportional to \(n\) times. This is sufficient to conclude that the running time is \(O(n^2)\) for all cases.&lt;/p&gt;
&lt;p&gt;For showing that the worst case is \(\Omega(n^2)\), we could use the same argument as insertion sort. However, that isn&amp;rsquo;t necessary. In &lt;em&gt;any&lt;/em&gt; case, the inner loop will run proportional to \(n\) times. It is not dependent on any specific arrangement of the input as selection sort is. Therefore, we can conclude that the worst-case is \(\Omega(n^2)\), and so selection sort is \(\Theta(n^2)\).&lt;/p&gt;
&lt;h2 id=&#34;formal-definition-of-asymptotic-notation&#34;&gt;Formal Definition of Asymptotic Notation&lt;/h2&gt;
&lt;p&gt;Now that we have established some understanding of the notation, let&amp;rsquo;s define it formally. We typically use functions whose domains are over the set of natural or real numbers.&lt;/p&gt;
&lt;h3 id=&#34;o-notation&#34;&gt;$O$-notation&lt;/h3&gt;
&lt;p&gt;We previously established that $O$-notation described as &lt;strong&gt;asymptotic upper bound&lt;/strong&gt;. It was briefly mentioned that this bound holds within a constant factor, which we will now define more thoroughly. For a function \(g(n)\), \(O(g(n)) = \{f(n) : \exists c &amp;gt; 0, n_0 &amp;gt; 0 \text{ such that } 0 \leq f(n) \leq cg(n) \text{ for all } n \geq n_0\}\). It might make more sense to visualize this definition.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-09-26_17-43-51_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Visualization of $O$-notation (source: Cormen et al.)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Visualization of $O$-notation (source: Cormen et al.)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Notice that the function \(f(n)\) is bounded above by \(cg(n)\) for all \(n \geq n_0\) in the figure above.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s put this definition to the test with an example. Given a function \(f(n) = 3n^2 + 200n + 1000\), show that \(f(n) = O(n^2)\). The goal is to find positive constants \(c\) and \(n_0\) such that \(3n^2 + 200n + 1000 \leq cn^2\) for all \(n \geq n_0\). Dividing both sides by \(n^2\) yields&lt;/p&gt;
&lt;p&gt;\[
3 + \frac{200}{n} + \frac{1000}{n^2} \leq c.
\]&lt;/p&gt;
&lt;p&gt;This equation has many possible solutions. Let&amp;rsquo;s choose \(n_0 = 2\), then&lt;/p&gt;
&lt;p&gt;\[
3 + \frac{200}{2} + \frac{1000}{2^2} = 3 + 100 + 250 = 353 \leq c.
\]&lt;/p&gt;
&lt;p&gt;Therefore, we can conclude that \(f(n) = O(n^2)\).&lt;/p&gt;
&lt;h3 id=&#34;and-omega-notation&#34;&gt;$Ω$-notation&lt;/h3&gt;
&lt;p&gt;The notation used to describe an &lt;strong&gt;asymptotic lower bound&lt;/strong&gt; is formally defined as \(\Omega(g(n)) = \{f(n) : \exists c &amp;gt; 0, n_0 &amp;gt; 0 \text{ such that } 0 \leq cg(n) \leq f(n) \text{ for all } n \geq n_0\}\). Again, it is helpful to visualize this.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-09-26_18-17-07_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 2: &amp;lt;/span&amp;gt;Visualization of $&amp;amp;Omega;$-notation (source: Cormen et al.)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 2: &lt;/span&gt;Visualization of $Ω$-notation (source: Cormen et al.)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Notice that the function \(f(n)\) is bounded below by \(cg(n)\) for all \(n \geq n_0\) in the figure above.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s revisit our function from above and show that \(f(n) = \Omega(n^2)\). The goal is to find positive constants \(c\) and \(n_0\) such that \(3n^2 + 200n + 1000 \geq cn^2\) for all \(n \geq n_0\). Dividing both sides by \(n^2\) yields&lt;/p&gt;
&lt;p&gt;\[
3 + \frac{200}{n} + \frac{1000}{n^2} \geq c.
\]&lt;/p&gt;
&lt;p&gt;This holds when \(c = 3\) and \(n_0\) is any positive integer. To see this, think about what happens to this function as \(n\) approaches infinity. The first term will always be 3, and the second and third terms will approach 0. Therefore, we can conclude that \(f(n) = \Omega(n^2)\).&lt;/p&gt;
&lt;h3 id=&#34;and-theta-notation&#34;&gt;$Θ$-notation&lt;/h3&gt;
&lt;p&gt;Lastly, the notation used for an &lt;strong&gt;asymptotically tight bound&lt;/strong&gt; is \(\Theta(g(n)) = \{f(n) : \exists c_1, c_2 &amp;gt; 0, n_0 &amp;gt; 0 \text{ such that } 0 \leq c_1g(n) \leq f(n) \leq c_2g(n) \text{ for all } n \geq n_0\}\).&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-09-26_18-23-25_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 3: &amp;lt;/span&amp;gt;Visualization of $&amp;amp;Theta;$-notation (source: Cormen et al.)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 3: &lt;/span&gt;Visualization of $Θ$-notation (source: Cormen et al.)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;We had mentioned previously that if \(f(n) = \Omega(g(n))\) and \(f(n) = O(g(n))\), then \(f(n) = \Theta(g(n))\). This is formalized in the following theorem, as stated in Cormen et al.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For any two functions \(f(n)\) and \(g(n)\), we have \(f(n) = \Theta(g(n))\) if and only if \(f(n) = O(g(n))\) and \(f(n) = \Omega(g(n))\).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;function-properties&#34;&gt;Function Properties&lt;/h3&gt;
&lt;p&gt;The following properties are useful when analyzing the asymptotic behavior of functions.&lt;/p&gt;
&lt;h4 id=&#34;transitivity&#34;&gt;Transitivity&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;If \(f(n) = O(g(n))\) and \(g(n) = O(h(n))\), then \(f(n) = O(h(n))\).&lt;/li&gt;
&lt;li&gt;If \(f(n) = \Omega(g(n))\) and \(g(n) = \Omega(h(n))\), then \(f(n) = \Omega(h(n))\).&lt;/li&gt;
&lt;li&gt;If \(f(n) = \Theta(g(n))\) and \(g(n) = \Theta(h(n))\), then \(f(n) = \Theta(h(n))\).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reflexivity&#34;&gt;Reflexivity&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\(f(n) = O(f(n))\)&lt;/li&gt;
&lt;li&gt;\(f(n) = \Omega(f(n))\)&lt;/li&gt;
&lt;li&gt;\(f(n) = \Theta(f(n))\)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;symmetry&#34;&gt;Symmetry&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\(f(n) = \Theta(g(n))\) if and only if \(g(n) = \Theta(f(n))\).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;transpose-symmetry&#34;&gt;Transpose Symmetry&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;\(f(n) = O(g(n))\) if and only if \(g(n) = \Omega(f(n))\).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;common-functions&#34;&gt;Common Functions&lt;/h2&gt;
&lt;p&gt;The functions used to describe both time and space complexity are visualized below.&lt;/p&gt;






&lt;figure&gt;

&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2023-09-26_19-11-32_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 4: &amp;lt;/span&amp;gt;Common functions used in complexity analysis (source: Wikipedia)&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  
  &lt;p&gt;
    &lt;span class=&#34;figure-number&#34;&gt;Figure 4: &lt;/span&gt;Common functions used in complexity analysis (source: Wikipedia)
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

</description>
    </item>
    
  </channel>
</rss>
