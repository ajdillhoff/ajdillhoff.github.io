<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alex Dillhoff</title>
    <link>https://ajdillhoff.github.io/</link>
    <description>Recent content on Alex Dillhoff</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sat, 14 Jun 2025 00:00:00 -0400</lastBuildDate>
    <atom:link href="https://ajdillhoff.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Description</title>
      <link>https://ajdillhoff.github.io/courses/cse3315/description/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse3315/description/</guid>
      <description>Selected theoretical concepts including regular and context-free languages, finite state and pushdown automata, Turing machines, computability, and complexity theory.</description>
    </item>
    <item>
      <title>Description</title>
      <link>https://ajdillhoff.github.io/courses/cse4310/description/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse4310/description/</guid>
      <description>Covers basic concepts in computer vision, including image formation, image filtering, feature extraction, stereo vision, and object recognition.</description>
    </item>
    <item>
      <title>Description</title>
      <link>https://ajdillhoff.github.io/courses/cse6363/description/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse6363/description/</guid>
      <description>Graduate-level machine learning topics covering the foundations up to modern publications.</description>
    </item>
    <item>
      <title>Description</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse3380/description/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse3380/description/</guid>
      <description>Linear Algebra theory combined with applications in Engineering and Computer Science.</description>
    </item>
    <item>
      <title>Description</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363/description/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363/description/</guid>
      <description>Graduate-level machine learning topics covering the foundations up to modern publications.</description>
    </item>
    <item>
      <title>Description</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363_8wk/description/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363_8wk/description/</guid>
      <description>Graduate-level machine learning topics covering the foundations up to modern publications.</description>
    </item>
    <item>
      <title>DASC 5304 - Machine Learning</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/dasc5304/description/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/dasc5304/description/</guid>
      <description>Graduate-level machine learning topics covering the foundations up to modern publications.</description>
    </item>
    <item>
      <title>Description</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse4310/description/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse4310/description/</guid>
      <description>Covers basic concepts in computer vision, including image formation, image filtering, feature extraction, stereo vision, and object recognition.</description>
    </item>
    <item>
      <title>Description</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse5373/description/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse5373/description/</guid>
      <description>Study of general purpose computation on a GPU. Topics include GPU architecture, CUDA programming, and performance optimization.</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/cse3315/materials/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse3315/materials/</guid>
      <description>&lt;h4 id=&#34;books&#34;&gt;Books&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Michael Sipser, &lt;a href=&#34;https://www.cengage.com/c/introduction-to-the-theory-of-computation-3e-sipser/9781133187790/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Introduction to the Theory of Computation&lt;/a&gt;, Cengage, 2013.&lt;/li&gt;&#xA;&lt;li&gt;Richard Hammack, &lt;a href=&#34;https://richardhammack.github.io/BookOfProof/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Book of Proof&lt;/a&gt;, Self published, 2018.&lt;/li&gt;&#xA;&lt;li&gt;Daniel J. Velleman, &lt;a href=&#34;https://www.cambridge.org/us/universitypress/subjects/mathematics/logic-categories-and-sets/how-prove-it-structured-approach-3rd-edition?format=PB&amp;amp;isbn=9781108424189&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;How To Prove It&lt;/a&gt;, Cambridge University Press, 2019.&lt;/li&gt;&#xA;&lt;li&gt;Avi Wigderson, &lt;a href=&#34;https://www.math.ias.edu/files/mathandcomp.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Mathematics and Computation&lt;/a&gt;, Online, 2018.&lt;/li&gt;&#xA;&lt;li&gt;Kenneth H. Rosen, &lt;a href=&#34;https://www.mheducation.com/highered/product/Discrete-Mathematics-and-Its-Applications-Rosen.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Discrete Mathematics and Its Applications&lt;/a&gt;, McGraw-Hill, 2018.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=9syvZr-9xwk&amp;amp;list=PLUl4u3cNGP60_JNv2MmK3wkOt9syvfQWY&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;MIT 18.404J Theory of Computation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/cse4310/materials/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse4310/materials/</guid>
      <description>&lt;h4 id=&#34;books&#34;&gt;Books&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Richard Szeliski, &lt;a href=&#34;https://szeliski.org/Book/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Computer Vision: Algorithms and Applications&lt;/a&gt;, Springer, 2020.&lt;/li&gt;&#xA;&lt;li&gt;David Forsyth and Jean Ponce, &lt;a href=&#34;https://www.amazon.com/Computer-Vision-Modern-Approach-2nd/dp/013608592X&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Computer Vision: A Modern Approach&lt;/a&gt;, Prentice Hall, 2011.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://opencv.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;OpenCV&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Anaconda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/cse6363/materials/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse6363/materials/</guid>
      <description>&lt;h4 id=&#34;books&#34;&gt;Books&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Christopher M. Bishop, &lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;, Springer, 2006.&lt;/li&gt;&#xA;&lt;li&gt;Trevor Hastie, Robert Tibshirani, and Jerome Friedman, &lt;a href=&#34;https://hastie.su.domains/ElemStatLearn/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&lt;/a&gt;, Springer, 2009.&lt;/li&gt;&#xA;&lt;li&gt;Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, &lt;a href=&#34;https://www.statlearning.com/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer, 2023.&lt;/li&gt;&#xA;&lt;li&gt;Kevin Murphy, &lt;a href=&#34;https://probml.github.io/pml-book/book1.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Probabilistic Machine Learning: An Introduction&lt;/a&gt;, MIT Press, 2022.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.lightning.ai/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch Lightning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Anaconda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.deep-ml.com/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;ML Code Challenges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse3380/materials/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse3380/materials/</guid>
      <description>&lt;h2 id=&#34;books&#34;&gt;Books&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;David Lay, Stephen Lay, and Judi McDonald, &lt;a href=&#34;https://www.google.com/books/edition/Linear_Algebra_and_Its_Applications/CeL5rQEACAAJ?hl=en&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Linear Algebra and Its Applications (5th ed.)&lt;/a&gt;, Pearson, 2016.&lt;/li&gt;&#xA;&lt;li&gt;Sheldon Axler, &lt;a href=&#34;https://www.google.com/books/edition/Linear_Algebra_Done_Right/5qYxBQAAQBAJ?hl=en&amp;amp;gbpv=1&amp;amp;dq=Linear&amp;#43;Algebra&amp;#43;Done&amp;#43;Right&amp;amp;printsec=frontcover&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Linear Algebra Done Right&lt;/a&gt;, Springer International Publishing, 2014.&lt;/li&gt;&#xA;&lt;li&gt;Wanmo Kang, Kyunghyun Cho, &lt;a href=&#34;https://kyunghyuncho.me/linear-algebra-for-data-science/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Linear Algebra for Data Science&lt;/a&gt;, 2024.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://youtu.be/fNk_zzaMoSs&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;3blue1brown - Essence of Linear Algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.math.utah.edu/~schwede/MichiganClasses/math217/RowReplacementIsOk.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Why row replacement doesn&amp;rsquo;t change the solution set&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363/materials/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363/materials/</guid>
      <description>&lt;h4 id=&#34;books&#34;&gt;Books&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Christopher M. Bishop, &lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;, Springer, 2006.&lt;/li&gt;&#xA;&lt;li&gt;Trevor Hastie, Robert Tibshirani, and Jerome Friedman, &lt;a href=&#34;https://hastie.su.domains/ElemStatLearn/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&lt;/a&gt;, Springer, 2009.&lt;/li&gt;&#xA;&lt;li&gt;Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, &lt;a href=&#34;https://www.statlearning.com/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer, 2023.&lt;/li&gt;&#xA;&lt;li&gt;Kevin Murphy, &lt;a href=&#34;https://probml.github.io/pml-book/book1.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Probabilistic Machine Learning: An Introduction&lt;/a&gt;, MIT Press, 2022.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.lightning.ai/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch Lightning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Anaconda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.deep-ml.com/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;ML Code Challenges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363_8wk/materials/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363_8wk/materials/</guid>
      <description>&lt;h4 id=&#34;books&#34;&gt;Books&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Christopher M. Bishop, &lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;, Springer, 2006.&lt;/li&gt;&#xA;&lt;li&gt;Trevor Hastie, Robert Tibshirani, and Jerome Friedman, &lt;a href=&#34;https://hastie.su.domains/ElemStatLearn/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&lt;/a&gt;, Springer, 2009.&lt;/li&gt;&#xA;&lt;li&gt;Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, &lt;a href=&#34;https://www.statlearning.com/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer, 2023.&lt;/li&gt;&#xA;&lt;li&gt;Kevin Murphy, &lt;a href=&#34;https://probml.github.io/pml-book/book1.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Probabilistic Machine Learning: An Introduction&lt;/a&gt;, MIT Press, 2022.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.lightning.ai/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch Lightning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Anaconda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.deep-ml.com/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;ML Code Challenges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/dasc5304/materials/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/dasc5304/materials/</guid>
      <description>&lt;h4 id=&#34;books&#34;&gt;Books&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Christopher M. Bishop, &lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;, Springer, 2006.&lt;/li&gt;&#xA;&lt;li&gt;Trevor Hastie, Robert Tibshirani, and Jerome Friedman, &lt;a href=&#34;https://hastie.su.domains/ElemStatLearn/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&lt;/a&gt;, Springer, 2009.&lt;/li&gt;&#xA;&lt;li&gt;Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, &lt;a href=&#34;https://www.statlearning.com/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer, 2023.&lt;/li&gt;&#xA;&lt;li&gt;Kevin Murphy, &lt;a href=&#34;https://probml.github.io/pml-book/book1.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Probabilistic Machine Learning: An Introduction&lt;/a&gt;, MIT Press, 2022.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Anaconda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse4310/materials/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse4310/materials/</guid>
      <description>&lt;h4 id=&#34;books&#34;&gt;Books&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Richard Szeliski, &lt;a href=&#34;https://szeliski.org/Book/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Computer Vision: Algorithms and Applications&lt;/a&gt;, Springer, 2020.&lt;/li&gt;&#xA;&lt;li&gt;David Forsyth and Jean Ponce, &lt;a href=&#34;https://www.amazon.com/Computer-Vision-Modern-Approach-2nd/dp/013608592X&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Computer Vision: A Modern Approach&lt;/a&gt;, Prentice Hall, 2011.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://opencv.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;OpenCV&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pytorch.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;PyTorch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Anaconda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Course Materials</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse5373/materials/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse5373/materials/</guid>
      <description>&lt;h4 id=&#34;books&#34;&gt;Books&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Wen-mei W. Hwu, David B. Kirk, Izzat El Hajj. &lt;a href=&#34;https://shop.elsevier.com/books/programming-massively-parallel-processors/hwu/978-0-323-91231-0&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Programming Massively Parallel Processors: A Hands-on Approach&lt;/a&gt;, 4th Edition, 2022.&lt;/li&gt;&#xA;&lt;li&gt;Jason Sanders and Edward Kandrot, &lt;a href=&#34;https://www.amazon.com/CUDA-Example-Introduction-General-Purpose-Programming/dp/0131387685&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;CUDA by Example: An Introduction to General-Purpose GPU Programming&lt;/a&gt;, Addison-Wesley Professional, 2010.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python Programming Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/cuda/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;CUDA&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/cse3315/schedule/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse3315/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 2&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction and Background&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;Chapter 0&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 4&lt;/td&gt;&#xA;        &lt;td&gt;Finite Automata, Regular Operations and Closure&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;1.1&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 9&lt;/td&gt;&#xA;        &lt;td&gt;Nondeterminism and Regular Expressions&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;1.2, 1.3&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 11&lt;/td&gt;&#xA;        &lt;td&gt;Regular Expressions, FSA Equivalence&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;1.3&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 16&lt;/td&gt;&#xA;        &lt;td&gt;FSA Equivalence, Pumping Lemma&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;1.3, 1.4&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 18&lt;/td&gt;&#xA;        &lt;td&gt;State Minimization, Countability&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;4.2&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/cse4310/schedule/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse4310/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 3&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction, Python Review&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 5&lt;/td&gt;&#xA;        &lt;td&gt;Color, Sampling and Aliasing&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/color&#34;&gt;Light and Color&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/sampling&#34;&gt;Sampling and Aliasing&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 10&lt;/td&gt;&#xA;        &lt;td&gt;Linear Filters and Interest Points&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_filters&#34;&gt;Linear Filters&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/image_features&#34;&gt;Interest Points&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 12&lt;/td&gt;&#xA;        &lt;td&gt;Histogram of Oriented Features, Scale-Invariant Feature Transform&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/histogram_of_oriented_gradients&#34;&gt;HOG&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/scale_invariant_feature_transforms&#34;&gt;SIFT&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 17&lt;/td&gt;&#xA;        &lt;td&gt;Scale-Invariant Feature Transform, Template Matching, Bag of Words&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/scale_invariant_feature_transforms&#34;&gt;SIFT&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://github.com/ajdillhoff/CSE4310/blob/main/feature_matching.ipynb&#34;&gt;Template Matching&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/bag_of_visual_words&#34;&gt;Bag of Visual Words&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 19&lt;/td&gt;&#xA;        &lt;td&gt;Juneteenth Holiday&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/cse6363/schedule/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/cse6363/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 2&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction, Supervised Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 4&lt;/td&gt;&#xA;        &lt;td&gt;Supervised Learning, Logistic Regression, HW1 Out&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/logistic_regression&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 9&lt;/td&gt;&#xA;        &lt;td&gt;Review of Probability Theory, Linear Discriminant Analysis&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/probability_theory&#34;&gt;Probability Theory&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_discriminant_analysis&#34;&gt;LDA&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 11&lt;/td&gt;&#xA;        &lt;td&gt;Naive Bayes, Kernels&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/naive_bayes&#34;&gt;Naive Bayes&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/kernels&#34;&gt;Kernels&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 16&lt;/td&gt;&#xA;        &lt;td&gt;Kernels&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/kernels&#34;&gt;Kernels&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;June 18&lt;/td&gt;&#xA;        &lt;td&gt;Support Vector Machine&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/publication/sequential-minimal-optimization-a-fast-algorithm-for-training-support-vector-machines/&#34;&gt;Sequential Minimal Optimization&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse3380/schedule/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse3380/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 1&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction and Systems of Linear Equations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;1.1 and 1.2&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 2&lt;/td&gt;&#xA;        &lt;td&gt;Solution Sets, Vectors, and Linear Combinations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;1.3, 1.4, and 1.5&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 3&lt;/td&gt;&#xA;        &lt;td&gt;Matrix Operations, Block Matrices, and Determinants&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;2.1, 2.2, 2.4, 3.1, 3.2&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 4&lt;/td&gt;&#xA;        &lt;td&gt;Vector Spaces and Subspaces&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;1.8, 2.8, 4.1, and 4.2&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 5&lt;/td&gt;&#xA;        &lt;td&gt;Exam Week (Review and Exam 1)&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 6&lt;/td&gt;&#xA;        &lt;td&gt;Subspaces, Linear Independence, Bases, and Linear Transformations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;1.8, 4.2, and 4.2&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 7&lt;/td&gt;&#xA;        &lt;td&gt;Computer Graphics, Determinants and Volumes&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;3.3 and 4.4&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 8&lt;/td&gt;&#xA;        &lt;td&gt;Change of Basis&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;4.7&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 9&lt;/td&gt;&#xA;        &lt;td&gt;Spring Break&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 10&lt;/td&gt;&#xA;        &lt;td&gt;Orthogonality and Gram-Schmidt&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;6.1 and 6.2&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 11&lt;/td&gt;&#xA;        &lt;td&gt;QR Factorization, Exam 2&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;6.3&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 12&lt;/td&gt;&#xA;        &lt;td&gt;Least-Squares Solutions, Image Stitching and RANSAC&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;6.5 and 6.6&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 13&lt;/td&gt;&#xA;        &lt;td&gt;Eigenvalues and Eigenvectors&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;5.1&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 14&lt;/td&gt;&#xA;        &lt;td&gt;Diagonalization, Singular Value Decomposition&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;5.3, 7.1, and 7.4&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 15&lt;/td&gt;&#xA;        &lt;td&gt;Prinicpal Component Analysis&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/principal_component_analysis&#34;&gt;PCA&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;Week 16&lt;/td&gt;&#xA;        &lt;td&gt;Exam 3 Review&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363/schedule/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 14&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 16&lt;/td&gt;&#xA;        &lt;td&gt;Supervised Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/regularization&#34;&gt;Regularization&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/logistic_regression&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 21&lt;/td&gt;&#xA;        &lt;td&gt;Probability Theory Review&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/probability_theory&#34;&gt;Probability Theory&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://online.stat.psu.edu/stat415/lesson/1/1.2&#34;&gt;Maximum Likelihood Estimation&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 23&lt;/td&gt;&#xA;        &lt;td&gt;Probabilistic Models&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_discriminant_analysis&#34;&gt;Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/naive_bayes&#34;&gt;Naive Bayes Classifier&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 28&lt;/td&gt;&#xA;        &lt;td&gt;Kernels and Support Vector Machine&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/kernels&#34;&gt;Kernel Methods&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/support_vector_machine&#34;&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 30&lt;/td&gt;&#xA;        &lt;td&gt;Using Python for Machine Learning, Decision Trees&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/decision_trees&#34;&gt;Decision Trees&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 4&lt;/td&gt;&#xA;        &lt;td&gt;Perceptron and Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/perceptron&#34;&gt;Perceptron&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/neural_networks&#34;&gt;Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 11&lt;/td&gt;&#xA;        &lt;td&gt;Bagging, Random Forests, and Adaboost&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/boosting&#34;&gt;Adaboost&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 13&lt;/td&gt;&#xA;        &lt;td&gt;Gradient Boosting&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gradient_boosting&#34;&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 18&lt;/td&gt;&#xA;        &lt;td&gt;Intro. to Deep Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/deep_learning&#34;&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/convolutional_neural_networks&#34;&gt;Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 20&lt;/td&gt;&#xA;        &lt;td&gt;Convolutional Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/convolutional_neural_networks&#34;&gt;Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html&#34;&gt;Pytorch Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 27&lt;/td&gt;&#xA;        &lt;td&gt;Optimization for Deep Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/optimization_for_deep_learning&#34;&gt;Optimization for Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 4&lt;/td&gt;&#xA;        &lt;td&gt;Automatic Differentiation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1502.05767&#34;&gt;Automatic Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 18&lt;/td&gt;&#xA;        &lt;td&gt;Clustering&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/clustering&#34;&gt;Clustering&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 20&lt;/td&gt;&#xA;        &lt;td&gt;Principal Component Analysis&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&#34;&gt;Chapter 12.1&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 25&lt;/td&gt;&#xA;        &lt;td&gt;Segmentation by Clustering, GANs&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/segmentation_via_clustering&#34;&gt;Segmentation via Clustering&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1406.2661&#34;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 27&lt;/td&gt;&#xA;        &lt;td&gt;Markov Decision Processes&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/markov_decision_processes&#34;&gt;Markov Decision Processes&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 1&lt;/td&gt;&#xA;        &lt;td&gt;Reinforcement Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2018-02-19-rl-overview/&#34;&gt;Reinforcement Learning Overview&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;http://incompleteideas.net/book/RLbook2020.pdf&#34;&gt;Chapters 3-6&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 3&lt;/td&gt;&#xA;        &lt;td&gt;Policy Gradient Methods&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/policy_gradient_methods&#34;&gt;Policy Gradient Methods&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 8&lt;/td&gt;&#xA;        &lt;td&gt;Natural Language Processing, Large Language Models&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/natural_language_processing&#34;&gt;Natural Language Processing&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/pretraining_large_language_models&#34;&gt;Pretraining LLMs&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 10&lt;/td&gt;&#xA;        &lt;td&gt;Recitation Day&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 15&lt;/td&gt;&#xA;        &lt;td&gt;LLM Post-Training, RAG&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/fine_tuning_llms&#34;&gt;Fine-tuning LLMs&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/blog/using-rag-to-talk-to-your-data&#34;&gt;Using RAG to Talk to Your Data&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 17&lt;/td&gt;&#xA;        &lt;td&gt;Vision Transformers, Pose Estimation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transfomers_for_computer_vision&#34;&gt;Transformers for Computer Vision&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 22&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 24&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 29&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363_8wk/schedule/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse6363_8wk/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 13&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction, Supervised Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/logistic_regression&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 15&lt;/td&gt;&#xA;        &lt;td&gt;Regularization, Probability Theory, and Linear Discriminant Analysis&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/regularization&#34;&gt;Regularization&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/probability_theory&#34;&gt;Probability Theory&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_discriminant_analysis&#34;&gt;Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 22&lt;/td&gt;&#xA;        &lt;td&gt;Naive Bayes Classifier, Support Vector Machine&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/naive_bayes&#34;&gt;Naive Bayes Classifier&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/kernels&#34;&gt;Kernels&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/support_vector_machine&#34;&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 27&lt;/td&gt;&#xA;        &lt;td&gt;Support Vector Machine, Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/support_vector_machine&#34;&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/support_vector_machine&#34;&gt;Sequential Minimal Optimization&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/perceptron&#34;&gt;Perceptron&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/neural_networks&#34;&gt;Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 29&lt;/td&gt;&#xA;        &lt;td&gt;Decision Trees, Boosting and Bagging&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/decision_trees&#34;&gt;Decision Trees&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/boosting&#34;&gt;Boosting&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gradient_boosting&#34;&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 3&lt;/td&gt;&#xA;        &lt;td&gt;Gradient Boosting, Deep Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gradient_boosting&#34;&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/convolutional_neural_networks&#34;&gt;Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 5&lt;/td&gt;&#xA;        &lt;td&gt;CNNs for Object Detection, Python for Deep Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/object_detection&#34;&gt;CNNs for Object Detection&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 10&lt;/td&gt;&#xA;        &lt;td&gt;Optimization for Deep Learning, Recurrent Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/optimization_for_deep_learning&#34;&gt;Optimization for Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/recurrent_neural_networks&#34;&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 12&lt;/td&gt;&#xA;        &lt;td&gt;Transformers&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transformers&#34;&gt;Transformers&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 17&lt;/td&gt;&#xA;        &lt;td&gt;Unsupervised Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/clustering&#34;&gt;Clustering&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/segmentation_via_clustering&#34;&gt;Segmentation via Clustering&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/principal_component_analysis&#34;&gt;Principal Component Analysis&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1406.2661&#34;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 19&lt;/td&gt;&#xA;        &lt;td&gt;Reinforcement Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/markov_decision_processes&#34;&gt;Markov Decision Processes&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2018-02-19-rl-overview/&#34;&gt;Reinforcement Learning Overview&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;http://incompleteideas.net/book/RLbook2020.pdf&#34;&gt;Chapters 3-6&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 24&lt;/td&gt;&#xA;        &lt;td&gt;Policy Gradient Methods, Introduction to NLP&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/policy_gradient_methods&#34;&gt;Policy Gradient Methods&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;http://incompleteideas.net/book/RLbook2020.pdf&#34;&gt;Chapter 13&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 26&lt;/td&gt;&#xA;        &lt;td&gt;Large Language Models&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 3&lt;/td&gt;&#xA;        &lt;td&gt;Special Topics&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 5&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/dasc5304/schedule/</link>
      <pubDate>Mon, 19 Aug 2024 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/dasc5304/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 14&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 16&lt;/td&gt;&#xA;        &lt;td&gt;Supervised Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/regularization&#34;&gt;Regularization&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/logistic_regression&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 21&lt;/td&gt;&#xA;        &lt;td&gt;Probability Theory Review&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/probability_theory&#34;&gt;Probability Theory&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://online.stat.psu.edu/stat415/lesson/1/1.2&#34;&gt;Maximum Likelihood Estimation&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 23&lt;/td&gt;&#xA;        &lt;td&gt;Probabilistic Models&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_discriminant_analysis&#34;&gt;Linear Discriminant Analysis&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/naive_bayes&#34;&gt;Naive Bayes Classifier&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 28&lt;/td&gt;&#xA;        &lt;td&gt;Kernels and Support Vector Machine&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/kernels&#34;&gt;Kernel Methods&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/support_vector_machine&#34;&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 30&lt;/td&gt;&#xA;        &lt;td&gt;Using Python for Machine Learning, Decision Trees&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/decision_trees&#34;&gt;Decision Trees&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 4&lt;/td&gt;&#xA;        &lt;td&gt;Perceptron and Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/perceptron&#34;&gt;Perceptron&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/neural_networks&#34;&gt;Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 6&lt;/td&gt;&#xA;        &lt;td&gt;Ensemble Methods&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gradient_boosting&#34;&gt;Random Forest&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/boosting&#34;&gt;Boosting&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 11&lt;/td&gt;&#xA;        &lt;td&gt;Bagging, Random Forests, and Adaboost&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/boosting&#34;&gt;Adaboost&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 13&lt;/td&gt;&#xA;        &lt;td&gt;Gradient Boosting&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gradient_boosting&#34;&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 18&lt;/td&gt;&#xA;        &lt;td&gt;Intro. to Deep Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/deep_learning&#34;&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/convolutional_neural_networks&#34;&gt;Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 20&lt;/td&gt;&#xA;        &lt;td&gt;Convolutional Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/convolutional_neural_networks&#34;&gt;Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html&#34;&gt;Pytorch Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://lightning.ai/docs/pytorch/stable/starter/introduction.html&#34;&gt;Pytorch Lightning&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 27&lt;/td&gt;&#xA;        &lt;td&gt;Optimization for Deep Learning, Object Detection&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/optimization_for_deep_learning&#34;&gt;Optimization for Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/object_detection&#34;&gt;Object Detection&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 4&lt;/td&gt;&#xA;        &lt;td&gt;Automatic Differentiation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1502.05767&#34;&gt;Automatic Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 6&lt;/td&gt;&#xA;        &lt;td&gt;Recurrent Neural Networks, Transformers&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/recurrent_neural_networks&#34;&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transformers&#34;&gt;Transformers&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 18&lt;/td&gt;&#xA;        &lt;td&gt;Clustering&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/clustering&#34;&gt;Clustering&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 20&lt;/td&gt;&#xA;        &lt;td&gt;Principal Component Analysis&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&#34;&gt;Chapter 12.1&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 25&lt;/td&gt;&#xA;        &lt;td&gt;Segmentation by Clustering, GANs&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/segmentation_via_clustering&#34;&gt;Segmentation via Clustering&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1406.2661&#34;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 27&lt;/td&gt;&#xA;        &lt;td&gt;Markov Decision Processes&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/markov_decision_processes&#34;&gt;Markov Decision Processes&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 1&lt;/td&gt;&#xA;        &lt;td&gt;Reinforcement Learning&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2018-02-19-rl-overview/&#34;&gt;Reinforcement Learning Overview&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;http://incompleteideas.net/book/RLbook2020.pdf&#34;&gt;Chapters 3-6&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 3&lt;/td&gt;&#xA;        &lt;td&gt;Policy Gradient Methods&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/policy_gradient_methods&#34;&gt;Policy Gradient Methods&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 8&lt;/td&gt;&#xA;        &lt;td&gt;Natural Language Processing, Large Language Models&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/natural_language_processing&#34;&gt;Natural Language Processing&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/pretraining_large_language_models&#34;&gt;Pretraining LLMs&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 10&lt;/td&gt;&#xA;        &lt;td&gt;Recitation Day&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 15&lt;/td&gt;&#xA;        &lt;td&gt;LLM Post-Training, RAG&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/fine_tuning_llms&#34;&gt;Fine-tuning LLMs&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/blog/using-rag-to-talk-to-your-data&#34;&gt;Using RAG to Talk to Your Data&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 17&lt;/td&gt;&#xA;        &lt;td&gt;Vision Transformers, Pose Estimation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transfomers_for_computer_vision&#34;&gt;Transformers for Computer Vision&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 22&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 24&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 29&lt;/td&gt;&#xA;        &lt;td&gt;Instance Segmentation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/instance_segmentation&#34;&gt;Instance Segmentation&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse4310/schedule/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse4310/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 13&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 15&lt;/td&gt;&#xA;        &lt;td&gt;Human Vision and Color&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/color&#34;&gt;Color&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 17&lt;/td&gt;&#xA;        &lt;td&gt;Sampling and Aliasing&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/sampling&#34;&gt;Sampling and Aliasing&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 22&lt;/td&gt;&#xA;        &lt;td&gt;Linear Filters&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_filters&#34;&gt;Linear Filters&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 24&lt;/td&gt;&#xA;        &lt;td&gt;Interest Points&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/image_features&#34;&gt;Interest Points&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 27&lt;/td&gt;&#xA;        &lt;td&gt;Image Features&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/image_features&#34;&gt;Image Features&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 29&lt;/td&gt;&#xA;        &lt;td&gt;Image Features&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/image_features&#34;&gt;Image Features&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 31&lt;/td&gt;&#xA;        &lt;td&gt;Histogram of Oriented Gradients&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/histogram_of_oriented_gradients&#34;&gt;Histogram of Oriented Gradients&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 3&lt;/td&gt;&#xA;        &lt;td&gt;Scale Invariant Feature Transforms&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/scale_invariant_feature_transforms&#34;&gt;SIFT Features&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 5&lt;/td&gt;&#xA;        &lt;td&gt;Bag of Visual Words and Feature Matching&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/bag_of_visual_words&#34;&gt;Bag of Visual Words&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 10&lt;/td&gt;&#xA;        &lt;td&gt;RANSAC&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/random_sample_consensus&#34;&gt;RANSAC&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 12&lt;/td&gt;&#xA;        &lt;td&gt;Hough Transforms&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/hough_transform&#34;&gt;Hough Transforms&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 14&lt;/td&gt;&#xA;        &lt;td&gt;CANCELLED&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 17&lt;/td&gt;&#xA;        &lt;td&gt;Image Segmentation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/image_segmentation&#34;&gt;Image Segmentation&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 19&lt;/td&gt;&#xA;        &lt;td&gt;Image Segmentation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/segmentation_via_clustering&#34;&gt;Segmentation via Clustering&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 21&lt;/td&gt;&#xA;        &lt;td&gt;Machine Learning Basics&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/linear_regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/logistic_regression&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 24&lt;/td&gt;&#xA;        &lt;td&gt;Machine Learning Basics&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/logistic_regression&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 26&lt;/td&gt;&#xA;        &lt;td&gt;Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/neural_networks&#34;&gt;Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 28&lt;/td&gt;&#xA;        &lt;td&gt;Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/neural_networks&#34;&gt;Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 3&lt;/td&gt;&#xA;        &lt;td&gt;Convolutional Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/convolutional_neural_networks&#34;&gt;Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 5&lt;/td&gt;&#xA;        &lt;td&gt;PyTorch Tutorial&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 7&lt;/td&gt;&#xA;        &lt;td&gt;Pytorch Lightning Tutorial&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 17&lt;/td&gt;&#xA;        &lt;td&gt;Object Detection&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/object_detection&#34;&gt;Object Detection&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 19&lt;/td&gt;&#xA;        &lt;td&gt;Object Detection&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/object_detection&#34;&gt;Object Detection&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 21&lt;/td&gt;&#xA;        &lt;td&gt;NO CLASS&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 24&lt;/td&gt;&#xA;        &lt;td&gt;Optical Flow&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/optical_flow&#34;&gt;Optical Flow&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 26&lt;/td&gt;&#xA;        &lt;td&gt;Tracking&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/tracking&#34;&gt;Tracking&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 31&lt;/td&gt;&#xA;        &lt;td&gt;Kalman Filter&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/tracking&#34;&gt;Tracking&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 2&lt;/td&gt;&#xA;        &lt;td&gt;Camera Models&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/camera_models&#34;&gt;Camera Models&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 4&lt;/td&gt;&#xA;        &lt;td&gt;Instance Segmentation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/instance_segmentation&#34;&gt;Instance Segmentation&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 7&lt;/td&gt;&#xA;        &lt;td&gt;Camera Calibration, Stereo Vision&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/camera_models&#34;&gt;Camera Models&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/stereo_vision&#34;&gt;Stereo Vision&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 9&lt;/td&gt;&#xA;        &lt;td&gt;Recurrent Neural Networks&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/recurrent_neural_networks&#34;&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 11&lt;/td&gt;&#xA;        &lt;td&gt;Transformers&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transformers&#34;&gt;Transformers&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 14&lt;/td&gt;&#xA;        &lt;td&gt;Transformers&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transformers&#34;&gt;Transformers&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 16&lt;/td&gt;&#xA;        &lt;td&gt;Transformers, Vision Transformers&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transformers&#34;&gt;Transformers&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transfomers_for_computer_vision&#34;&gt;Vision Transformer&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 18&lt;/td&gt;&#xA;        &lt;td&gt;Vision Transformers&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/transfomers_for_computer_vision&#34;&gt;Vision Transformer&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 21&lt;/td&gt;&#xA;        &lt;td&gt;Special Topics, Wrap Up&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 23&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 25&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 28&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Schedule</title>
      <link>https://ajdillhoff.github.io/courses/archive/spring2025/cse5373/schedule/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0100</pubDate>
      <guid>https://ajdillhoff.github.io/courses/archive/spring2025/cse5373/schedule/</guid>
      <description>&lt;p&gt;This schedule is tentative and may change.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;th&gt;Date&lt;/th&gt;&#xA;      &lt;th&gt;Topic&lt;/th&gt;&#xA;      &lt;th&gt;Materials&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 13&lt;/td&gt;&#xA;        &lt;td&gt;Course Introduction&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/introduction_to_gpgpu_programming&#34;&gt;Intro. to GPGPU Programming&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 15&lt;/td&gt;&#xA;        &lt;td&gt;Heterogeneous Data Parallel Computing&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/heterogeneous_data_parallel_computing&#34;&gt;Heterogeneous Data Parallel Computing&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 17&lt;/td&gt;&#xA;        &lt;td&gt;Environment Setup Day&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 22&lt;/td&gt;&#xA;        &lt;td&gt;Multidimensional Grids and Data&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/multidimensional_grids_and_data&#34;&gt;Multidimensional Grids and Data&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 24&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 27&lt;/td&gt;&#xA;        &lt;td&gt;Multidimensional Grids and Data&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/multidimensional_grids_and_data&#34;&gt;Multidimensional Grids and Data&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 29&lt;/td&gt;&#xA;        &lt;td&gt;CUDA Compute Architecture&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/cuda_architecture&#34;&gt;CUDA Architecture&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;January 31&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 3&lt;/td&gt;&#xA;        &lt;td&gt;Memory Architecture&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/cuda_memory_architecture&#34;&gt;Memory Architecture&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 5&lt;/td&gt;&#xA;        &lt;td&gt;Tiling and Shared Memory&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/cuda_memory_architecture&#34;&gt;Memory Architecture&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 10&lt;/td&gt;&#xA;        &lt;td&gt;GPU Performance Basics&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_performance_basics&#34;&gt;GPU Performance Basics&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 12&lt;/td&gt;&#xA;        &lt;td&gt;GPU Performance Basics&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_performance_basics&#34;&gt;GPU Performance Basics&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 14&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 17&lt;/td&gt;&#xA;        &lt;td&gt;Convolutional Pattern&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_convolution&#34;&gt;GPU Pattern: Convolution&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 19&lt;/td&gt;&#xA;        &lt;td&gt;Convolutional Pattern&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_convolution&#34;&gt;GPU Pattern: Convolution&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 21&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 26&lt;/td&gt;&#xA;        &lt;td&gt;Profiling and Benchmarking&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/profiling_cuda_applications&#34;&gt;Profiling CUDA Applications&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;February 28&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 3&lt;/td&gt;&#xA;        &lt;td&gt;Stencil Pattern&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_stencils&#34;&gt;GPU Pattern: Stencils&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 5&lt;/td&gt;&#xA;        &lt;td&gt;Parallel Histogram&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_parallel_histogram&#34;&gt;GPU Pattern: Parallel Histogram&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 7&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 17&lt;/td&gt;&#xA;        &lt;td&gt;Parallel Scan&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_parallel_scan&#34;&gt;GPU Pattern: Parallel Scan&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 19&lt;/td&gt;&#xA;        &lt;td&gt;Parallel Scan&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_parallel_scan&#34;&gt;GPU Pattern: Parallel Scan&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 21&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 24&lt;/td&gt;&#xA;        &lt;td&gt;General Reductions&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_reduction&#34;&gt;GPU Pattern: Reduction&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 26&lt;/td&gt;&#xA;        &lt;td&gt;General Reductions&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_reduction&#34;&gt;GPU Pattern: Reduction&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 28&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;March 31&lt;/td&gt;&#xA;        &lt;td&gt;Merge&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_merge&#34;&gt;GPU Pattern: Merge&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 2&lt;/td&gt;&#xA;        &lt;td&gt;Merge&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_merge&#34;&gt;GPU Pattern: Merge&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 4&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 7&lt;/td&gt;&#xA;        &lt;td&gt;Merge, Parallel Sorting Algorithms&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_merge&#34;&gt;GPU Pattern: Merge&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/parallel_sorting_algorithms&#34;&gt;Parallel Sorting Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 9&lt;/td&gt;&#xA;        &lt;td&gt;Merge&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/gpu_pattern_merge&#34;&gt;GPU Pattern: Merge&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 11&lt;/td&gt;&#xA;        &lt;td&gt;Lab/Recitation&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 14&lt;/td&gt;&#xA;        &lt;td&gt;Parallel Sorting Algorithms, Sparse Matrix Multiplication&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/parallel_sorting_algorithms&#34;&gt;Parallel Sorting Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/sparse_matrix_computation&#34;&gt;Sparse Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 16&lt;/td&gt;&#xA;        &lt;td&gt;Sparse Matrix Multiplication&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/sparse_matrix_computation&#34;&gt;Sparse Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 18&lt;/td&gt;&#xA;        &lt;td&gt;Parallel Graph Traversal&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/parallel_graph_traversal&#34;&gt;Parallel Graph Traversal&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 21&lt;/td&gt;&#xA;        &lt;td&gt;Parallel Graph Traversal&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;              &#xA;                &lt;li&gt;&lt;a href=&#34;https://ajdillhoff.github.io/notes/parallel_graph_traversal&#34;&gt;Parallel Graph Traversal&lt;/a&gt;&lt;/li&gt;&#xA;              &#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 23&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 25&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;      &lt;tr&gt;&#xA;        &lt;td&gt;April 28&lt;/td&gt;&#xA;        &lt;td&gt;Project Presentations&lt;/td&gt;&#xA;        &lt;td&gt;&#xA;          &lt;ul&gt;&#xA;            &#xA;          &lt;/ul&gt;&#xA;        &lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;    &#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Fine-Tuning LLMs</title>
      <link>https://ajdillhoff.github.io/notes/fine_tuning_llms/</link>
      <pubDate>Tue, 15 Apr 2025 10:37:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/fine_tuning_llms/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#supervised-fine-tuning&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Supervised Fine-Tuning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#reinforcement-learning-with-human-feedback&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Reinforcement Learning with Human Feedback&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#direct-preference-optimization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Direct Preference Optimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#using-tools&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Using Tools&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#chain-of-thought--cot--and-reasoning&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Chain of Thought (CoT) and Reasoning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;After pre-training an LLM, which builds a general model of language understanding, fine-tuning is necessary to adapt the model to behave like a helpful assistant.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Policy Gradient Methods</title>
      <link>https://ajdillhoff.github.io/notes/policy_gradient_methods/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/policy_gradient_methods/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#policy-gradients&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Policy Gradients&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;When we had full knowledge of the states, we could use &lt;a href=&#34;https://ajdillhoff.github.io/notes/markov_decision_processes/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Markov Decision Processes&lt;/a&gt; to find the optimal policy. When this assumption breaks down, we need to come up with our best approximation. This is not a far stretch from how we might handle new scenarios in our own lives. When we begin a new task, we are certainly not experts. We may learn from a teacher or set off to explore on our own. As we practice and churn out the seemingly endless variations of our endeavour, we begin to develop a sense of what works and what doesn&amp;rsquo;t. We may not be able to articulate the exact rules that we follow, but we can certainly tell when we are doing well or poorly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clustering</title>
      <link>https://ajdillhoff.github.io/notes/clustering/</link>
      <pubDate>Sun, 16 Feb 2025 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/clustering/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#k-means-clustering&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;K-Means Clustering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#k-medoids-clustering&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;K-Medoids Clustering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mixtures-of-gaussians&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Mixtures of Gaussians&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;In machine learning, the three most common forms of learning are&lt;/p&gt;</description>
    </item>
    <item>
      <title>Positional Encoding</title>
      <link>https://ajdillhoff.github.io/notes/positional_encoding/</link>
      <pubDate>Tue, 11 Feb 2025 09:12:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/positional_encoding/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-are-positional-encodings&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What are positional encodings?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#why-are-positional-encodings-needed&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Why are positional encodings needed?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#properties-of-positional-encodings&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Properties of Positional Encodings&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#sinusoidal-positional-encoding&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Sinusoidal Positional Encoding&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#translation-and-rotation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Translation and Rotation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rotary-position-embedding--rope&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rotary Position Embedding (RoPE)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;what-are-positional-encodings&#34;&gt;What are positional encodings?&lt;/h2&gt;&#xA;&lt;p&gt;Positional encodings are a way to encode the position of elements in a sequence. They are used in the context of sequence-to-sequence models, such as transformers, to provide the model with information about the order of elements in the input sequence. These were not needed for models like RNNs and LSTMs since the order of elements in the input sequence is preserved by the recurrent connections.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AVL Trees</title>
      <link>https://ajdillhoff.github.io/notes/avl_trees/</link>
      <pubDate>Thu, 31 Oct 2024 13:30:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/avl_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rebalancing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rebalancing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;&#xA;&lt;p&gt;An AVL tree is a binary search tree that is self-balancing based on the height of the tree. It manages this by adding a balance factor property to each node. Given a node \(X\), the balance factor is defined as:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using RAG to Talk to Your Data</title>
      <link>https://ajdillhoff.github.io/blog/using-rag-to-talk-to-your-data/</link>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/blog/using-rag-to-talk-to-your-data/</guid>
      <description>How can LLMs provide results that are not only factual, but based on your own private data? This article accompanies a workshop given at HackUTA 6 on October 12, 2024.</description>
    </item>
    <item>
      <title>Automatic Differentiation</title>
      <link>https://ajdillhoff.github.io/notes/automatic_differentiation/</link>
      <pubDate>Mon, 23 Sep 2024 18:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/automatic_differentiation/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#types-of-differentiation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Types of Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#forward-mode-ad&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Forward Mode AD&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#reverse-mode-ad&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Reverse Mode AD&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#basic-implementation-in-python&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Basic Implementation in Python&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#matrix-implementation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Matrix Implementation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#comparison-with-pytorch&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Comparison with PyTorch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;These notes largely follow the survey presented by (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Baydin et al. 2018&lt;/a&gt;). I have added a few examples to clarify the matrix algebra as well as a lead in to a practical implemenation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Debugging in C</title>
      <link>https://ajdillhoff.github.io/notes/debugging_in_c/</link>
      <pubDate>Sat, 22 Jun 2024 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/debugging_in_c/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#types-of-errors&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Types of Errors&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#debugging-techniques&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Debugging Techniques&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#examples&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Examples&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;With great power comes great responsibility. -Ben Parker&lt;/p&gt;</description>
    </item>
    <item>
      <title>Low Rank Adaptation</title>
      <link>https://ajdillhoff.github.io/notes/low_rank_adaptation/</link>
      <pubDate>Sat, 08 Jun 2024 13:03:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/low_rank_adaptation/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#key-concepts&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Key Concepts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts&lt;/h2&gt;&#xA;&lt;h3 id=&#34;traditional-fine-tuning&#34;&gt;Traditional Fine-Tuning&lt;/h3&gt;&#xA;&lt;p&gt;Fine-tuning a model for a specific task can be expensive if the entire weight matrix is updated. LLMs range from billions to trillions of parameters, making fine-tuning infeasible for many applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Patch Extraction</title>
      <link>https://ajdillhoff.github.io/notes/patch_extraction/</link>
      <pubDate>Thu, 06 Jun 2024 17:57:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/patch_extraction/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#native-patch-extraction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Native Patch Extraction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#changing-perspective&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Changing Perspective&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-mechanics-of-as-strided&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Mechanics of &lt;code&gt;as_strided&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-about-rgb&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What about RGB?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;This post is a recreation of &lt;a href=&#34;https://x.com/MishaLaskin/status/1478500251376009220&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Misha Laskin&amp;rsquo;s Twitter post&lt;/a&gt; about patch extraction in &lt;code&gt;numpy&lt;/code&gt;. I wanted to provide a version of it that can be accessed without requiring a Twitter account.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NP-Completeness</title>
      <link>https://ajdillhoff.github.io/notes/np_completeness/</link>
      <pubDate>Thu, 25 Apr 2024 11:03:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/np_completeness/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#reductions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Reductions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#clique-problem&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Clique Problem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#vertex-cover-problem&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Vertex Cover Problem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Most of the algorithms discussed in a typical algorithms course run in polynomial time. This focus is reasonable since algorithms that run worse than polynomial time have little practical use. To simplify this notion: a problem for which a polynomial-time algorithm exists is &amp;ldquo;easy&amp;rdquo; and a problem for which no polynomial-time algorithm exists is &amp;ldquo;hard&amp;rdquo;. Knowing how to determine whether a problem is easy or hard is extremely useful. If one can identify a hard problem, then an approximate solution may be the best that can be achieved.&lt;/p&gt;</description>
    </item>
    <item>
      <title>All-Pairs Shortest Paths</title>
      <link>https://ajdillhoff.github.io/notes/all_pairs_shortest_paths/</link>
      <pubDate>Sat, 20 Apr 2024 11:32:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/all_pairs_shortest_paths/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#problem-representation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Problem Representation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#a-naive-solution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;A Naive Solution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-floyd-warshall-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Floyd-Warshall Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;TychoLink is a telecommunications company looking to optimize its network for the fastest and most efficient data transfer possible. The network consists of multiple routers, each connected by various types of links that differ in latency and bandwidth. The company wants to ensure that data packets can travel from any router to any other router in the network using the path that offers the best balance between low latency and high bandwidth. There are three objectives in total:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dynamic Parallelism</title>
      <link>https://ajdillhoff.github.io/notes/dynamic_parallelism/</link>
      <pubDate>Fri, 19 Apr 2024 16:52:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/dynamic_parallelism/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Dynamic Parallelism&lt;/strong&gt; is an extension to CUDA that enables kernels to directly call other kernels. Earlier versions of CUDA only allowed kernels to be launched from the host code. When we studied &lt;GPU Pattern: Parallel Scan&gt;, the segmented approach required multiple kernel calls.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NVIDIA Visual Profiler Quickstart Guide</title>
      <link>https://ajdillhoff.github.io/notes/visual_profiler_quick_guide/</link>
      <pubDate>Mon, 15 Apr 2024 20:14:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/visual_profiler_quick_guide/</guid>
      <description>&lt;h1 id=&#34;nvidia-visual-profiler-quickstart-guide&#34;&gt;NVIDIA Visual Profiler Quickstart Guide&lt;/h1&gt;&#xA;&lt;p&gt;NVIDIA Visual Profiler is installed on both the GPU machines and the workstations. The following guide will show you how to use the NVIDIA Visual Profiler to profile your CUDA code. For more details, please refer to the &lt;a href=&#34;https://docs.nvidia.com/cuda/profiler-users-guide/index.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using the cuDNN Library</title>
      <link>https://ajdillhoff.github.io/notes/using_the_cudnn_library/</link>
      <pubDate>Mon, 15 Apr 2024 20:14:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/using_the_cudnn_library/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-is-cudnn&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What is cuDNN?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#setting-up-cudnn&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Setting up cuDNN&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#handling-errors&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Handling Errors&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#representing-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Representing Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dense-layers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dense Layers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#activation-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Activation Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#loss-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Loss Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#convolutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Convolutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#pooling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Pooling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;what-is-cudnn&#34;&gt;What is cuDNN?&lt;/h2&gt;&#xA;&lt;p&gt;NVIDIA cuDNN provides optimized implementations of core operations used in deep learning. It is designed to be integrated into higher-level machine learning frameworks, such as TensorFlow, PyTorch, and Caffe.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Maximum Flow</title>
      <link>https://ajdillhoff.github.io/notes/maximum_flow/</link>
      <pubDate>Fri, 12 Apr 2024 18:51:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/maximum_flow/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#objective-questions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Objective Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#maximum-flow&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Maximum Flow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#a-polynomial-time-solution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;A polynomial time solution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;A flow network is a directed graph in which the edges begin at a node that produces the flow and the adjacent nodes are the ones that receive it. &lt;em&gt;Flow&lt;/em&gt; in this context could take on many meanings, such as the amount of water that can flow through a pipe, the amount of data that can be sent through a network, or the amount of traffic that can be sent through a road network. The goal of a flow network is to maximize the flow from the source to the sink.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Language of LLMs</title>
      <link>https://ajdillhoff.github.io/blog/the-language-of-llms/</link>
      <pubDate>Thu, 11 Apr 2024 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/blog/the-language-of-llms/</guid>
      <description>How do LLMs read and process the high dimensional landscape of text efficiently? Presented as a workshop at UTA&amp;rsquo;s Datathon on April 13, 2024.</description>
    </item>
    <item>
      <title>Parallel Graph Traversal</title>
      <link>https://ajdillhoff.github.io/notes/parallel_graph_traversal/</link>
      <pubDate>Sat, 06 Apr 2024 15:26:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/parallel_graph_traversal/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#parallelization-over-vertices&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Parallelization over vertices&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#parallelization-over-edges&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Parallelization over edges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#improving-work-efficiency&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Improving work efficiency&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#privatization-to-reduce-contention&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Privatization to reduce contention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#additional-optimizations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Additional Optimizations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;For an introduction on basic graph theory and traversal algorithms, see &lt;a href=&#34;https://ajdillhoff.github.io/notes/introduction_to_graph_theory/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;these notes.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Topological Sort</title>
      <link>https://ajdillhoff.github.io/notes/topological_sort/</link>
      <pubDate>Thu, 04 Apr 2024 10:21:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/topological_sort/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#topological-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Topological Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#strongly-connected-components&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Strongly Connected Components&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#application-recommender-graphs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Application: Recommender Graphs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;topological-sort&#34;&gt;Topological Sort&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;topological sort&lt;/strong&gt; of a directed acyclic graph \(G = (V, E)\) is a linear ordering of all its vertices such that for every directed edge \((u, v) \in E\), vertex \(u\) comes before vertex \(v\) in the ordering.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Parallel Sorting Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/parallel_sorting_algorithms/</link>
      <pubDate>Sun, 31 Mar 2024 10:50:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/parallel_sorting_algorithms/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#radix-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Radix Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#optimizing-memory-access-efficiency&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Optimizing Memory Access Efficiency&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#choosing-a-different-radix-value&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Choosing a different Radix value&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;radix-sort&#34;&gt;Radix Sort&lt;/h2&gt;&#xA;&lt;p&gt;For a background on Radix Sort, see these notes on &lt;a href=&#34;https://ajdillhoff.github.io/notes/sorting_in_linear_time/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Sorting in Linear Time&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sparse Matrix Computation</title>
      <link>https://ajdillhoff.github.io/notes/sparse_matrix_computation/</link>
      <pubDate>Sat, 30 Mar 2024 10:36:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/sparse_matrix_computation/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#coordinate-list-format--coo&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Coordinate List Format (COO)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#compressed-sparse-row-format--csr&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Compressed Sparse Row Format (CSR)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#ell-format&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;ELL Format&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#ell-coo-format&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;ELL-COO Format&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#jagged-diagonal-storage-format--jds&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Jagged Diagonal Storage Format (JDS)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Sparse matrices are matrices with mostly zero elements. They are common in scientific computing, machine learning, and other fields. It is important to study them in the context of GPU computing because they can be very large and require a lot of memory. Effeciently representing and computing with sparse matrices provides a substantial benefit to many applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Recursion Tree Method</title>
      <link>https://ajdillhoff.github.io/notes/recursion_tree_method/</link>
      <pubDate>Mon, 18 Mar 2024 22:10:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/recursion_tree_method/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-4-dot-13-from-clrs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example 4.13 from CLRS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Visualizing the characteristics of an algorithm is a great way to build intuition about its runtime. Although it can be used to prove a recurrence, it is often a good jumping off point for the &lt;a href=&#34;https://ajdillhoff.github.io/notes/substitution_method/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Substitution Method&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Greedy Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/greedy_algorithms/</link>
      <pubDate>Mon, 18 Mar 2024 14:45:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/greedy_algorithms/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#activity-selection&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Activity Selection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#properties-of-greedy-solutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Properties of Greedy Solutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#huffman-codes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Huffman Codes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Greedy algorithms are a class of algorithms that yield &lt;em&gt;locally&lt;/em&gt; optimal solutions. In cases where the local optimum is also the global optimum, greedy algorithms are ideal. Even in cases where the global solution is more elusive, a local solution may be sufficient.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hash Tables</title>
      <link>https://ajdillhoff.github.io/notes/hash_tables/</link>
      <pubDate>Thu, 14 Mar 2024 15:16:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/hash_tables/</guid>
      <description>&lt;p&gt;See &lt;a href=&#34;https://ajdillhoff.github.io/teaching/dasc5300/lectures/hash_maps.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;these slides&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dynamic Programming</title>
      <link>https://ajdillhoff.github.io/notes/dynamic_programming/</link>
      <pubDate>Thu, 14 Mar 2024 10:40:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/dynamic_programming/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rod-cutting&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rod Cutting&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#matrix-chain-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Matrix-chain Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#applying-dynamic-programming&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Applying Dynamic Programming&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#longest-common-subsequence&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Longest Common Subsequence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Dynamic programming is a technique for solving problems by breaking them down into simpler subproblems, very much like divide and conquer algorithms. One primary difference is that the subproblems are designed in such a way that they do not need to be recomputed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Medians and Order Statistics</title>
      <link>https://ajdillhoff.github.io/notes/medians_and_order_statistics/</link>
      <pubDate>Tue, 12 Mar 2024 13:17:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/medians_and_order_statistics/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#order-statistics&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Order Statistics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#minimum-and-maximum&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Minimum and Maximum&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#selection-in-expected-linear-time&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Selection in expected linear time&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#problems-and-exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Problems and Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;We briefly touched on a median finding algorithm when discussing &lt;a href=&#34;https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Divide and Conquer Algorithms&lt;/a&gt;. This section will be a bit of a review, but the point is to touch on the topic of order statistics more generally.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sorting in Linear Time</title>
      <link>https://ajdillhoff.github.io/notes/sorting_in_linear_time/</link>
      <pubDate>Mon, 11 Mar 2024 17:10:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/sorting_in_linear_time/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#establishing-a-lower-bound-on-comparison-sorts&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Establishing a Lower Bound on Comparison Sorts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#counting-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Counting Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#radix-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Radix Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bucket-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bucket Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#questions-and-exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Questions and Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These are my personal notes for Chapter 8 of &lt;em&gt;Introduction to Algorithms&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cormen et al. 2022&lt;/a&gt;). Readers should reference the book for more details when necessary.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Pattern: Merge</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_merge/</link>
      <pubDate>Wed, 28 Feb 2024 19:19:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_merge/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#key-concepts-and-challenges&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Key Concepts and Challenges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-merge-operation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Merge Operation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tiled-merge&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tiled Merge&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#circular-buffers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Circular Buffers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#thread-coarsening&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Thread Coarsening&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;key-concepts-and-challenges&#34;&gt;Key Concepts and Challenges&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Dynamic input data identification&lt;/li&gt;&#xA;&lt;li&gt;Data locality&lt;/li&gt;&#xA;&lt;li&gt;Buffer management schemes&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The &lt;strong&gt;merge&lt;/strong&gt; operation takes two sorted subarrays and combines them into a single sorted array. You may be familiar with this approach from studying &lt;a href=&#34;https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Divide and Conquer Algorithms&lt;/a&gt;. Parallelizing the merge operation is a non-trivial task and will require the use of a few new techniques.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Substitution Method</title>
      <link>https://ajdillhoff.github.io/notes/substitution_method/</link>
      <pubDate>Tue, 27 Feb 2024 19:12:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/substitution_method/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-from-clrs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example from CLRS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#making-the-wrong-guess&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Making the Wrong Guess&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;The &lt;strong&gt;substitution method&lt;/strong&gt; is a technique for solving recurrences. It works in two steps:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Quicksort</title>
      <link>https://ajdillhoff.github.io/notes/quicksort/</link>
      <pubDate>Sun, 25 Feb 2024 17:24:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/quicksort/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#basic-quicksort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Basic Quicksort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#performance&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Performance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#randomized-quicksort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Randomized Quicksort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#paranoid-quicksort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Paranoid Quicksort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Quicksort is a popular sorting algorithm implemented in many language libraries that has a worst-case running time of \(\Theta(n^2)\). &lt;strong&gt;Why would anyone choose this as the default sorting algorithm if one like mergesort has better worst-case performance?&lt;/strong&gt; As you will see, the devil is in the details. Quicksort is often faster in practice. It also has a small memory footprint and is easy to implement.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Priority Queues</title>
      <link>https://ajdillhoff.github.io/notes/priority_queues/</link>
      <pubDate>Sat, 24 Feb 2024 14:10:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/priority_queues/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#quick-facts&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Quick Facts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#implementation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Implementation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;quick-facts&#34;&gt;Quick Facts&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Time Complexity&lt;/strong&gt;&lt;/strong&gt;: \(O(\lg n)\)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Space Complexity&lt;/strong&gt;&lt;/strong&gt;: \(O(n)\)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Besides being the primary data structure for &lt;a href=&#34;https://ajdillhoff.github.io/notes/heapsort/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Heapsort&lt;/a&gt;, a heap is also used to implement a priority queue. A priority queue is a key-value data structure in which the keys are used to determine the priority of each element in the queue. There are two variants, maximum and minimum, and they support the following operations:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Heapsort</title>
      <link>https://ajdillhoff.github.io/notes/heapsort/</link>
      <pubDate>Wed, 21 Feb 2024 14:58:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/heapsort/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#maintaining-the-heap-property&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Maintaining the Heap Property&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#building-the-heap&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Building the Heap&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#heapsort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Heapsort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Running time is \(O(n \lg n)\).&lt;/li&gt;&#xA;&lt;li&gt;Sorts in place, only a constant number of elements needed in addition to the input.&lt;/li&gt;&#xA;&lt;li&gt;Manages data with a &lt;strong&gt;heap&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;A &lt;strong&gt;binary heap&lt;/strong&gt; can be represented as a binary tree, but is stored as an array. The root is the first element of the array. The left subnode for the element at index \(i\) is located at \(2i\) and the right subnode is located at \(2i + 1\). &lt;strong&gt;This assumes a 1-based indexing&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Pattern: Parallel Scan</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_parallel_scan/</link>
      <pubDate>Wed, 14 Feb 2024 20:09:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_parallel_scan/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-is-it&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What is it?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#naive-parallel-reduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Naive Parallel Reduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#kogge-stone-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Kogge-Stone Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#brent-kung-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Brent-Kung Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#adding-coarsening&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Adding Coarsening&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#segmented-parallel-scan&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Segmented Parallel Scan&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#optimizing-memory-efficiency&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Optimizing Memory Efficiency&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;what-is-it&#34;&gt;What is it?&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Parallelizes sequential problems.&lt;/li&gt;&#xA;&lt;li&gt;Works with computations that can be described in terms of a recursion.&lt;/li&gt;&#xA;&lt;li&gt;Used as a primitive operation for sorting, tree operations, and recurrences.&lt;/li&gt;&#xA;&lt;li&gt;Studying this will also reveal how parallelization can increase the complexity beyond that of a traditional sequential approach.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;example-inclusive-scan&#34;&gt;Example: Inclusive Scan&lt;/h3&gt;&#xA;&lt;p&gt;Given an array of numbers, the inclusive scan computes the sum of all elements up to a given index. For example, given the array [1, 2, 3, 4, 5], the inclusive scan would produce [1, 3, 6, 10, 15]. You could solve this recursively, but it would be horribly inefficient. A sequential solution is achievable with dynamic programming. However, a parallel solution is much more efficient.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Pattern: Reduction</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_reduction/</link>
      <pubDate>Mon, 05 Feb 2024 15:47:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_reduction/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#reduction-trees&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Reduction Trees&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#a-simple-kernel&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;A Simple Kernel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#minimizing-control-divergence&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Minimizing Control Divergence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-divergence-of-reduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Divergence of Reduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#reducing-the-number-of-global-memory-requests&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Reducing the number of global memory requests&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#hierarchical-reduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Hierarchical Reduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#thread-coarsening-back-again&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Thread Coarsening - Back Again&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;The following notes follow Chapter 10 of &lt;em&gt;Programming Massively Parallel Processors&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bag of Visual Words</title>
      <link>https://ajdillhoff.github.io/notes/bag_of_visual_words/</link>
      <pubDate>Sun, 04 Feb 2024 18:54:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/bag_of_visual_words/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bag-of-visual-words&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bag of Visual Words&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;&lt;strong&gt;Bag of Words&lt;/strong&gt; is a technique used in Natural Language Processing for document classification. It is a collection of word counts. To create a Bag of Words for a document, it necessary to create a dictionary first. Choosing the a dictionary is based on many factors including computational limitations. Next, the documents in a dataset are tokenized into words. The word counts are collected as part of a histogram and used as a feature vector for a machine learning model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Master Theorem</title>
      <link>https://ajdillhoff.github.io/notes/master_theorem/</link>
      <pubDate>Sun, 04 Feb 2024 17:49:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/master_theorem/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-merge-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Merge Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-matrix-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-median-finding&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Median Finding&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-cormen-et-al-dot-exercise-4-dot-5-2&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Cormen et al. Exercise 4.5-2&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;In the study of &lt;a href=&#34;https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Divide and Conquer Algorithms&lt;/a&gt;, a recurrence tree can be used to determine the runtime complexity. These notes focus on the &lt;strong&gt;master theorem&lt;/strong&gt;, a blueprint for solving any recurrence of the form&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Pattern: Parallel Histogram</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_parallel_histogram/</link>
      <pubDate>Mon, 29 Jan 2024 17:22:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_parallel_histogram/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#histograms&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Histograms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#latency-of-atomic-operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Latency of Atomic Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#privatization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Privatization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#coarsening&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Coarsening&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#aggregation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Aggregation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These notes follow the presentation of the parallel histogram pattern in the book &lt;strong&gt;Programming Massively Parallel Processors: A Hands-on Approach&lt;/strong&gt; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Divide and Conquer Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/</link>
      <pubDate>Tue, 23 Jan 2024 08:38:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/divide_and_conquer_algorithms/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#solving-recurrences&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Solving Recurrences&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-merge-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Merge Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-multiplying-square-matrices&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Multiplying Square Matrices&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-convex-hull&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Convex Hull&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-median-search&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Median Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;&#xA;&lt;p&gt;Divide and conquer algorithms are a class of algorithms that solve a problem by breaking it into smaller subproblems, solving the subproblems recursively, and then combining the solutions to the subproblems to form a solution to the original problem. Problems that can be solved in this manner are typically highly parallelizable. These notes investigate a few examples of classic divide and conquer algorithms and their analysis.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Pattern: Stencils</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_stencils/</link>
      <pubDate>Mon, 22 Jan 2024 19:39:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_stencils/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#differential-equations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Differential Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#stencils&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Stencils&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-basic-stencil&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Basic Stencil&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tiled-stencil&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tiled Stencil&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#thread-coarsening&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Thread Coarsening&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#register-tiling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Register Tiling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#questions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;differential-equations&#34;&gt;Differential Equations&lt;/h2&gt;&#xA;&lt;p&gt;Any computational problem requires discretization of data or equations so that they can be solved numerically. This is fundamental in numerical analysis, where differential equations need to be approximated.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Pattern: Convolution</title>
      <link>https://ajdillhoff.github.io/notes/gpu_pattern_convolution/</link>
      <pubDate>Mon, 15 Jan 2024 21:35:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_pattern_convolution/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#convolution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Convolution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#properties-of-convolutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Properties of Convolutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#implementing-a-convolution-kernel&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Implementing a Convolution Kernel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#constant-memory-and-caching&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Constant Memory and Caching&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tiled-convolutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tiled Convolutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#caching-the-halo-cells&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Caching the Halo Cells&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;This pattern involves tiling and input data staging.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Profiling CUDA Applications</title>
      <link>https://ajdillhoff.github.io/notes/profiling_cuda_applications/</link>
      <pubDate>Mon, 15 Jan 2024 14:48:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/profiling_cuda_applications/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#overview-of-nsight&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Overview of Nsight&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#getting-started-with-nsight&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Getting Started with Nsight&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#case-study-matrix-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Case Study: Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tips-and-best-practices&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tips and Best Practices&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#ocl-notes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;OCL Notes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;overview-of-nsight&#34;&gt;Overview of Nsight&lt;/h2&gt;&#xA;&lt;p&gt;NVIDIA NSight Compute is a profiling tool for CUDA kernels. It features an expert system that can help you identify performance bottlenecks in your code. It is essential for methodically optimizing your code. These notes will cover the basics of using Nsight Compute to profile your CUDA applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU Performance Basics</title>
      <link>https://ajdillhoff.github.io/notes/gpu_performance_basics/</link>
      <pubDate>Sun, 14 Jan 2024 13:31:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gpu_performance_basics/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-coalescing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Coalescing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#hiding-memory-latency&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Hiding Memory Latency&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#thread-coarsening&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Thread Coarsening&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#optimization-checklist&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Optimization Checklist&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#identifying-bottlenecks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Identifying Bottlenecks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These notes are on &amp;ldquo;Chapter 6: Performance Considerations&amp;rdquo; from the book &lt;em&gt;Programming Massively Parallel Processors&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Hwu, Kirk, and El Hajj 2022&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>CUDA Memory Architecture</title>
      <link>https://ajdillhoff.github.io/notes/cuda_memory_architecture/</link>
      <pubDate>Thu, 11 Jan 2024 15:07:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/cuda_memory_architecture/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-access&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Access&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-types&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Types&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tiling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tiling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-tiled-matrix-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Tiled Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#boundary-checking&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Boundary Checking&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#memory-use-and-occupancy&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Memory Use and Occupancy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dynamically-changing-the-block-size&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dynamically Changing the Block Size&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;So far, the kernels we have used assume everything is on global memory. Even though there are thousands of cores that can effectively hide the latency of transferring data to and from global memory, we will see this delay will become a bottleneck in many applications. These notes explore the different types of memory available on the GPU and how to use them effectively.&lt;/p&gt;</description>
    </item>
    <item>
      <title>CUDA Architecture</title>
      <link>https://ajdillhoff.github.io/notes/cuda_architecture/</link>
      <pubDate>Mon, 08 Jan 2024 20:49:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/cuda_architecture/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#architecture&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#block-scheduling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Block Scheduling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#synchronization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Synchronization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#warps&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Warps&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#control-divergence&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Control Divergence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#warp-scheduling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Warp Scheduling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resource-partitioning&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resource Partitioning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dynamic-launch-configurations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dynamic Launch Configurations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-takeaway&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Takeaway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;&#xA;&lt;p&gt;A GPU consists of chip that is composed of several &lt;strong&gt;streaming multiprocessors&lt;/strong&gt; (SMs). Each SM has a number of cores that execute instructions in parallel. The H100, seen below, has 144 SMs (you can actually count them by eye). Each SM has 128 FP32 cores for a total of 18,432 cores. Historically, CUDA has used DDR memory, but newer architectures use high-bandwidth memory (HBM). This is closely integrated with the GPU for faster data transfer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multidimensional Grids and Data</title>
      <link>https://ajdillhoff.github.io/notes/multidimensional_grids_and_data/</link>
      <pubDate>Fri, 05 Jan 2024 11:56:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/multidimensional_grids_and_data/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multidimensional-grid-organization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multidimensional Grid Organization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-color-to-grayscale&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Color to Grayscale&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#no-longer-embarrassing-overlapping-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;No longer embarrassing: overlapping data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#matrix-multiplication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Matrix Multiplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-s-next&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What&amp;rsquo;s Next?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;The CUDA Programming model allows us to organize our data in a multidimensional grid. The purpose of this is primarily for our own convenience, but it also allows us to take advantage of the GPU&amp;rsquo;s memory hierarchy. In Lab 0, we only required a single dimension for our grid as well as each block since the input was a vector. When performing computations on multidimensional data like matrices, we can match the dimensions of our launch configuration to the dimensions of our data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Heterogeneous Data Parallel Computing</title>
      <link>https://ajdillhoff.github.io/notes/heterogeneous_data_parallel_computing/</link>
      <pubDate>Sat, 30 Dec 2023 14:41:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/heterogeneous_data_parallel_computing/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cuda-c-programs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;CUDA C Programs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-vector-addition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Vector Addition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#error-checking&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Error Checking&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;  &#xA;&#xA;  &#xA;  &#xA;&#xA;&#xA;&#xA;&#xA;&#xA;  &#xA;&#xA;&#xA;&lt;div class=&#34;notice info&#34;&gt;&#xA;  &lt;div class=&#34;notice-head&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; fill=&#34;none&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;1.5&#34; stroke=&#34;currentColor&#34; width=&#34;22&#34; height=&#34;22&#34;&gt;&#xA;        &lt;path stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; d=&#34;m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z&#34; /&gt;&#xA;      &lt;/svg&gt;&lt;p&gt;Terms &amp;amp; Concepts&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to GPGPU Programming</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_gpgpu_programming/</link>
      <pubDate>Wed, 20 Dec 2023 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_gpgpu_programming/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#structure-of-the-course&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Structure of the Course&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#heterogeneous-parallel-computing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Heterogeneous Parallel Computing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#measuring-speedup&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Measuring Speedup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gpu-programming-history&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;GPU Programming History&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#applications&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Applications&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-to-expect-from-this-course&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What to expect from this course&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;structure-of-the-course&#34;&gt;Structure of the Course&lt;/h2&gt;&#xA;&lt;p&gt;The primary of this goal is of course to learn how to program GPUs. A key skill that will be developed is the ability to think in parallel. We will start with simple problems that are &lt;em&gt;embarrassingly parallel&lt;/em&gt; and then move on to more complex problems that require synchronization. One of the biggest challenges will be in converting processes that are simple to reason about in serial to parallel processes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MapReduce</title>
      <link>https://ajdillhoff.github.io/notes/mapreduce/</link>
      <pubDate>Fri, 24 Nov 2023 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/mapreduce/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-is-mapreduce&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What is MapReduce?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#hadoop-distributed-file-system--hdfs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Hadoop Distributed File System (HDFS)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mapreduce-overview&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;MapReduce Overview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#hadoop-v2-aka-yarn&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Hadoop v2 AKA YARN&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These are my personal notes from the book &lt;em&gt;Fundamentals of Database Systems&lt;/em&gt; by (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;). I highly recommend reading the original source material. The contents of the article should only serve as a brief overview of the topic.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pretraining Large Language Models</title>
      <link>https://ajdillhoff.github.io/notes/pretraining_large_language_models/</link>
      <pubDate>Thu, 16 Nov 2023 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/pretraining_large_language_models/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#unsupervised-pre-training&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Unsupervised Pre-training&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#from-gpt-to-gpt2&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;From GPT to GPT2&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bert&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;BERT&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bart&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;BART&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gpt3&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;GPT3&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These notes provide an overview of pre-training large language models like GPT and Llama.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Distributed Databases</title>
      <link>https://ajdillhoff.github.io/notes/distributed_databases/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/distributed_databases/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#overview&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Overview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#data-fragmentation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Data Fragmentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#data-replication&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Data Replication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#data-concurrency&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Data Concurrency&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Distributed systems excel at partitioning large problems into smaller chunks that can be processed in parallel. This requires parallel thinking instead of serial thinking. Many algorithms and solutions that run serially may be easier to adapt to parallel applications than others.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NOSQL</title>
      <link>https://ajdillhoff.github.io/notes/nosql/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/nosql/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#nosql-characteristics-for-distributed-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;NOSQL Characteristics for Distributed Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#nosql-data-models&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;NOSQL Data Models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cap-theorem&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;CAP Theorem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#document-based-nosql-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Document-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#key-value-nosql-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Key-Value NOSQL Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#column-based-nosql-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Column-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#graph-based-nosql-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Graph-Based NOSQL Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;&lt;strong&gt;NOSQL&lt;/strong&gt; refers to Not Only SQL. A NOSQL system is commonly a distributed one that focuses on semi-structured data storage, high performance, availability, replication and scalability. These type of systems developed to meet the needs of large-scale internet applications where a traditional SQL database could not.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Structured Query Language</title>
      <link>https://ajdillhoff.github.io/notes/structured_query_language/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/structured_query_language/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#history-and-development&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;History and Development&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#schemas&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Schemas&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#data-types&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Data Types&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#creation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Creation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#constraints&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#retrieving-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Retrieving Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#modifying-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Modifying Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#nested-queries&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Nested Queries&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#joined-tables&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Joined Tables&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#aggregate-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Aggregate Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#grouping&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Grouping&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#with-clause&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;&lt;code&gt;WITH&lt;/code&gt; Clause&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#modifying-tables&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Modifying Tables&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;history-and-development&#34;&gt;History and Development&lt;/h2&gt;&#xA;&lt;p&gt;Structured Query Language (SQL) is a database language for managing data in a relation DBMS. Its original inception was based on a paper by Edgar F. Codd in 1970 titled &lt;em&gt;A Relational Model of Data for Large Shared Data Banks&lt;/em&gt; (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Codd 1970&lt;/a&gt;). Two employees working at IBM in the 1970s, Donald D. Chamberlin and Raymond F. Boyce, developed the first version of SQL in 1974 (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Chamberlin and Boyce 1974&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Databases</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_databases/</link>
      <pubDate>Sat, 28 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_databases/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#an-online-rpg-database&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;An Online RPG Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#from-schema-to-database&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;From Schema to Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#database-management-systems&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Database Management Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#creating-our-rpg-database&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Creating our RPG Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;&lt;strong&gt;Recommended Reading: Chapters 1 and 2 from (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Elmasri and Navathe 2015&lt;/a&gt;)&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Minimum Spanning Trees</title>
      <link>https://ajdillhoff.github.io/notes/minimum_spanning_trees/</link>
      <pubDate>Sat, 21 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/minimum_spanning_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#finding-the-minimum-spanning-tree&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Finding the Minimum Spanning Tree&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#kruskal-s-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Kruskal&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#prim-s-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Prim&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Minimum spanning trees are undirected graphs that connect all of the vertices such that there are no redundant edges and the total weight is minimized. They are useful for finding the shortest path between two points in a graph. Useful application of MSTs include&lt;/p&gt;</description>
    </item>
    <item>
      <title>Single-Source Shortest Paths</title>
      <link>https://ajdillhoff.github.io/notes/single_source_shortest_paths/</link>
      <pubDate>Sat, 21 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/single_source_shortest_paths/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bellman-ford&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bellman-Ford&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#shortest-paths-on-a-dag&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Shortest Paths on a DAG&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dijkstra-s-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dijkstra&amp;rsquo;s Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;When you hear the term &lt;em&gt;shortest path&lt;/em&gt;, you may think of the shortest physical distance between your current location and wherever it is you&amp;rsquo;re going. Finding the most optimal route via GPS is one of the most widely used mobile applications. Physical paths are not the only types we may wish to find a shortest path for. Other examples include:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Graph Theory</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_graph_theory/</link>
      <pubDate>Tue, 17 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_graph_theory/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-are-graphs&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What are Graphs?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#graph-traversal-algorithms&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Graph Traversal Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#breadth-first-search&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Breadth First Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#depth-first-search&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Depth First Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;what-are-graphs&#34;&gt;What are Graphs?&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;graph&lt;/strong&gt; is a data structure that is used to represent pairwise relationships between objects. Graphs are used in many applications, such as social networks, maps, and routing algorithms. These notes accompany the series of lectures on graphs for my &lt;em&gt;Foundations of Computing&lt;/em&gt; course at the University of Texas - Arlington.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Red-Black Trees</title>
      <link>https://ajdillhoff.github.io/notes/red_black_trees/</link>
      <pubDate>Sun, 15 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/red_black_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Red-Black Trees are modified &lt;a href=&#34;https://ajdillhoff.github.io/notes/binary_search_trees/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Binary Search Trees&lt;/a&gt; that maintain a balanced structure in order to guarantee that operations like search, insert, and delete run in \(O(\log n)\) time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Binary Search Trees</title>
      <link>https://ajdillhoff.github.io/notes/binary_search_trees/</link>
      <pubDate>Tue, 10 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/binary_search_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#binary-search-trees&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Binary Search Trees&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;A $n$-ary tree is a graph-based data structure in which each node has up to \(n\) subnodes. It is supported by the following operations (not exclusive):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Data Structures</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_data_structures/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_data_structures/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction-to-data-structures&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction to Data Structures&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#review-pointers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Review: Pointers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#arrays&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Arrays&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#matrices&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Matrices&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multi-dimensional-arrays&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multi-Dimensional Arrays&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#stacks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Stacks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#queues&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Queues&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction-to-data-structures&#34;&gt;Introduction to Data Structures&lt;/h2&gt;&#xA;&lt;p&gt;Data structures are fundamental concepts in computer science that allow us to organize and store data in a way that enables efficient access and modification. They are essential building blocks for creating efficient and sophisticated computer programs and databases. Different types of data structures include arrays, linked lists, stacks, queues, trees, graphs, and many more, each serving a specific purpose and suited to specific applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linked Lists</title>
      <link>https://ajdillhoff.github.io/notes/linked_lists/</link>
      <pubDate>Sun, 01 Oct 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/linked_lists/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#singly-linked-lists&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Singly-Linked Lists&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#doubly-linked-lists&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Doubly-Linked Lists&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#operations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#exercises&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;A linked list is a &lt;strong&gt;dynamic&lt;/strong&gt; and &lt;strong&gt;aggregate&lt;/strong&gt; data structure made up of a collection of nodes. The nodes of a linked list can store any data type and are not enforced to contain the same data type. A basic &lt;code&gt;node&lt;/code&gt; structure may be defined as&lt;/p&gt;</description>
    </item>
    <item>
      <title>Complexity Analysis</title>
      <link>https://ajdillhoff.github.io/notes/complexity_analysis/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/complexity_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-notation-of-complexity-analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The notation of complexity analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#formal-definition-of-asymptotic-notation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Formal Definition of Asymptotic Notation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#common-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Common Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;the-notation-of-complexity-analysis&#34;&gt;The notation of complexity analysis&lt;/h2&gt;&#xA;&lt;h3 id=&#34;o-notation&#34;&gt;$O$-notation&lt;/h3&gt;&#xA;&lt;p&gt;$O$-notation, often referred to as &amp;ldquo;Big Oh&amp;rdquo; notation, describes an upper bound on the behavior of a function. It really means that the function &lt;em&gt;will not grow faster&lt;/em&gt; than the a given rate. This rate is typically the highest-order term in the function, and is often referred to as the &amp;ldquo;dominant term&amp;rdquo; or &amp;ldquo;dominant function&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Algorithms</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_complexity_analysis/</link>
      <pubDate>Tue, 19 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_complexity_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction-to-algorithms&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction to Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#insertion-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Insertion Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-sorting-numbers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Sorting Numbers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#correctness&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Correctness&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#worst-case-analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Worst-Case Analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#best-case-analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Best-Case Analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rate-of-growth&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rate of Growth&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-analysis-of-selection-sort&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Analysis of Selection Sort&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction-to-algorithms&#34;&gt;Introduction to Algorithms&lt;/h2&gt;&#xA;&lt;p&gt;One of the major goals of computer science is to solve important problems. In order to do that, we must be able to express those solutions both mathematically and in a way that can be executed by a computer. Further, those solutions need to be aware of the resources that are available to them. It does us no good to come up with a solution that could never be run by current hardware or executed in a reasonable amount of time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Review Questions</title>
      <link>https://ajdillhoff.github.io/notes/python_exam_review/</link>
      <pubDate>Tue, 12 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/python_exam_review/</guid>
      <description>&lt;h1 id=&#34;python-review-questions&#34;&gt;Python Review Questions&lt;/h1&gt;&#xA;&lt;p&gt;The following questions are meant to help you review introductory concepts in Python. They are based on the &lt;a href=&#34;https://docs.python.org/3/tutorial/index.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python 3 Tutorial&lt;/a&gt; and &lt;a href=&#34;https://docs.python.org/3/index.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;Python 3 Documentation&lt;/a&gt; and were written to accompany a 5 lecture series on Python.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NumPy: Basics</title>
      <link>https://ajdillhoff.github.io/notes/numpy_basics/</link>
      <pubDate>Sun, 10 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/numpy_basics/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/numpy_quickstart/basics.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;&lt;h1 id=&#34;numpy-quickstart&#34;&gt;&lt;code&gt;NumPy&lt;/code&gt; Quickstart&lt;/h1&gt;&#xA;&lt;p&gt;This notebook is a quick introduction to &lt;code&gt;NumPy&lt;/code&gt;. It is an interactive version of the &lt;a href=&#34;https://docs.scipy.org/doc/numpy/user/quickstart.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;NumPy Quickstart Tutorial&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NumPy: Copies and Views</title>
      <link>https://ajdillhoff.github.io/notes/numpy_copies_and_views/</link>
      <pubDate>Sun, 10 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/numpy_copies_and_views/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/numpy_quickstart/copies_and_views.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;&lt;h1 id=&#34;numpy-quickstart&#34;&gt;&lt;code&gt;NumPy&lt;/code&gt; Quickstart&lt;/h1&gt;&#xA;&lt;p&gt;This notebook is a quick introduction to &lt;code&gt;NumPy&lt;/code&gt;. It is an interactive version of the &lt;a href=&#34;https://docs.scipy.org/doc/numpy/user/quickstart.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;NumPy Quickstart Tutorial&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NumPy: Shape Manipulation</title>
      <link>https://ajdillhoff.github.io/notes/numpy_shape_manipulation/</link>
      <pubDate>Sun, 10 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/numpy_shape_manipulation/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/numpy_quickstart/shape_manipulation.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;# `NumPy` Quickstart&#xA;&lt;p&gt;This notebook is a quick introduction to &lt;code&gt;NumPy&lt;/code&gt;. It is an interactive version of the &lt;a href=&#34;https://docs.scipy.org/doc/numpy/user/quickstart.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;NumPy Quickstart Tutorial&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Example: Writing a Data Loader in Python</title>
      <link>https://ajdillhoff.github.io/notes/dataloader/</link>
      <pubDate>Mon, 04 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/dataloader/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/examples/dataloader.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;&lt;h1 id=&#34;loading-data-for-ml-applications&#34;&gt;Loading Data for ML Applications&lt;/h1&gt;&#xA;&lt;p&gt;In this notebook, we will implement code to load data for ML applications. Following the approach used by &lt;code&gt;PyTorch&lt;/code&gt;, we will implement a &lt;code&gt;Dataset&lt;/code&gt; class and a &lt;code&gt;DataLoader&lt;/code&gt; class. The &lt;code&gt;Dataset&lt;/code&gt; class will be used to load the data and the &lt;code&gt;DataLoader&lt;/code&gt; class will be used to iterate over the data in batches.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Object-Oriented Programming with Python</title>
      <link>https://ajdillhoff.github.io/notes/oop/</link>
      <pubDate>Mon, 04 Sep 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/oop/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/basics/oop.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;&lt;h1 id=&#34;classes&#34;&gt;Classes&lt;/h1&gt;&#xA;&lt;p&gt;When a class is defined, a namespace is created for it. All assignments to local variables are part of this namespace. The code below defines a class, creates an instance of the class, and calls a method on the instance.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python File I/O</title>
      <link>https://ajdillhoff.github.io/notes/file_io/</link>
      <pubDate>Wed, 30 Aug 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/file_io/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/basics/file_io.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;&lt;h1 id=&#34;file-io-in-python&#34;&gt;File I/O in Python&lt;/h1&gt;&#xA;&lt;p&gt;This notebook will cover the following topics:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Functions</title>
      <link>https://ajdillhoff.github.io/notes/functions/</link>
      <pubDate>Wed, 30 Aug 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/functions/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/basics/functions.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;&lt;h1 id=&#34;functions&#34;&gt;Functions&lt;/h1&gt;&#xA;&lt;p&gt;We learned the importance of functions early on in mathematics. It is a compact way of represented a complex process dependent on a set of variables. In programming, functions are used to encapsulate a set of instructions that are used repeatedly. Functions are also used to make code more readable and easier to debug.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Git</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_git/</link>
      <pubDate>Sat, 26 Aug 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_git/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-is-version-control&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What is Version Control?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-is-git&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What is Git?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-is-a-repository&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What is a Repository?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#configuring-git&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Configuring Git&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#creating-a-repository&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Creating a Repository&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#staging-files&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Staging Files&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#committing-changes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Committing Changes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#ignoring-files&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Ignoring Files&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#branching&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Branching&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#merging&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Merging&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#remotes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Remotes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cloning-an-existing-repository&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Cloning an Existing Repository&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;what-is-version-control&#34;&gt;What is Version Control?&lt;/h2&gt;&#xA;&lt;p&gt;Version control is a system that records changes to a file or set of files over time so that you can recall specific versions later. This is useful not just for team projects, for for individual projects as well.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python List Comprehensions</title>
      <link>https://ajdillhoff.github.io/notes/list_comprehensions/</link>
      <pubDate>Sat, 26 Aug 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/list_comprehensions/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/basics/list_comprehensions.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;&lt;h1 id=&#34;lists-and-list-comprehensions&#34;&gt;Lists and List Comprehensions&lt;/h1&gt;&#xA;&lt;p&gt;List comprehensions provide a concise way to create lists, and are often faster than using a for-loop. They are inspired by set-builder notation in mathematics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Control Flow in Python</title>
      <link>https://ajdillhoff.github.io/notes/control_flow_in_python/</link>
      <pubDate>Tue, 22 Aug 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/control_flow_in_python/</guid>
      <description>&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/ajdillhoff/python-examples/blob/main/basics/control_flow.ipynb&#34;&gt;&#xA;  &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;/&gt;&#xA;&lt;/a&gt;&#xA;&lt;h1 id=&#34;control-flow&#34;&gt;Control Flow&lt;/h1&gt;&#xA;&lt;p&gt;Control flow allows us to build programs that react to some pre-determined condition. For example, what happens when a user logs in with the correct credentials? What if they don&amp;rsquo;t give valid credentials?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Python</title>
      <link>https://ajdillhoff.github.io/notes/introduction_to_python/</link>
      <pubDate>Sun, 20 Aug 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/introduction_to_python/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#programming-with-python&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Programming with Python&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#variables-values-and-data-types&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Variables, Values, and Data Types&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#basic-operators&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Basic Operators&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#statements-and-expressions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Statements and Expressions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#basic-i-o&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Basic I/O&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#commenting-code&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Commenting Code&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;These notes are focused on introducing programming with Python for those without a technical background.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Markov Decision Processes</title>
      <link>https://ajdillhoff.github.io/notes/markov_decision_processes/</link>
      <pubDate>Mon, 24 Jul 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/markov_decision_processes/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#key-terms&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Key Terms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#defining-goals&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Defining Goals&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#policies-and-values&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Policies and Values&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bellman-equations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bellman Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#optimality&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Optimality&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#optimizing-the-policy&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Optimizing the Policy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;key-terms&#34;&gt;Key Terms&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;: The learner or decision maker.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Environment&lt;/strong&gt;: The world that the agent can interact with.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;State&lt;/strong&gt;: A representation of the agent and environment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action&lt;/strong&gt;: The agent can take an action in the environment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Reward&lt;/strong&gt;: Given to the agent based on actions taken.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Goal&lt;/strong&gt;: Maximize rewards earned over time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gradient Boosting</title>
      <link>https://ajdillhoff.github.io/notes/gradient_boosting/</link>
      <pubDate>Mon, 17 Jul 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/gradient_boosting/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#notes-from&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Notes from (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Friedman 2001&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;notes-from&#34;&gt;Notes from (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Friedman 2001&lt;/a&gt;)&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Many machine learning methods are parameterized functions that are optimized using some numerical optimization techniques, notably steepest-descent.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Hidden Markov Models for Gesture Recognition</title>
      <link>https://ajdillhoff.github.io/blog/introduction-to-hmms/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/blog/introduction-to-hmms/</guid>
      <description>Hidden Markov Models provide a way of modeling the dynamics of sequential information. They have been used for speech recognition, part-of-speech tagging, machine translation, handwriting recognition, and, as we will see in this article, gesture recognition.</description>
    </item>
    <item>
      <title>Reinforcement Learning</title>
      <link>https://ajdillhoff.github.io/notes/reinforcement_learning/</link>
      <pubDate>Wed, 12 Jul 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/reinforcement_learning/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#topics&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Topics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rl-vs-dot-mdp&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;RL vs. MDP&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#passive-rl&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Passive RL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;topics&#34;&gt;Topics&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is reinforcement learning?&lt;/li&gt;&#xA;&lt;li&gt;Examples&lt;/li&gt;&#xA;&lt;li&gt;Finite Markov Decision Processes&lt;/li&gt;&#xA;&lt;li&gt;Passive vs. Active Methods&lt;/li&gt;&#xA;&lt;li&gt;Adaptive Dynamic Programming&lt;/li&gt;&#xA;&lt;li&gt;Monte Carlo Methods&lt;/li&gt;&#xA;&lt;li&gt;Temporal-Different Learning&lt;/li&gt;&#xA;&lt;li&gt;Q-Learning&lt;/li&gt;&#xA;&lt;li&gt;Function Approximation&lt;/li&gt;&#xA;&lt;li&gt;Deep Q-Learning&lt;/li&gt;&#xA;&lt;li&gt;Policy and Value Iteration&lt;/li&gt;&#xA;&lt;li&gt;Case Studies&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;When placed in a new environment, we orient and learn about it by interacting with it.&#xA;When given a novel task, we may not be able to explicitly describe the task or even perform well at it, but we can learn a lot about it through trial and error.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bias and Variance</title>
      <link>https://ajdillhoff.github.io/notes/bias_and_variance/</link>
      <pubDate>Tue, 04 Jul 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/bias_and_variance/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#generalization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Generalization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bias&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bias&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#variance&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Variance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bias-variance-tradeoff&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bias-Variance Tradeoff&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;generalization&#34;&gt;Generalization&lt;/h2&gt;&#xA;&lt;p&gt;When fitting machine learning models to data, we want them to &lt;strong&gt;generalize&lt;/strong&gt; well to the distribution that we have sampled from. We can measure a model&amp;rsquo;s ability to generalize by evaluating it on previously unseen data that is sampled from the same distribution as the training set. However, we often do not know the true underlying distribution. So we must fit the models to empirical distributions derived from observed data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Natural Language Processing</title>
      <link>https://ajdillhoff.github.io/notes/natural_language_processing/</link>
      <pubDate>Sun, 23 Apr 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/natural_language_processing/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#text-preprocessing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Text Preprocessing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tasks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tasks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#models&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#perplexity&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Perplexity&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Text Preprocessing&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Character-level tokenization&lt;/li&gt;&#xA;&lt;li&gt;Word-level tokenization&lt;/li&gt;&#xA;&lt;li&gt;Subword tokenization&lt;/li&gt;&#xA;&lt;li&gt;Stopwords&lt;/li&gt;&#xA;&lt;li&gt;Batching&lt;/li&gt;&#xA;&lt;li&gt;Padding&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Unsupervised Pre-Training&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Autoregression&lt;/li&gt;&#xA;&lt;li&gt;BERT loss&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Tasks&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Text Classification&lt;/li&gt;&#xA;&lt;li&gt;Named Entity Recognition&lt;/li&gt;&#xA;&lt;li&gt;Question Answering&lt;/li&gt;&#xA;&lt;li&gt;Summarization&lt;/li&gt;&#xA;&lt;li&gt;Translation&lt;/li&gt;&#xA;&lt;li&gt;Text Generation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;text-preprocessing&#34;&gt;Text Preprocessing&lt;/h2&gt;&#xA;&lt;p&gt;Text preprocessing is an essential step in NLP that involves cleaning and transforming unstructured text data to prepare it for analysis. Some common text preprocessing techniques include:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformers for Computer Vision</title>
      <link>https://ajdillhoff.github.io/notes/transfomers_for_computer_vision/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/transfomers_for_computer_vision/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#vision-transformer--vit&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Vision Transformer (ViT) (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Dosovitskiy et al. 2021&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#swin-transformer&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Swin Transformer (&lt;a href=&#34;#citeproc_bib_item_4&#34;&gt;Liu et al. 2021&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;vision-transformer--vit&#34;&gt;Vision Transformer (ViT) (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Dosovitskiy et al. 2021&lt;/a&gt;)&lt;/h2&gt;&#xA;&lt;p&gt;The original Vision Transformer (ViT) was published by Google Brain with a simple objective: apply the Transformer architecture to images, adding as few modifications necessary. When trained on ImageNet, as was standard practice, the performance of ViT does not match models like ResNet. However, scaling up to hundreds of millions results in a better performing model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformers</title>
      <link>https://ajdillhoff.github.io/notes/transformers/</link>
      <pubDate>Sun, 06 Nov 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/transformers/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#attention&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Attention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#key-value-store&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Key-value Store&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#scaled-dot-product-attention&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Scaled Dot Product Attention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multi-head-attention&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multi-Head Attention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#encoder-decoder-architecture&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Encoder-Decoder Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#encoder&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Encoder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#decoder&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Decoder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#usage&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Usage&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The story of Transformers begins with &amp;ldquo;Attention Is All You Need&amp;rdquo; (Vaswani et al., n.d.). In this seminal work, the authors describe the current landscape of sequential models, their shortcomings, and the novel ideas that result in their successful application.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Submitting Assignments using GitHub</title>
      <link>https://ajdillhoff.github.io/notes/submitting_assignments_using_github/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/submitting_assignments_using_github/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cloning-a-repository&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Cloning a Repository&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#adding-a-new-file&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Adding a new file&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#committing-changes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Committing Changes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#pushing-your-local-changes-to-the-remote-repository&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Pushing your local changes to the remote repository&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;This article walks through the steps needed to complete Assignment 0.&#xA;For this course, we only need to use 5 commands.&#xA;Although it is not required for this course, it is highly recommended that you learn the basics of &lt;code&gt;git&lt;/code&gt;.&#xA;The &lt;a href=&#34;https://git-scm.com/doc&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;documentation page&lt;/a&gt; provided by &lt;code&gt;git-scm&lt;/code&gt; is extremely helpful.&#xA;It includes links to a free book on &lt;code&gt;git&lt;/code&gt; as well as a cheat sheet with the most common &lt;code&gt;git&lt;/code&gt; commands.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sequential Minimal Optimization</title>
      <link>https://ajdillhoff.github.io/notes/sequential_minimal_optimization/</link>
      <pubDate>Mon, 04 Jul 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/sequential_minimal_optimization/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#box-constraints&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Box Constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#updating-the-lagrangians&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Updating the Lagrangians&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#implementation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Implementation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Paper link:&lt;/strong&gt; &lt;a href=&#34;https://www.microsoft.com/en-us/research/publication/sequential-minimal-optimization-a-fast-algorithm-for-training-support-vector-machines/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://www.microsoft.com/en-us/research/publication/sequential-minimal-optimization-a-fast-algorithm-for-training-support-vector-machines/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Discriminant Functions</title>
      <link>https://ajdillhoff.github.io/notes/discriminant_functions/</link>
      <pubDate>Tue, 07 Jun 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/discriminant_functions/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#binary-classification&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Binary Classification&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#plotting-a-decision-boundary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Plotting a Decision Boundary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multiple-classes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multiple Classes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#sensitivity-to-outliers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Sensitivity to Outliers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The notebook for this lesson can be found &lt;a href=&#34;https://github.com/ajdillhoff/CSE6363/blob/main/logistic_regression/least_squares_classification.ipynb&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Instance Segmentation</title>
      <link>https://ajdillhoff.github.io/notes/instance_segmentation/</link>
      <pubDate>Mon, 18 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/instance_segmentation/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mask-r-cnn&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Mask R-CNN (&lt;a href=&#34;#citeproc_bib_item_4&#34;&gt;He et al. 2018&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#centermask&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;CenterMask (&lt;a href=&#34;#citeproc_bib_item_6&#34;&gt;Lee and Park 2020&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cascade-r-cnn&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Cascade R-CNN (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;Cai and Vasconcelos 2019&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#maskformer&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;MaskFormer (&lt;a href=&#34;#citeproc_bib_item_3&#34;&gt;Cheng, Schwing, and Kirillov 2021&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mask2former&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Mask2Former (&lt;a href=&#34;#citeproc_bib_item_2&#34;&gt;Cheng et al. 2022&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mask-frozendetr&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Mask-FrozenDETR (&lt;a href=&#34;#citeproc_bib_item_7&#34;&gt;Liang and Yuan 2023&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#segment-anything&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Segment Anything (&lt;a href=&#34;#citeproc_bib_item_5&#34;&gt;Kirillov et al. 2023&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#segment-anything-2&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Segment Anything 2 (&lt;a href=&#34;#citeproc_bib_item_9&#34;&gt;Ravi et al. 2024&lt;/a&gt;)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Instance segmentation is the task of assigning a label to pixels based on which class they belong to. In a supervised setting, the results are more focused given that the domain objects is well defined. Remember that in &lt;a href=&#34;https://ajdillhoff.github.io/notes/image_segmentation/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Image Segmentation&lt;/a&gt;, the pixels were grouped under a general critera such as proximity or color.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Object Detection</title>
      <link>https://ajdillhoff.github.io/notes/object_detection/</link>
      <pubDate>Mon, 18 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/object_detection/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#papers&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Papers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#evaluating-object-detection-methods&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Evaluating Object Detection Methods&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#datasets&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Datasets&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#an-incomplete-history-of-deep-learning-based-object-detection&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;An Incomplete History of Deep-Learning-based Object Detection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;papers&#34;&gt;Papers&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://awesomeopensource.com/projects/object-detection&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://awesomeopensource.com/projects/object-detection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;evaluating-object-detection-methods&#34;&gt;Evaluating Object Detection Methods&lt;/h2&gt;&#xA;&lt;p&gt;Object detection algorithms are evaluated using the mean of Average Precision (mAP) across all classes in the dataset.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Long Short-Term Memory</title>
      <link>https://ajdillhoff.github.io/notes/long_short_term_memory/</link>
      <pubDate>Tue, 12 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/long_short_term_memory/</guid>
      <description>&lt;p&gt;The recurrent nature of RNNs means that gradients get smaller and smaller as the timesteps increase.&#xA;This is known as the &lt;strong&gt;vanishing gradient problem&lt;/strong&gt;.&#xA;One of the first popular solutions to this problem is called &lt;strong&gt;Long Short-Term Memory&lt;/strong&gt;, a recurrent network architecture by Hochreiter and Schmidhuber.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Recurrent Neural Networks</title>
      <link>https://ajdillhoff.github.io/notes/recurrent_neural_networks/</link>
      <pubDate>Sun, 10 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/recurrent_neural_networks/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bidirectional-recurrent-neural-networks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Bidirectional Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#references&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Neural networks are an effective tool for regression and classification tasks, but they do not consider the dependencies of information over time.&#xA;Many tasks have implicit information that is dependent on input that may have already been processed or may not be seen until the future.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimization for Deep Learning</title>
      <link>https://ajdillhoff.github.io/notes/optimization_for_deep_learning/</link>
      <pubDate>Thu, 07 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/optimization_for_deep_learning/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gradient-descent-and-its-variants&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Gradient Descent and its Variants&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#adaptive-learning-rate-methods&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Adaptive Learning Rate Methods&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#parameter-initialization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Parameter Initialization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ruder.io/optimizing-gradient-descent/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://ruder.io/optimizing-gradient-descent/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.deeplearningbook.org/contents/optimization.html&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://www.deeplearningbook.org/contents/optimization.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;empirical risk minimization&lt;/strong&gt; - minimizing over an empirical distribution. Differs from risk minimization which is minimizing over the true distribution. We typically do not know the true distribution.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Convolutional Neural Networks</title>
      <link>https://ajdillhoff.github.io/notes/convolutional_neural_networks/</link>
      <pubDate>Sat, 02 Apr 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/convolutional_neural_networks/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#convolution-operator&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Convolution Operator&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#properties-of-convolutions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Properties of Convolutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#parameter-sharing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Parameter Sharing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#pooling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Pooling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#backwards-pass&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Backwards Pass&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#neural-networks-for-image-classification&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Neural Networks for Image Classification&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#useful-resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Useful Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;&lt;strong&gt;Key Concepts&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deep Learning</title>
      <link>https://ajdillhoff.github.io/notes/deep_learning/</link>
      <pubDate>Tue, 29 Mar 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/deep_learning/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#what-makes-a-model-deep&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;What makes a model deep?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#deep-networks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Deep Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#deep-vs-dot-shallow-networks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Deep vs. Shallow Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#high-dimensional-structured-data&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;High Dimensional Structured Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#activation-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Activation Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#loss-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Loss Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#a-typical-training-pipeline&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;A Typical Training Pipeline&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#useful-links&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Useful Links&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Deep learning is a term that you&amp;rsquo;ve probably heard of a million times by now in different contexts. It is an umbrella term that encompasses techniques for computer vision, bioinformatics, natural language processing, and much more. It almost always involves a neural network of some kind that was trained on a large corpus of data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Boosting</title>
      <link>https://ajdillhoff.github.io/notes/boosting/</link>
      <pubDate>Wed, 23 Mar 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/boosting/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#adaboost&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;AdaBoost&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Combining predictions from multiple sources is usually preferred to a single source.&#xA;For example, a medical diagnosis would carry much more weight if it was the result of a consensus of several experts.&#xA;This idea of prediction by consensus is a powerful way to improve classification and regression models.&#xA;In fact, good performance of a committee of models can be achieved even if each individual model is conceptually very simple.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stereo Vision</title>
      <link>https://ajdillhoff.github.io/notes/stereo_vision/</link>
      <pubDate>Wed, 23 Mar 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/stereo_vision/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#epipolar-geometry&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Epipolar Geometry&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#calibration-with-known-intrinsic-parameters-and-world-points&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Calibration with Known Intrinsic Parameters and World Points&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#estimating-depth&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Estimating Depth&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Binocular vision permits depth perception.&#xA;It is an important part of many tasks such as robotic vision, pose estimation, and scene understanding.&#xA;The goal of steropsis is to reconstruct a 3D representation of the world given correspondences between two or more cameras.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decision Trees</title>
      <link>https://ajdillhoff.github.io/notes/decision_trees/</link>
      <pubDate>Fri, 18 Mar 2022 00:00:00 -0500</pubDate>
      <guid>https://ajdillhoff.github.io/notes/decision_trees/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example-iris-dataset&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example: Iris Dataset&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#growing-a-tree&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Growing a Tree&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#examining-the-iris-classification-tree&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Examining the Iris Classification Tree&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#pruning-a-tree&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Pruning a Tree&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/dmilla/introduction-to-decision-trees-titanic-dataset&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://www.kaggle.com/dmilla/introduction-to-decision-trees-titanic-dataset&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;decision tree&lt;/strong&gt;, or Classification and Regression Trees (CART), is a model that recursively partitions the input space based on a collection of features.&#xA;The partitions are split based on very simple binary choices.&#xA;If yes, branch to the left; if no, branch to the right.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Camera Models</title>
      <link>https://ajdillhoff.github.io/notes/camera_models/</link>
      <pubDate>Fri, 11 Mar 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/camera_models/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#reading&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Reading&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#outline&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Outline&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#pinhole-model&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Pinhole Model&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#from-world-space-to-image-space&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;From World Space to Image Space&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#camera-parameters&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Camera Parameters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#estimating-camera-parameters&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Estimating Camera Parameters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#application-camera-calibration&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Application: Camera Calibration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;reading&#34;&gt;Reading&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Chapters 1 and 7 (Forsyth and Ponce)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.scratchapixel.com/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://www.scratchapixel.com/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1RMyNQR9jGdJm64FCiuvoyJiL6r3H18jeNIyocIO9sfA/edit#slide=id.p&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://docs.google.com/presentation/d/1RMyNQR9jGdJm64FCiuvoyJiL6r3H18jeNIyocIO9sfA/edit#slide=id.p&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture8_camera_models_cs131_2016.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture8_camera_models_cs131_2016.pdf&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://vlm1.uta.edu/~athitsos/courses/cse4310_spring2021/lectures/11_geometry.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;http://vlm1.uta.edu/~athitsos/courses/cse4310_spring2021/lectures/11_geometry.pdf&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;outline&#34;&gt;Outline&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pinhole model&lt;/li&gt;&#xA;&lt;li&gt;Coordinates of a pinhole model&lt;/li&gt;&#xA;&lt;li&gt;Perspective projections&lt;/li&gt;&#xA;&lt;li&gt;Homogeneous coordinates&lt;/li&gt;&#xA;&lt;li&gt;Computer graphics perspective&lt;/li&gt;&#xA;&lt;li&gt;Lenses&lt;/li&gt;&#xA;&lt;li&gt;Intrinsic and extrensic parameters&lt;/li&gt;&#xA;&lt;li&gt;From world to camera to image space&lt;/li&gt;&#xA;&lt;li&gt;Camera calibration&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;pinhole-model&#34;&gt;Pinhole Model&lt;/h2&gt;&#xA;&lt;p&gt;Imagine piercing a small hole into a plate and placing it in front of a black screen.&#xA;The light that enters through the pinhole will show an inverted image against the back plane.&#xA;If we place a virtual screen in front of the pinhole plate, we can project the image onto it.&#xA;This is the basic idea behind a &lt;strong&gt;pinhole camera model&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tracking</title>
      <link>https://ajdillhoff.github.io/notes/tracking/</link>
      <pubDate>Mon, 07 Mar 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/tracking/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#tracking-with-optical-flow&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Tracking with Optical Flow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#kalman-filters&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Kalman Filters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Tracking features and objects is required in many applications ranging from autonomous driving to security. Vision tracking systems are often used for live sports broadcasts to keep track of players, the ball, and other visual queues related to the game.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optical Flow</title>
      <link>https://ajdillhoff.github.io/notes/optical_flow/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/optical_flow/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#motion-features&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Motion Features&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#computing-optical-flow&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Computing Optical Flow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#assumptions-of-small-motion&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Assumptions of Small Motion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#applications&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Applications&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Optical flow refers to the apparent motion in a 2D image. Optical flow methods estimate a &lt;strong&gt;motion field&lt;/strong&gt;, which refers to the true motion of objects in 3D. If a fixed camera records a video of someone walking from the left side of the screen to the right, a difference of two consecutive frames reveals much about the apparent motion.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Segmentation via Clustering</title>
      <link>https://ajdillhoff.github.io/notes/segmentation_via_clustering-2/</link>
      <pubDate>Thu, 24 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/segmentation_via_clustering-2/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#agglomerative-clustering&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Agglomerative Clustering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#k-means-clustering&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;K-Means Clustering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#simple-linear-iterative-clustering--slic&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Simple Linear Iterative Clustering (SLIC)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#superpixels-in-recent-work&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Superpixels in Recent Work&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The goal of segmentation is fairly broad: group visual elements together.&#xA;For any given task, the question is &lt;em&gt;how are elements grouped?&lt;/em&gt;&#xA;At the smallest level of an image, pixels can be grouped by color, intensity, or spatial proximity.&#xA;Without a model of higher level objects, the pixel-based approach will break down at a large enough scale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Segmentation via Clustering</title>
      <link>https://ajdillhoff.github.io/notes/segmentation_via_clustering/</link>
      <pubDate>Thu, 24 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/segmentation_via_clustering/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#agglomerative-clustering&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Agglomerative Clustering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#k-means-clustering&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;K-Means Clustering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#simple-linear-iterative-clustering--slic&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Simple Linear Iterative Clustering (SLIC)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#superpixels-in-recent-work&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Superpixels in Recent Work&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The goal of segmentation is fairly broad: group visual elements together.&#xA;For any given task, the question is &lt;em&gt;how are elements grouped?&lt;/em&gt;&#xA;At the smallest level of an image, pixels can be grouped by color, intensity, or spatial proximity.&#xA;Without a model of higher level objects, the pixel-based approach will break down at a large enough scale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Active Contours</title>
      <link>https://ajdillhoff.github.io/notes/active_contours/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/active_contours/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#parametric-representation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Parametric Representation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#motivation-of-the-fundamental-snake-equation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Motivation of the Fundamental Snake Equation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#external-force&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;External Force&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#energy-minimization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Energy Minimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#iterative-solution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Iterative Solution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#applications&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Applications&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.cs.ait.ac.th/~mdailey/cvreadings/Kass-Snakes.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;http://www.cs.ait.ac.th/~mdailey/cvreadings/Kass-Snakes.pdf&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hidden Markov Models</title>
      <link>https://ajdillhoff.github.io/notes/hidden_markov_models/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/hidden_markov_models/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-markov-assumption&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Markov Assumption&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#evaluation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Evaluation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-viterbi-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Viterbi Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#estimating-parameters&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Estimating Parameters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#expectation-maximization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Expectation Maximization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;This article is essentially a grok of a tutorial on HMMs by (&lt;a href=&#34;#citeproc_bib_item_1&#34;&gt;RABINER 1989&lt;/a&gt;). It will be useful for the reader to reference the &lt;a href=&#34;https://courses.physics.illinois.edu/ece417/fa2017/rabiner89.pdf&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;original paper&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Image Segmentation</title>
      <link>https://ajdillhoff.github.io/notes/image_segmentation/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/image_segmentation/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gestalt-theory&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Gestalt Theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#grouping&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Grouping&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#segmentation-methods&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Segmentation Methods&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/&lt;/a&gt; (Berkeley Segmentation Database)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2105.15203v2&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://arxiv.org/abs/2105.15203v2&lt;/a&gt; (SegFormer)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1703.06870&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://arxiv.org/abs/1703.06870&lt;/a&gt; (Mask R-CNN)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/sithu31296/semantic-segmentation&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;https://github.com/sithu31296/semantic-segmentation&lt;/a&gt; (Collection of SOTA models)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Feature extraction methods such as &lt;a href=&#34;https://ajdillhoff.github.io/notes/scale_invariant_feature_transforms/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;SIFT&lt;/a&gt; provide us with many distinct, low-level features that are useful for providing local descriptions images. We now &amp;ldquo;zoom out&amp;rdquo; and take a slightly higher level look at the next stage of image summarization.&#xA;Our goal here is to take these low-level features and group, or fit, them together such that they represent a higher level feature. For example, from small patches representing color changes or edges, we may wish to build higher-level feature representing an eye, mouth, and nose.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hough Transform</title>
      <link>https://ajdillhoff.github.io/notes/hough_transform/</link>
      <pubDate>Thu, 17 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/hough_transform/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rectangle-detection-based-on-a-windowed-hough-transform&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rectangle Detection based on a Windowed Hough Transform&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Fitting a model to a set of data by consensus, as in &lt;a href=&#34;https://ajdillhoff.github.io/notes/random_sample_consensus/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;RANdom SAmple Consensus&lt;/a&gt;, produces a parameter estimate that is robust to outliers. A similar technique for detecting shapes in images is the &lt;strong&gt;Hough Transform&lt;/strong&gt;.&#xA;Originally it was designed for detecting simple lines, but it can be extended to detect &lt;a href=&#34;https://en.wikipedia.org/wiki/Generalised_Hough_transform&#34;&#xA;&#xA;&#xA;&#xA;&#xA; target=&#34;_blank&#34;&#xA; &#xA;&#xA;&#xA;&gt;arbitrary shapes&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RANdom SAmple Consensus</title>
      <link>https://ajdillhoff.github.io/notes/random_sample_consensus/</link>
      <pubDate>Tue, 15 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/random_sample_consensus/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#finding-the-best-fit-model&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Finding the Best Fit Model&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Unless our data is perfect, we will not be able to find parameters that fit the data in the presence of outliers.&#xA;Consider fitting the data in the figure below using a least squares method.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lagrangian Multipliers</title>
      <link>https://ajdillhoff.github.io/notes/lagrangian_multipliers/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/lagrangian_multipliers/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s take a simple constrained problem (from Nocedal and Wright).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Edge Detection</title>
      <link>https://ajdillhoff.github.io/notes/edge_detection/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/edge_detection/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#computing-gradient-norms&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Computing Gradient Norms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#nonmaxima-suppression&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Nonmaxima Suppression&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#thresholding&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Thresholding&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#connectivity-analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Connectivity Analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;div class=&#34;outer-figure&#34;&gt;&#xA;&lt;figure class=&#34;custom-figure&#34;&gt;&#xA;&#xA;  &lt;a data-fancybox=&#34;&#34; href=&#34;https://ajdillhoff.github.io/ox-hugo/2022-01-31_22-45-59_screenshot.png&#34; data-caption=&#34;Figure 1: Vertical derivative filter (left) and horizontal derivative filter (right).&#34; class=&#34;glightbox&#34;&gt;&#xA;&#xA;&lt;img src=&#34;https://ajdillhoff.github.io/ox-hugo/2022-01-31_22-45-59_screenshot.png&#34; alt=&#34;&amp;lt;span class=&amp;#34;figure-number&amp;#34;&amp;gt;Figure 1: &amp;lt;/span&amp;gt;Vertical derivative filter (left) and horizontal derivative filter (right).&#34; &gt;&#xA;&lt;/a&gt;&#xA;&#xA;&#xA;&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;&#xA;  &#xA;  &lt;p&gt;&#xA;    &lt;span class=&#34;figure-number&#34;&gt;Figure 1: &lt;/span&gt;Vertical derivative filter (left) and horizontal derivative filter (right).&#xA;    &#xA;    &#xA;    &#xA;  &lt;/p&gt;</description>
    </item>
    <item>
      <title>Sampling and Aliasing</title>
      <link>https://ajdillhoff.github.io/notes/sampling/</link>
      <pubDate>Sun, 30 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/sampling/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#resizing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Resizing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#sampling&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Sampling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;resizing&#34;&gt;Resizing&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Aliasing arises through resampling an image&lt;/li&gt;&#xA;&lt;li&gt;How to resize - algorithm&lt;/li&gt;&#xA;&lt;li&gt;How to resolve aliasing&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Resizing an image, whether increase or decreasing the size, is a common image operation. In Linear Algebra, &lt;strong&gt;scaling&lt;/strong&gt; is one of the transformations usually discussed, along with rotation and skew. Scaling is performed by creating a transformation matrix&lt;/p&gt;</description>
    </item>
    <item>
      <title>Color</title>
      <link>https://ajdillhoff.github.io/notes/color/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/color/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#agenda&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Agenda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#light-and-color&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Light and Color&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-human-eye&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Human Eye&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#color-matching&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Color Matching&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#color-physics&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Color Physics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#color-spaces&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Color Spaces&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#hsv-color-space&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;HSV Color Space&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;agenda&#34;&gt;Agenda&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is color?&lt;/li&gt;&#xA;&lt;li&gt;How do we process color?&lt;/li&gt;&#xA;&lt;li&gt;How is color modeled?&lt;/li&gt;&#xA;&lt;li&gt;What information does color contain?&lt;/li&gt;&#xA;&lt;li&gt;What can we infer from color?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;light-and-color&#34;&gt;Light and Color&lt;/h2&gt;&#xA;&lt;p&gt;Light is electromagnetic radiation. It is generally described as waves in an electromagnetic field, but it also considered as photons. Electromagnetic radiation is typically measured based on its wavelength and intensity. Intensity refers to the amount of power that is carried by the photons.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Histogram of Oriented Gradients</title>
      <link>https://ajdillhoff.github.io/notes/histogram_of_oriented_gradients/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/histogram_of_oriented_gradients/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#orientation-histograms&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Orientation Histograms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#histogram-of-oriented-gradients&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Histogram of Oriented Gradients&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Key Questions&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Image Features</title>
      <link>https://ajdillhoff.github.io/notes/image_features/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/image_features/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#detecting-corners&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Detecting Corners&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#describing-image-patches&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Describing Image Patches&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#scale-invariance&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Scale Invariance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Why do we care about image features? One of the main goals of computer vision is understanding of some environment through visual perception. In order to summarize a visual object, we need some description of it.&#xA;These descriptions can come in many forms, so we need to articulate some goals as to what we are ultimately looking for when describing an image.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kernels</title>
      <link>https://ajdillhoff.github.io/notes/kernels/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/kernels/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dual-representation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dual Representation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#relating-back-to-the-original-formulation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Relating Back to the Original Formulation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#types-of-kernels&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Types of Kernels&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#constructing-kernels&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Constructing Kernels&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rbf-maps-to-infinite-dimensional-space&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;RBF maps to infinite-dimensional space&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Slides for these notes can be found &lt;a href=&#34;https://ajdillhoff.github.io/teaching/cse6363/lectures/kernels.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;here.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linear Discriminant Analysis</title>
      <link>https://ajdillhoff.github.io/notes/linear_discriminant_analysis/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/linear_discriminant_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gaussian-class-conditional-densities&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Gaussian Class Conditional Densities&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#decision-boundaries&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Decision Boundaries&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#maximum-likelihood-estimation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Maximum Likelihood Estimation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#quadratic-descriminant-analysis&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Quadratic Descriminant Analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#example&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Slides for these notes can be found &lt;a href=&#34;https://ajdillhoff.github.io/teaching/cse6363/lectures/lda.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linear Filters</title>
      <link>https://ajdillhoff.github.io/notes/linear_filters/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/linear_filters/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#smoothing&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Smoothing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#convolution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Convolution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gaussian-filters&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Gaussian Filters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#image-derivatives&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Image Derivatives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Liner filters are a fundamental concept in computer vision. They are used to process images in a variety of ways, such as smoothing, sharpening, and edge detection. They are also used in convolutional neural networks to extract features from images. An essential building block of the computer vision pipeline, understanding linear filters is crucial for anyone working in the field.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Logistic Regression</title>
      <link>https://ajdillhoff.github.io/notes/logistic_regression/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/logistic_regression/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#picking-a-model&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Picking a Model&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#binary-classification&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Binary Classification&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multiple-classes&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multiple Classes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Slides for these notes are available &lt;a href=&#34;https://ajdillhoff.github.io/teaching/cse6363/lectures/logistic_regression.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;here.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Naive Bayes</title>
      <link>https://ajdillhoff.github.io/notes/naive_bayes/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/naive_bayes/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#maximum-likelihood-estimation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Maximum Likelihood Estimation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#making-a-decision&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Making a Decision&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#relation-to-multinomial-logistic-regression&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Relation to Multinomial Logistic Regression&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mnist-example&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;MNIST Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#gaussian-formulation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Gaussian Formulation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Slides for these notes can be found &lt;a href=&#34;https://ajdillhoff.github.io/teaching/cse6363/lectures/naive_bayes.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;here.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neural Networks</title>
      <link>https://ajdillhoff.github.io/notes/neural_networks/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/neural_networks/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#linear-models-as-a-template-for-machine-learning&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Linear Models as a Template for Machine Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#definition&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#forward-pass&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Forward Pass&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#activation-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Activation Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multi-class-classification&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multi-Class Classification&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#backpropagation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Backpropagation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#visualizing-neural-networks&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Visualizing Neural Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#non-convex-optimization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Non-Convex Optimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;linear-models-as-a-template-for-machine-learning&#34;&gt;Linear Models as a Template for Machine Learning&lt;/h2&gt;&#xA;&lt;p&gt;Previously, we studied the &lt;a href=&#34;https://ajdillhoff.github.io/notes/perceptron/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Perceptron&lt;/a&gt; and saw that while it made for a simple linear classifier, it is severely limited to problems that are already linearly separable.&#xA;This limitation was resolved by introduding a hidden layer with multiple perceptron units, aptly named Multi-Layer Perceptrons.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Perceptron</title>
      <link>https://ajdillhoff.github.io/notes/perceptron/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/perceptron/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#the-perceptron-learning-algorithm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;The Perceptron Learning Algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#limitations-of-single-layer-perceptrons&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Limitations of Single-Layer Perceptrons&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A popular example of a &lt;a href=&#34;https://ajdillhoff.github.io/notes/logistic_regression/&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Logistic Regression&lt;/a&gt; model is the &lt;strong&gt;perceptron&lt;/strong&gt;. Proposed by Frank Rosenblatt in 1962, the perceptron is defined as a generalized linear model:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Principal Component Analysis</title>
      <link>https://ajdillhoff.github.io/notes/principal_component_analysis/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/principal_component_analysis/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#maximum-variance-formulation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Maximum Variance Formulation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#motivating-example&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Motivating Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#noise-and-redundancy&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Noise and Redundancy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#covariance-matrix&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Covariance Matrix&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;If we have some measurements of data, but do not know the underlying dynamics, PCA can resolve this by producing a change of basis such that the dynamics are reflected upon the eigenvectors.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Probability Theory</title>
      <link>https://ajdillhoff.github.io/notes/probability_theory/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/probability_theory/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#a-simple-example&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;A Simple Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#probability-distributions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Probability Distributions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#conditional-probability&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Conditional Probability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#rules-of-probability&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Rules of Probability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#random-variables&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Random Variables&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#continuous-variables&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Continuous Variables&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#moments-of-a-distribution&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Moments of a Distribution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Slides for these notes are available &lt;a href=&#34;https://ajdillhoff.github.io/teaching/cse6363/lectures/probability.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;here.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Regularization</title>
      <link>https://ajdillhoff.github.io/notes/regularization/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/regularization/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#overfitting&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Overfitting&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#penalizing-weights&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Penalizing Weights&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dataset-augmentation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dataset Augmentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#early-stopping&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Early Stopping&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dropout&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Dropout&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Slides for these notes are available &lt;a href=&#34;https://ajdillhoff.github.io/teaching/cse6363/lectures/regularization.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;here.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scale Invariant Feature Transforms</title>
      <link>https://ajdillhoff.github.io/notes/scale_invariant_feature_transforms/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/scale_invariant_feature_transforms/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#scale-space-extrema&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Scale-Space Extrema&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#keypoint-localization&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Keypoint Localization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#orientation-assignment&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Orientation Assignment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#descriptor-formation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Descriptor Formation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;The goal is to detect features that are robust to varying conditions like scale, rotation, and translation. SIFT focuses first on detection of scale-space extrema. A robust feature is one that is invariant to scale change. If this feature appears consistently as the scale space is changed, it will ultimately be selected.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Support Vector Machine</title>
      <link>https://ajdillhoff.github.io/notes/support_vector_machine/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/support_vector_machine/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#maximum-margin-classifier&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Maximum Margin Classifier&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#formulation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Formulation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#overlapping-class-distributions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Overlapping Class Distributions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#multiclass-svm&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Multiclass SVM&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#additional-resources&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Additional Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Support Vector Machines are a class of supervised learning methods primarily used for classification. Although they can be formulated for regression and outlier detection as well. Instead of optimizing a set of parameters which compress or summarize the training set, they use a small subset of the training data to compute the decision function.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linear Regression</title>
      <link>https://ajdillhoff.github.io/notes/linear_regression/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 -0600</pubDate>
      <guid>https://ajdillhoff.github.io/notes/linear_regression/</guid>
      <description>&lt;div class=&#34;ox-hugo-toc toc&#34;&gt;&#xA;&lt;div class=&#34;heading&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#probabilistic-interpretation&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Probabilistic Interpretation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#solving-with-normal-equations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Solving with Normal Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#another-approach-to-normal-equations&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Another Approach to Normal Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#fitting-polynomials&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Fitting Polynomials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#linear-basis-functions&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;Linear Basis Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;!--endtoc--&gt;&#xA;&lt;p&gt;Slides for these notes are available &lt;a href=&#34;https://ajdillhoff.github.io/teaching/cse6363/lectures/linear_regression.pdf&#34;&#xA;&#xA;&#xA;&#xA; &#xA;&#xA;&#xA;&gt;here.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Survey about Covid-19 in Boston</title>
      <link>https://ajdillhoff.github.io/project/project-6/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/project/project-6/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua.&#xA;Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea&#xA;commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machine Learning for Airbnb Data</title>
      <link>https://ajdillhoff.github.io/project/project-5/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/project/project-5/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua.&#xA;Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea&#xA;commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Autumn Cartoon Fun</title>
      <link>https://ajdillhoff.github.io/project/project-4/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/project/project-4/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua.&#xA;Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea&#xA;commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Book Mockup</title>
      <link>https://ajdillhoff.github.io/project/project-3/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/project/project-3/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua.&#xA;Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea&#xA;commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Foster Youth in Ma Schools</title>
      <link>https://ajdillhoff.github.io/project/project-2/</link>
      <pubDate>Sun, 02 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/project/project-2/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua.&#xA;Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea&#xA;commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Book hardcover</title>
      <link>https://ajdillhoff.github.io/project/project-1/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://ajdillhoff.github.io/project/project-1/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipisci elit, sed eiusmod tempor incidunt ut labore et dolore magna aliqua.&#xA;Ut enim ad minim veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea&#xA;commodi consequatur. Quis aute iure reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
