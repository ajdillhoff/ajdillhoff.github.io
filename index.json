[{"authors":["admin"],"categories":null,"content":"I love building things and helping others build things they are passionate about. I also love distilling complex topics, clearing the path towards knowledge.\n","date":1689397200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1689397200,"objectID":"05ebe7d8c837c5d6c5fe1186ef4f04cb","permalink":"https://ajdillhoff.github.io/authors/alex-dillhoff/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/alex-dillhoff/","section":"authors","summary":"I love building things and helping others build things they are passionate about. I also love distilling complex topics, clearing the path towards knowledge.","tags":null,"title":"Alex Dillhoff","type":"authors"},{"authors":["admin"],"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nIt is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum. The point of using Lorem Ipsum. distracted by the readable content of a page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ajdillhoff.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nIt is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum.","tags":null,"title":"Alex Dillhoff","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\nOnline courses Project or software documentation Tutorials The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"01d39688af48040d7111d20c6b01d10b","permalink":"https://ajdillhoff.github.io/courses/example.1/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example.1/","section":"courses","summary":"Learn how to use Academia's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview 2","type":"docs"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\nOnline courses Project or software documentation Tutorials The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"970b63766f241ba034ef2d1838dad4b3","permalink":"https://ajdillhoff.github.io/courses/example.2/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example.2/","section":"courses","summary":"Learn how to use Academia's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview 3","type":"docs"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\nOnline courses Project or software documentation Tutorials The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://ajdillhoff.github.io/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academia's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://ajdillhoff.github.io/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"883c5cf2007b50b720ce5f4a17b72261","permalink":"https://ajdillhoff.github.io/courses/example.1/example3/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example.1/example3/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"32df3afea9008eacfc678398fd6443ad","permalink":"https://ajdillhoff.github.io/courses/example.2/example3/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example.2/example3/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"ae73c2dafb9eed90c8870cdf783e948c","permalink":"https://ajdillhoff.github.io/courses/example.2/example4/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example.2/example4/","section":"courses","summary":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://ajdillhoff.github.io/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"507e4cd2746d8b7ea0b6ed4a42cb4462","permalink":"https://ajdillhoff.github.io/courses/example.1/example4/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example.1/example4/","section":"courses","summary":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":["Alex Dillhoff"],"categories":null,"content":"Introduction Hidden Markov Models provide a way of modeling the dynamics of sequential information. They have been used for speech recognition, part-of-speech tagging, machine translation, handwriting recognition, and, as we will see in this article, gesture recognition.\nConsider a somewhat practical use-case: you are going to throw a party with a meticulously curated playlist. You would rather not let anyone have the remote as it might get lost, and letting anyone interrupt the playlist with their own selections may derail the entire event. However, you still want to give your guests the ability to control the volume and skip back and forth between tracks in the playlist. We will also assume that guests will use change tracks and control the volume responsibly.\nThe solution to this problem is to implement a gesture recognition system to identify simple hand motions. In this case, we only have to model 4 separate gestures: VolumeUp, VolumeDown, PrevTrack, NextTrack. Since the motions are temporal in nature, we can model each gesture using Hidden Markov Models. First, we need to cover a bit of background on what a Hidden Markov Model actually is.\nBackground First, introduce Markov Chains Then the Markov assumption At the core of our problem, we want to model a distribution over a sequence of states. Consider a sequence of only 3 states \\(p(x_1, x_2, x_3)\\). The full computation of this can be done using the chain rule of probability:\n\\[ p(x_1, x_2, x_3) = p(x_1) p(x_2 | x_1) p(x_3 | x_1, x_2). \\]\nIf the random variables of our problem are not conditionally independent, the complexity of calculating this is exponential in the number of random variables.\nThe Markov in Hidden Markov Models addresses this complexity. The Markov Assumption states that the probability of an event at time \\(t\\) is conditioned only on the previously observed event: \\(p(x_t | x_{t-1})\\). This is compactly represented with a graphical model, as seen in figure TODO.\nTODO: Figure of basic Markov Chain\nThe hidden qualifier comes from the fact that the data we wish to model was generated from some underlying process that is not directly observable. A classic example for HMMs uses the weather. Imagine you had a log which had the number of water bottles a person had drank per day over the entire year. To make the problem slightly more difficult, the log entries were not associated with a date. It is reasonable to say that the amount of water a person drinks is influenced by how hot or cold it is on a particular day. So, the hidden state in this case is the weather: hot or cold. We can model this with an HMM by establishing that the amount of water (observed state) is conditioned on the weather (hidden state). Figure TODO shows this HMM graphically.\nTODO: Figure of HMM\nFormally, a Hidden Markov Model is defined by\nThe number of hidden states \\(N\\). A transition probability matrix \\(A \\in \\mathbb{R}^{N \\times N}\\), where \\(a_{ij} = p(z_t = j | z_{t-1} = i)\\). An observation symbol probability distribution \\(B = \\{b_j(k)\\} = p(\\mathbf{x}_t = k | z_t = j)\\). An initial state distribution \\(\\pi_i = p(z_t = i)\\). The trainable parameters of our model are \\(\\lambda = (A, B, \\pi)\\).\nFunctions of an HMM Given the basic definition of what an HMM is, how can we train the parameters defined in \\(\\lambda\\). If we somehow already knew the parameters, how can we extract useful information from the model? Depending on our task, we can use HMMs to answer many important questions:\nFiltering computes \\(p(z_t | \\mathbf{x}_{1:t})\\). That is, we are computing this probability as new samples come in up to time \\(t\\). Smoothing is accomplished when we have all the data in the sequence. This is expressed as \\(p(z_t|\\mathbf{x}_{1:T})\\). Fixed lag smoothing allows for a trade off between accuracy and delay. It is useful in cases where we might not have the full sequence, but we wish to compute \\(p(z_{t-l}|\\mathbf{x}_{1:t})\\) for some \\(l \u0026gt; 0\\). Predictions are represented as \\(p(z_{t+h}|\\mathbf{x}_{1:t})\\), where \\(h \u0026gt; 0\\). MAP estimation yields the most probably state sequence \\(\\text{arg}\\max_{\\mathbf{z}_{1:T}}p(\\mathbf{z}_{1:T}|\\mathbf{x}_{1:T})\\). We can sample the posterior \\(p(\\mathbf{z}_{1:T}|\\mathbf{x}_{1:T})\\). We can also compute \\(p(\\mathbf{x}_{1:T})\\) by summing up over all hidden paths. This is useful for classification tasks. Of course not all of these functions make sense for every possible task, more on that later. This article is not meant to be an exhaustive resource for all HMM functions; we will only look at the tasks necessary to train and use HMMs for isolated gesture recognition TODO: offer additional reading suggestions.\nData Processing As far as the efficacy of our model goes, how we process the data is the most important. Our system will start with a camera that records our guests performing one of the four simple motions. For simplicity, let\u0026rsquo;s pretend that the camera has an onboard chip that detects the 2D centroids of the left hand for each frame. That helps a lot, but there is still the problem of isolating a group of frames based on when the user wanted to start and finish the command. Assuming we have a solution for both of these problems, we still need to take into account that users will gesture at different speeds. Since all of these problems are challenging in their own right, we will assume the computer vision fairy has taken care of this for us.\nEach gesture in our dataset consists of 30 \\((x, y)\\) locations of the center of the left hand with respect to image coordinates. Even with this simplified data, we have another problem: different users may gesture from different locations. The hand locations for one user performing the VolumeUp gesture may be vastly different from another. This isn\u0026rsquo;t too bad to deal with. We could normalize or training data by subtracting the location of the hand in the first frame from the gesture. That way every input would start at \\((0, 0)\\). We can simplify this even further by using relative motion states.\nRelative Motion States Relative motion states discretize our data, thus simplifying the input space. The idea is quite simple: if the hand moved to the right relative to the previous frame, we assign \\(x = 1\\) for that frame. If it moved to the left, assign \\(x = -1\\). If it didn\u0026rsquo;t move at all, or did not move a significant amount, assign \\(x = 0\\). We apply similar rules for the \\(y\\) locations as well. The TODO: figure below shows the relative motion grid.\nBesides greatly simplifying our input space, meaning we can use a simple categorical distribution to model these observations, we no longer have to worry about the discrepency between where each user performed the gesture.\nModeling a Gesture Our system will consist of 4 HMM models to model the dynamics of each gesture. To determine which gesture was performed, we will given our input sequence to each one and have it compute \\(p(\\mathbf{x}_{1:T}; \\lambda_i)\\), the probability of the observation given the parameters of model \\(i\\). Whichever model gives the high probability wins.\nTODO\nDescribe EM at a high level, show the breakdown of probabilities that need to be known Go into forward-backwards Go back to EM and plug them in Training: Expectation-Maximization If we cannot observe the hidden states directly, how are we supposed to update the model parameters \\(\\lambda = (A, B, \\pi)\\)? We may not have all of the information, but we do have some information. We can use that to fill in the missing values with what we would expect them to be given what we already know. Then, we can update our parameters using those expected values. This is accomplished through a two-stage algorithm called Expectation-Maximization. Those familiar with k-Nearest Neighbors should already be familiar with this process.\nUpdating with Perfect Information It is useful to know how we would update our parameters assuming we had perfect information. If the hidden states were fully observable, then updating our model parameters would be as straightforward as computing the maximum likelihood estimates. For \\(A\\) and \\(\\pi\\), we first tally up the following counts:\n\\[ \\hat{a}_{ij} = \\frac{N_{ij}}{\\sum_j N_{ij}}, \\]\nthe number of times we expect to transition from \\(i\\) to \\(j\\) divided by the number of times we transition from \\(i\\) to any other state. Put simply, this computes the expected transitions from \\(i\\) to \\(j\\) normalized by all the times we expect to start in state \\(i\\).\nFor \\(\\pi\\), we have\n\\[ \\hat{\\pi_i} = \\frac{N_i}{\\sum_i N_i}, \\]\nthe number of times we expect to start in state \\(i\\) divided by the number of times we start in any other state.\nEstimating the parameters for \\(B\\) depends on which distribution we are using for our observation probabilities. For a multinomial distribution, we would compute the number of times we are in state \\(j\\) and observe a symbol \\(k\\) divided by the number of times we are in state \\(j\\):\n\\[ \\hat{b}_{jk} = \\frac{N_{jk}}{N_k}, \\]\nwhere\n\\[ N_{jk} = \\sum_{i=1}^N \\sum_{t=1}^T \\mathbb{1} (z_{i, t}=j, x_{i, t}=k). \\]\nIt is also common to model our emission probability using a Normal distribution. We can even use a parameterized model like a neural network. TODO: provide links to examples of these\nUpdating with Missing Information Now to the real problem: fill in our missing information using our observable data and the current parameter estimates. There are two important statistics that we need to compute, called the sufficient statistics.\nThe expected number of transitions from \\(i\\) to \\(j\\). The expected number of times we are transitioning from \\(i\\) to any other state. Both of these can be computed starting with the same probability conditioned on our observable data:\n\\[ p(z_t = i, z_{t+1} = j|\\mathbf{x}_{1:T}). \\]\nForwards-Backwards Algorithm Implementation in Python Conclusion ","date":1689397200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689397200,"objectID":"f274eff17c529462e71940e1c4965e60","permalink":"https://ajdillhoff.github.io/articles/intro_to_hmms/","publishdate":"2023-07-15T00:00:00-05:00","relpermalink":"/articles/intro_to_hmms/","section":"articles","summary":"Hidden Markov Models provide a way of modeling the dynamics of sequential information. They have been used for speech recognition, part-of-speech tagging, machine translation, handwriting recognition, and, as we will see in this article, gesture recognition.","tags":["machine learning"],"title":"An Introduction to Hidden Markov Models for Gesture Recognition","type":"articles"},{"authors":null,"categories":null,"content":" Introduction Binary Classification Plotting a Decision Boundary Multiple Classes Sensitivity to Outliers Introduction The notebook for this lesson can be found here.\nWith linear regression, we were able to fit a model to our data in order to make inferences on unseen data points. In the examples, both the input features and observation were continuous. With discriminant functions, we will use similar models to classify the data points based on their input features. We start out with the simplest approach: we assume that the data is linearly separable and can be assigned one of \\(K\\) discrete classes.\nFor classification with linear discriminant functions, we will use a \\(K\\) dimensional vector that has a 1 corresponding to the class encoding for that input and a 0 for all other positions. For example, if our possible target classes were \\(\\{\\text{car, truck, person}\\}\\), then a target vector for \\(\\text{person}\\) would be \\(\\mathbf{y} = [0, 0, 1]^T\\).\nThis article will stick to a discriminative approach to classification. That is, we define a discriminant function which assigns each data input \\(\\mathbf{x}\\) to a class. For a probabilistic perspective, see Linear Discriminant Analysis.\nWe will again start with a linear model \\(y = f(\\mathbf{x}; \\mathbf{w})\\). Unlike the model used with linear regression, ours will need to predict a discrete class label. In other words, we need to predict a vector with a 1 corresponding to the class encoding.\nBinary Classification Consider a simple dataset with 2 features per data sample. Our goal is to classify the data as being one of two possible classes. This only requires a single function which classifies the sample as being in class 0 if \\(f(\\mathbf{x};\\mathbf{w}) \\geq 0\\) and class 1 otherwise.\nFigure 1: Two groups of data that are very clearly linearly separable. The model output is such that \\(f(\\mathbf{x};\\mathbf{w}) = [1, 0]\\) when \\(\\mathbf{x}\\) is predicted as class 1. If \\(f(\\mathbf{x};\\mathbf{w}) = [0, 1]\\) then \\(\\mathbf{x}\\) is assigned to class 2. In practice, the actual output will not be a one-hot vector. There will be some values in all positions of the vector.\nFor example, a model trained on a binary classification task outputs the following vector given a randomly selected input sample:\n\\[ [0.1224, 0.8776] \\]\nA class would be assigned by taking the argmax of this output vector. That is, the model predicts that this sample belongs to class 1.\nMeasuring Classifier Performance L1 loss can be used to measure classifier performance for linear discriminant function models.\n\\[ E = \\sum_{i=1}^N \\sum_{j=1}^M |\\hat{y}_{ij} - y_{ij}| \\]\nPlotting a Decision Boundary In the case of binary classification, a sample is predicted as class 1 if the output vector has the highest value at index 0. Otherwise, it is classified as class 2. If we were to plot the decision regions, we would see that the boundary is at the point when the output for both classes is equal.\nFigure 2: Binary classification with decision regions shown. Multiple Classes Extending this to multiple classes is as easy as encoding the classes in a one-hot vector whose length equals the number of classes. The parameters of the model can be obtained using gradient descent, the normal equations, or any other method that optimizes the least squares criterion.\nThe figure below shows an example of a linear discriminant function model fit to a dataset with 3 classes.\nFigure 3: Multiclass classification using linear discriminant functions. Sensitivity to Outliers One major flaw with least squares models is their sensitivity to outliers in the data. Consider the dataset shown below.\nFigure 4: Linearly separable dataset This dataset is clearly linearly separable. This will be no problem for our linear classifier, as seen below.\nFigure 5: Linear classifier fit to data using least squares. This dataset has a convenient property that the samples from each class are tightly clustered. What happens if our data is slightly more diverse?\nFigure 6: 2-class dataset in which one class is not as tightly clustered as the other. In the dataset above, we can still clearly see that it should be linearly separable. Unfortunately, our least squares model will be very sensitive to the 20 points at the top left of the plot. Training a linear discriminant function using least squares results in the following decision boundary.\nFigure 7: The model misclassifies samples that should be linearly separable. If we determine that a linear classifier is adequate for a given dataset, we may wish to use a slightly more robust model such as Logistic Regression instead of linear discriminant functions.\n","date":1654578000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654578000,"objectID":"4eeb3b49e53888a547d60e92fc258530","permalink":"https://ajdillhoff.github.io/notes/discriminant_functions/","publishdate":"2022-06-07T00:00:00-05:00","relpermalink":"/notes/discriminant_functions/","section":"notes","summary":"Introduction Binary Classification Plotting a Decision Boundary Multiple Classes Sensitivity to Outliers Introduction The notebook for this lesson can be found here.\nWith linear regression, we were able to fit a model to our data in order to make inferences on unseen data points. In the examples, both the input features and observation were continuous. With discriminant functions, we will use similar models to classify the data points based on their input features.","tags":null,"title":"Discriminant Functions","type":"notes"},{"authors":["Alex Dillhoff"],"categories":null,"content":" TODO Introduction AdaBoost TODO Gradient Boosting Introduction Combining predictions from multiple sources is usually preferred to a single source. For example, a medical diagnosis would carry much more weight if it was the result of a consensus of several experts. This idea of prediction by consensus is a powerful way to improve classification and regression models. In fact, good performance of a committee of models can be achieved even if each individual model is conceptually very simple.\nBoosting is one such way of building a committee of models for classification or regression and is popularly implemented by an algorithm called AdaBoost.\nAdaBoost Given a dataset \\(\\{\\mathbf{x}_i\\}\\) and target variables \\(\\{\\mathbf{y}_i\\}\\), AdaBoost first initializes a set of weights corresponding to each data sample as \\(w_i = \\frac{1}{N}\\). At each step of the algorithm, a simple classifier, called a weak learner is fit to the data. The weights for each sample are adjusted based on the individual classifier\u0026rsquo;s performance. If the sample was misclassified, the relative weight for that sample is increased. After all classifiers have been fit, they are combined to form an ensemble model.\nThe Algorithm Initialize data weights \\({w_i}\\) as \\(w_i^{(1)} = \\frac{1}{n}\\) for \\(i = 1, \\dots, n\\).\nFit each weak learner \\(j\\) to the training data by minimizing the misclassification cost:\n\\[ \\sum_{i=1}^n w_i^{(j)} \\mathbb{1}(f_j(\\mathbf{x}_i) \\neq \\mathbf{y}_i) \\]\nCompute a weighted error rate\n\\[ \\epsilon_j = \\frac{\\sum_{i=1}^n w_i^{(j)} \\mathbb{1}(f_j(\\mathbf{x}_i) \\neq \\mathbf{y}_i)}{\\sum_{i=1}^n w_i^{(j)}} \\]\nUse the weighted error rate to compute a weight for each classifier such that misclassified samples are given higher weight:\n\\[ \\alpha_j = \\ln \\bigg\\{\\frac{1 - \\epsilon_j}{\\epsilon_j}\\bigg\\}. \\]\nUpdate the data weights for the next model in the sequence:\n\\[ w_i^{j+1} = w_i^{j} \\exp\\{\\alpha_j \\mathbb{1}(f_j(\\mathbf{x}_i \\neq \\mathbf{y}_i)\\}. \\]\nOnce all weak learners are trained, the final model predictions are given by\n\\[ Y_M(\\mathbf{x}) = \\text{sign} \\Bigg(\\sum_{j=1}^M \\alpha_j f_j(\\mathbf{x})\\Bigg). \\]\nWeak Learners The weak learners can be any classification or regression model. However, they are typically chosen to be very simple to account for training time. For example, a complex deep learning model would be a poor choice for a weak learner.\nOne example of a weak learner is a simple linear model like a Perceptron or decision stump. A standard implementation of AdaBoost uses a decision tree with depth 1, as observed in sklearn\u0026rsquo;s implementation.\nExample Let\u0026rsquo;s put this together and walk through the first few steps of training an AdaBoost model using a decision stump as the weak learner. We will use a very simple dataset to keep the values easy to compute by hand.\nInitial Data\nx1 x2 y weight 1 5 0 0.2 2 6 1 0.2 3 7 0 0.2 4 8 1 0.2 5 9 1 0.2 Weak Learner 1\nThe first learner is trained on the initial data and picks \\(x_1 = 2.5\\) as the split threshold. Input where \\(x_1 \\leq 2.5\\) is assigned to class 0 and all other samples are assigned class 1. The data with this learner\u0026rsquo;s predictions are shown below.\nx1 x2 y weight prediction 1 5 0 0.2 0 2 6 1 0.2 0 3 7 0 0.2 1 4 8 1 0.2 1 5 9 1 0.2 1 Error and weight\nThe error is simple enough to compute as all samples are currently weighted equally. Since two of the samples were misclassified, the error is the sum of their weights.\nTotal error\n\\(e_1 = 0.2 + 0.2 = 0.4\\).\nThe weight of the classifier can then be computed.\nClassifier weight\n\\(\\alpha_1 = \\frac{1}{2} \\ln \\big(\\frac{1 - e_1}{e_1}\\big) = 0.2027\\).\nThe weights of our data can now be updated using this value of \\(\\alpha_1\\). The weight of each example is updated by multiplying each correctly classifed sample by \\(\\exp\\{-\\alpha_1\\}\\) and each incorrectly classified sample by \\(\\exp\\{\\alpha\\}\\):\n\\[ w_i^{j+1} = w_i^{j} \\exp\\{\\alpha_j \\mathbb{1}(f_j(\\mathbf{x}_i \\neq \\mathbf{y}_i)\\}. \\]\nNOTE: You will notice that the equation above is different from the actual update rule that was applied to the weights in this example. In the original publication (TODO: reference Fruend), the weights are renormalized at the end of the loop. In this example, the normalization is combined with the update. In either case, the updated weights are shown below.\nx1 x2 y weight 1 5 0 0.167 2 6 1 0.250 3 7 0 0.250 4 8 1 0.167 5 9 1 0.167 Weak Learner 2\nThe algorithm now moves to the next weak learner, which classifies the data given a threshold of \\(x_1 = 3.5\\). Its predictions are shown below.\nx1 x2 y weight prediction 1 5 0 0.167 0 2 6 1 0.250 0 3 7 0 0.250 0 4 8 1 0.167 1 5 9 1 0.167 1 Only a single sample is misclassified, and the error is computed as before.\nTotal error\n\\(e_2 = 0.250\\)\nClassifier weight\n\\(\\alpha_2 = \\frac{1}{2} \\ln \\big(\\frac{1 - e_2}{e_2}\\big) = 0.5493\\)\nThe weights are updated for each sample, yielding the following data:\nx1 x2 y weight 1 5 0 0.111 2 6 1 0.500 3 7 0 0.167 4 8 1 0.111 5 9 1 0.111 The second sample has been misclassified twice at this point, leading to a relatively high weight. This will hopefully be addressed by the third learner.\nWeak Learner 3\nThe final weak learner splits the data on \\(x_2 = 6.5\\), yielding the following output for each sample.\nx1 x2 y weight prediction 1 5 0 0.111 0 2 6 1 0.500 0 3 7 0 0.167 1 4 8 1 0.111 1 5 9 1 0.111 1 Unfortunately, sample 2 is too tricky for any of our weak learners. The total error is shown below. Since this is a binary classification problem, the error suggests that our weak learner performs worse than random guessing.\nTotal error\n\\(e_3 = 0.667\\)\nClassifier weight\n\\(\\alpha_3 = \\frac{1}{2} \\ln \\big(\\frac{1 - e_3}{e_3}\\big) = -0.3473\\)\nThe negative value of the classifier weight suggests that its predictions will be reversed when evaluated. The updated weights of each data sample are given below.\nx1 x2 y weight 1 5 0 0.167 2 6 1 0.375 3 7 0 0.125 4 8 1 0.167 5 9 1 0.167 Final Classifier\nThe final classifier is a weighted vote of the three weak learners, with the weights being the classifier weights we calculated (0.2027, 0.5493, and -0.3473). The negative weight means that the third learner\u0026rsquo;s predictions are reversed.\n","date":1648011600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648011600,"objectID":"a74fb661122bb4b9319a36a6668cd31f","permalink":"https://ajdillhoff.github.io/notes/boosting/","publishdate":"2022-03-23T00:00:00-05:00","relpermalink":"/notes/boosting/","section":"notes","summary":"TODO Introduction AdaBoost TODO Gradient Boosting Introduction Combining predictions from multiple sources is usually preferred to a single source. For example, a medical diagnosis would carry much more weight if it was the result of a consensus of several experts. This idea of prediction by consensus is a powerful way to improve classification and regression models. In fact, good performance of a committee of models can be achieved even if each individual model is conceptually very simple.","tags":["machine learning"],"title":"Boosting","type":"notes"},{"authors":["Alex Dillhoff"],"categories":null,"content":" Introduction The Markov Assumption Definition Evaluation The Viterbi Algorithm Estimating Parameters Expectation Maximization Introduction This article is essentially a grok of a tutorial on HMMs by (RABINER 1989). It will be useful for the reader to reference the original paper.\nUp to this point, we have only explored \u0026ldquo;atomic\u0026rdquo; data points. That is, all of the information about a particular sample is encapsulated into one vector. Sequential data is easily represented by graphical models. This article introduces Hidden Markov Models, a powerful probabilistic graphical model used in many applications from gesture recognition to natural language processing.\nThere are many tasks for which we do not know the underlying process. However, we can observe samples that are produced from such processes. Music, gesture recognition, speech, text, etc. All of these have some underlying process which forms their outputs together into a hopefully coherent sequence. If we wish to make predictions about future samples given these sequences, we will need to make some guess about the underlying processes defining their output.\nThe Markov Assumption Markov models make a convenient assumption about sequential data. That is, all relevant information required for predicting future samples is captured in the current time step \\(t\\). Given a joint distribution over an input of \\(T\\) frames, \\(p(\\mathbf{x}_{1:T})\\), the Markov assumption allows us to represent it as\n\\[ p(\\mathbf{x}_{1:T}) = p(\\mathbf{x}_1)\\prod_{t=2}^T p(\\mathbf{x}_t|\\mathbf{x}_{t-1}) \\]\nDefinition A more complicated case is when we are attempting to model some unknown process that is responsible for the observations. In this case, an ordinary Markov chain is not sufficient. A hidden Markov model (HMM) is defined by a set \\(z_t \\in \\{1, \\dots, K\\}\\) of discrete hidden states and an observation model \\(p(\\mathbf{x}_i|z_t)\\). The joint probability distribution of this model is given by\n\\[ p(\\mathbf{z}, \\mathbf{x}) = p(\\mathbf{z})p(\\mathbf{x}|\\mathbf{z}) = \\Big(p(z_1)\\prod_{t=2}^Tp(z_t|z_{t-1})\\Big)\\Big(\\prod_{t=1}^Tp(\\mathbf{x}_t|z_t)\\Big). \\]\nFigure 1: The observations y are generated by the latent states x. Source: Wikipedia Although the states themselves are discrete, the observations may be continuous: \\(p(\\mathbf{x}|z_t, \\mathbf{\\theta})\\). If they are discrete, they can be modeled by an observation matrix \\(B\\). Continuous observations are typically modeled using a conditional Gaussian:\n\\[ p(\\mathbf{x}_t|z_t=k, \\theta) = \\mathcal{N}(\\mathbf{x}_t|\\mathbf{\\mu}_k,\\mathbf{\\Sigma}_k). \\]\nFollowing Rabiner, an HMM can be characterized by\nThe number of states in the model \\(N\\). The number of distinct observation symbols per state \\(M\\). The state probability distribution \\(A = \\{a_{ij}\\}\\), \\(a_{ij} = p(z_t=j | z_{t-1} = i)\\). The observation symbol probability distribution \\(B = \\{b_j(k)\\} = p(\\mathbf{x}_t = k|z_t = j)\\). An initial state distribution \\(\\mathbf{\\pi}_i = p(z_t = i)\\). Figure 2: HMM with observation probabilities and state transition probabilities. Source: Wikipedia The observation probability distribution is commonly modeled as a Gaussian, Mixture of Gaussians, or Multinomial distribution. Thus, the parameter estimates for those distributions follow the likelihood estimates for each respective distribution.\nIn his famous tutorial on HMMs, Rabiner addressed the three fundamental problems of HMMs:\nGiven an observation sequence and model parameters, how do we compute the probability of the observation sequence given the parameters (likelihood)? Given an observation sequence and model parameters, how do we choose a state sequence which is optimal (decoding)? How do we adjust the model parameters (learning)? HMMs are able to solve several different inference problems.\nFiltering computes \\(p(z_t | \\mathbf{x}_{1:t})\\). That is, we are computing this probability as new samples come in up to time \\(t\\). Smoothing is accomplished when we have all the data in the sequence. This is expressed as \\(p(z_t|\\mathbf{x}_{1:T})\\). Fixed lag smoothing allows for a trade off between accuracy and delay. It is useful in cases where we might not have the full sequence, but we wish to compute \\(p(z_{t-l}|\\mathbf{x}_{1:t})\\) for some \\(l \u0026gt; 0\\). Predictions are represented as \\(p(z_{t+h}|\\mathbf{x}_{1:t})\\), where \\(h \u0026gt; 0\\). MAP estimation yields the most probably state sequence \\(\\text{arg}\\max_{\\mathbf{z}_{1:T}}p(\\mathbf{z}_{1:T}|\\mathbf{x}_{1:T})\\). We can sample the posterior \\(p(\\mathbf{z}_{1:T}|\\mathbf{x}_{1:T})\\). We can also compute \\(p(\\mathbf{x}_{1:T})\\) by summing up over all hidden paths. This is useful for classification tasks. Evaluation We start by solving the first problem posited by (RABINER 1989).\nGiven an observation sequence and model parameters, how do we compute the probability of the observation sequence given the parameters? That is, given some model parameters \\(\\lambda = (A, B, \\pi)\\), compute \\(p(z_t|\\mathbf{x}_{1:t})\\).\nForwards Pass The forwards algorithm solves two problems of interest. First, we want to know how well our current parameters explain the observation sequence. That is, \\(p(\\mathbf{x}_{1:T}|\\lambda)\\).\nSecond, we want to compute \\(p(z_t | \\mathbf{x}_{1:t})\\). To compute these in an efficient way, a recursive strategy is adopted. Let the forward variable \\(\\alpha_t(i)\\) be defined as\n\\[ \\alpha_t(i) = p(\\mathbf{x}_{1:t}, z_t = i | \\lambda). \\]\nThe forwards algorithm is defined as 3 steps.\nInitialization:\n\\[ \\alpha_1(i) = \\pi_i b_i(\\mathbf{x}_1),\\quad 1 \\leq i \\leq N. \\]\nRecursion:\n\\[ \\alpha_{t+1}(j) = \\Big(\\sum_{i=1}^N \\alpha_t(i)a_{ij}\\Big)b_j(\\mathbf{x}_{t+1}),\\quad 1 \\leq t \\leq T - 1,\\quad 1 \\leq j \\leq N \\]\nTermination:\n\\[ p(\\mathbf{x}_{1:T}) = \\sum_{i=1}^N \\alpha_T(i). \\]\nThe recursive step is visualized as a lattice structure as seen below.\nFigure 3: From Rabiner 1989. With this step, we have a solution for the first problem. We can now calculate more efficiently the probability of our observations given the current model parameters. This along with the following backwards pass will be essential for updating our model parameters.\nThe forwards algorithm is also used to solve the filtering problem. To see how, consider \\(p(z_t | \\mathbf{x}_{1:t-1})\\) right before time \\(t\\).\n\\begin{equation*} p(z_t=j|\\mathbf{x}_{1:t-1}) = \\sum_i p(z_t=j|z_{t-1}=i)p(z_{t-1}=i|\\mathbf{x}_{1:t-1}) \\end{equation*}\nWhen we update for time \\(t\\), we have that\n\\begin{align*} p(z_t=j|\\mathbf{x}_{1:t}) \u0026amp;= p(z_t=j|\\mathbf{x}_t, \\mathbf{x}_{1:t})\\\\ \u0026amp;=\\frac{p(\\mathbf{x}_t|z_t=j, \\mathbf{x}_{1:t-1})p(z_t=j|\\mathbf{x}_{1:t-1})}{p(\\mathbf{x}_t|\\mathbf{x}_{t-1})} \\end{align*}\nHowever, \\(\\mathbf{x}_{1:t-1}\\) is conditionally independent given \\(z_t\\), so it becomes\n\\begin{equation*} p(z_t=j|\\mathbf{x}_{1:t})=\\frac{p(\\mathbf{x}_t|z_t=j)p(z_t=j|\\mathbf{x}_{1:t-1})}{p(\\mathbf{x}_t|\\mathbf{x}_{t-1})}. \\end{equation*}\nWriting out \\(p(z_t=j|\\mathbf{x}_{1:t-1})\\) fully yields\n\\begin{equation*} p(z_t=j|\\mathbf{x}_{1:t}) \\propto p(\\mathbf{x}_t|z_t=j)\\sum_i p(z_t=j|z_{t-1}=i)p(z_{t-1}=i|\\mathbf{x}_{1:t-1}). \\end{equation*}\nThis is the recursion step from above!\nThis can also be represented in terms of the \\(\\alpha\\) variables from above. To compute \\(p(z_t=i|\\mathbf{x}_{1:t})\\), we can use the definition of a conditional probability distribution:\n\\begin{align*} p(z_t=i|\\mathbf{x}_{1:t}) \u0026amp;= \\frac{p(z_t=i, \\mathbf{x}_{1:t})}{p(\\mathbf{x}_{1:t})}\\\\ \u0026amp;= \\frac{\\alpha_t(i)}{\\sum_{j=1}^N \\alpha_t(j)} \\end{align*}\nCompared to the complexity of the explicit representation, the forwards pass needs only \\(N^2T\\) calculations. As pointed out in (RABINER 1989), with 5 hidden states and an observation sequence of length 100, the forwards pass only needs around 3000 computations. A direct calculation would require \\(10^{72}\\).\nBackwards Pass When updating the parameters of our model, we will need to consider the entire observation sequence. The forward pass did not require the entire sequence. Instead, we can compute the probability of the observation up to some time \\(t\\). The backwards pass begins by defining the variable\n\\[ \\beta_t(i) = p(\\mathbf{x}_{t+1:T} | z_t = i). \\]\nWe can utilize a recursive process similar to the forwards algorithm with the following steps:\nInitialization:\n\\[ \\beta_T(i) = 1,\\quad 1 \\leq i \\leq N \\]\nRecursion:\n\\[ \\beta_t(i) = \\sum_{j=1}^N a_{ij}b_j(\\mathbf{x}_{t+1})\\beta_{t+1}(j),\\quad t = T-1,\\dots,1,\\quad 1 \\leq i \\leq N. \\]\nTermination:\n\\[ p(\\mathbf{x}_{1:T}) = \\sum_{j=1}^N \\pi_j b_j(x_1) \\beta_1(j) \\]\nThe complexity of the backwards algorithm is similar to that of the forwards: \\(N^2T\\).\nWith both the forward and backwards passes defined, we can compute the smoothing problem:\n\\[ p(z_t=i|\\mathbf{x}_{1:T}) = \\frac{\\alpha_t(i)\\beta_t(i)}{\\sum_{j=1}^N \\alpha_t(j)\\beta_t(j)} \\]\nThe Viterbi Algorithm With problem 1 out of the way, we turn our attention to problem 2.\nGiven an observation sequence and model parameters, how do we choose a state sequence which is optimal? \\[ \\mathbf{z}^* = \\text{arg}\\max_{\\mathbf{z}_{1:T}}p(\\mathbf{z}_{1:T}|\\mathbf{x}_{1:T}) \\]\nWith respect to the lattice diagram, this is equivalent to computing the shortest path. This is accomplished via the Viterbi algorithm, sometimes referred to as the max-sum algorithm. As with the forwards-backwards algorithm, the Viterbi algorithm takes on a recursive approach. It starts by defining an intermediate variable\n\\[ \\gamma_t(i) = p(z_t=i|\\mathbf{x}_{1:T}). \\]\nUsing the variables defined in the forwards-backwards algorithm, this can be expressed as\n\\[ \\gamma_t(i) = \\frac{\\alpha_t(i) \\beta_t(i)}{\\sum_{i=1}^N \\alpha_t(i) \\beta_t(i)}. \\]\nThis \\(\\gamma_t(i)\\), we can compute the most likely state at time \\(t\\):\n\\[ z_t^* = \\text{arg}\\max_{1\\leq i \\leq N} \\gamma_t(i), \\quad 1 \\leq t \\leq T. \\]\nOne problem with this approach alone is that the most likely state at a particular time \\(t\\) may not lead us to the most probable sequence of states. As stated above, we need to maximize \\(p(\\mathbf{z}_{1:T}|\\mathbf{x}_{1:T})\\). In order to tackle this efficiently, Viterbi employs a dynamic programming approach.\nInitialization\nStart with the best initial state out of all states given the observation at \\(t=1\\). Additionally, we want to record the index of each state through time so that the best path can be retraced.\n\\begin{align*} \\delta_1(i) \u0026amp;= \\pi_i b_i(\\mathbf{x}_1),\\quad 1 \\leq i \\leq N\\\\ \\psi_1(i) \u0026amp;= 0 \\end{align*}\nRecursion:\nThe quantity \\(\\delta_t(i)\\) represents the joint probability of state sequences and observations up to time \\(t\\) ending with state \\(z_t=i\\). Thus, the recursive step is to maximize the probability of the intermediate output for \\(t-1\\):\n\\[ \\delta_t(j) = \\max_{1 \\leq i \\leq N} (\\delta_{t-1}(i) a_{ij})b_j(\\mathbf{x}_t), \\quad 2 \\leq t \\leq T,\\quad 1 \\leq j \\leq N. \\]\nThe corresponding index for this step is recorded in the path matrix:\n\\[ \\psi_t(j) = \\text{arg}\\max_{1 \\leq i \\leq N} \\delta_{t-1}(i)a_{ij},\\quad 2 \\leq t \\leq T,\\quad 1 \\leq j \\leq N. \\]\nTermination\nThe last step of the Viterbi algorithm completes the calcuation of the joint probability of state sequences and observations.\n\\[ p^* = \\max_{1 \\leq i \\leq N} \\delta_T(i) \\]\n\\[ \\mathbf{z}_T^* = \\text{arg}\\max_{1 \\leq i \\leq N} \\delta_T(i) \\]\nPath Backtrace\nWith the state sequence matrix recorded along the way, we can retrace it to get the most probable sequence:\n\\[ z_t^* = \\psi_{t+1}(z_{t+1}^*),\\quad t = T-1, \\cdots, 1. \\]\nEstimating Parameters If the hidden states were fully observable, then updating our model parameters would be as straightforward as computing the maximum likelihood estimates for the model parameters \\(\\lambda = (A, B, \\pi)\\). For \\(A\\) and \\(\\pi\\), we first tally up the following counts:\n\\[ \\hat{a}_{ij} = \\frac{N_{ij}}{\\sum_j N_{ij}}, \\]\nthe number of times we expect to transition from \\(i\\) to \\(j\\) divided by the number of times we transition from \\(i\\) to any other state.\nFor \\(\\pi\\), we have\n\\[ \\hat{\\pi_i} = \\frac{N_i}{\\sum_i N_i}, \\]\nThe number of times we expect to start in state \\(i\\) divided by the number of times we start in any other state.\nEstimating the parameters for \\(B\\) depends on which distribution we are using for our observation probabilities. For a multinomial distribution, we would compute the number of times we are in state \\(j\\) and observe a symbol \\(k\\) divided by the number of times we are in state \\(j\\):\n\\[ \\hat{B}_{jk} = \\frac{N_{jk}}{N_k}, \\]\nwhere\n\\[ N_{jk} = \\sum_{i=1}^N \\sum_{t=1}^T \\mathbb{1} (z_{i, t}=j, x_{i, t}=k). \\]\nIf the observation probability follows a Gaussian distribution, the MLEs for \\(\\mu\\) and \\(\\mathbf{\\Sigma}\\) are\n\\[ \\hat{\\mathbf{\\mu}}_k = \\frac{\\bar{\\mathbf{x}}_k}{N_k},\\quad \\hat{\\mathbf{\\Sigma}}_k = \\frac{(\\bar{\\mathbf{x}}\\bar{\\mathbf{x}})_k^T - N_k \\hat{\\mathbf{\\mu}}_k\\hat{\\mathbf{\\mu}}_k^T}{N_k}, \\]\nwhere\n\\[ \\bar{\\mathbf{x}}_k = \\sum_{i=1}^N \\sum_{t=1}^T \\mathbb{1}(z_{i, t}=k)\\mathbf{x}_{i, t} \\]\nand\n\\[ (\\bar{\\mathbf{x}}\\bar{\\mathbf{x}})_k^T) = \\sum_{i=1}^N \\sum_{t=1}^T \\mathbb{1} (z_{i, t}=k)\\mathbf{x}_{i,k}\\mathbf{x}_{i,k}^T. \\]\nExpectation Maximization Of course, HMMs have hidden states which are not fully observable. Thus, we need to come up with another strategy for updating our parameters based on the observable data. The intuition behind this approach is as follows. We first start out by using our current parameters to estimate the missing data, making it complete. Initially, we may randomize our estimates if we have no good heuristic or guess as to what they should be.\nWith the completed data, we can update our current parameters. In other words, the expected values of the sufficient statistics can be derived now that the data has been filled in. A new set of parameters is found such that it maximizes the likelihood function with respect to the estimated data.\nE Step Following (RABINER 1989), we start with the joint probability of being in state \\(i\\) at time \\(t\\) and state \\(j\\) at time \\(t+1\\):\n\\[ \\xi_t(i, j) = p(z_t = i, z_{t+1} = j|\\mathbf{x}_{1:T}). \\]\nThis can be computed using the forwards-backwards algorithm:\n\\[ \\xi_t(i, j) = \\frac{\\alpha_t(i)a_{ij}b_j(\\mathbf{x}_{t+1})\\beta_{t+1}(j)}{\\sum_{i=1}^N \\sum_{j=1}^N \\alpha_t(i)a_{ij}b_j(\\mathbf{x}_{t+1})\\beta_{t+1}(j)}. \\]\nThis can be related back to \\(\\gamma_t(i)\\) by summing over over \\(j\\):\n\\[ \\gamma_t(i) = \\sum_{j=1}^N \\xi_t(i, j). \\]\nHere, \\(\\gamma_t(i)\\) is the expected number of times we transition from \\(z = i\\). Summing over all \\(t\\) yields the expected transitions from \\(z_i\\) over all time steps:\n\\[ \\sum_{t=1}^{T-1} \\gamma_t(i). \\]\nSince \\(\\xi_t(i, j)\\) is the expected transition from \\(i\\) to \\(j\\) at time \\(t\\), we can compute the total number of transitions from \\(i\\) to \\(j\\) via\n\\[ \\sum_{t=1}^{T-1} \\xi_t(i, j). \\]\nM Step The previous E Step computed the expected values given the current parameter estimates. Now that the data is complete, we can update our parameter estimates. Starting with the transition probabilities, we must add the expected number of transitions from \\(i\\) to \\(j\\) and divide by the expected number of times we transition from \\(i\\). Using the parameters from the E Step, this can be written\n\\[ \\hat{a}_{ij} = \\frac{\\sum_{t=1}^{T-1}\\xi_t(i, j)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}. \\]\nThe initial state probability at \\(t=1\\) is the number of times we expect to be in state \\(z=i\\) at \\(t=1\\):\n\\[ \\gamma_1(i). \\]\nFinally, the observation probability parameters are updated by considering the number of times we are in state \\(z=j\\) and observing \\(x=k\\) divided by the number of times we are in state \\(z=j\\). Note that this is for a multinomial probabiliy distribution:\n\\[ \\hat{b}_j(k) = \\frac{\\sum_{t=1, x_t = k}^T \\gamma_t(j)}{\\sum_{t=1}^T \\gamma_t(j)}. \\]\nThese formulas are derived from maximizing Baum\u0026rsquo;s auxiliary function\n\\[ Q(\\lambda, \\hat{\\lambda}) = \\sum_{Q} p(\\mathbf{z}|\\mathbf{x}, \\lambda) \\log p(\\mathbf{x}, \\mathbf{z}|\\hat{\\lambda}) \\]\nover \\(\\hat{\\lambda}\\). It has further been shown that maximizing this function leads to increased likelihood:\n\\[ \\max_{\\hat{\\lambda}} Q(\\lambda, \\hat{\\lambda}) \\implies p(\\mathbf{x}|\\hat{\\lambda}) \\geq p(\\mathbf{x}|\\lambda). \\]\nIf we have a Gaussian observation model, the values for \\(\\hat{b}_j(k)\\) are computed to accommodate the parameters of the distribution. These parameter estimates assume a Gaussian mixture model. Starting with \\(\\hat{\\mu}_{jk}\\), it can be estimated by dividing the expected value of observations belonging to Gaussian density \\(k\\) by the expected number of times we are in state \\(j\\) using the \\(k^{\\text{th}}\\) mixture component:\n\\[ \\hat{\\mathbf{\\mu}}_{jk} = \\frac{\\sum_{t=1}^T \\gamma_t(j, k)\\mathbf{x}_t}{\\sum_{t=1}^T \\gamma_t(j, k)}. \\]\nHere, \\(\\gamma_t(j, k)\\) is the probability of being in state \\(j\\) at time \\(t\\) with the \\(k^{\\text{th}}\\) mixture component accounting for \\(\\mathbf{x}_t\\):\n\\[ \\gamma_t(j, k) = \\frac{\\alpha_t(j)\\beta_t(j)}{\\sum_{j=1}^N \\alpha_t(j) \\beta_t(j)} \\frac{c_{jk}\\mathcal{N}(\\mathbf{x}_t, \\mu_{jk}, \\mathbf{\\Sigma}_{jk})}{\\sum_{m=1}^M c_{jm}\\mathcal{N}(\\mathbf{x}_t, \\mu_{jm}, \\mathbf{\\Sigma}_{jm})}. \\]\nThis method is proven to improve the parameters.\nEach iteration is guaranteed to improve the log-likelihood function. The process is guaranteed to converge. The convergence point is a fixed point of the likelihood function. These guarantees are similar to gradient ascent.\nReferences ","date":1645509600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689379200,"objectID":"24afc41ee651bea868216ff2c5e1f084","permalink":"https://ajdillhoff.github.io/notes/hidden_markov_models/","publishdate":"2022-02-22T00:00:00-06:00","relpermalink":"/notes/hidden_markov_models/","section":"notes","summary":"Introduction The Markov Assumption Definition Evaluation The Viterbi Algorithm Estimating Parameters Expectation Maximization Introduction This article is essentially a grok of a tutorial on HMMs by (RABINER 1989). It will be useful for the reader to reference the original paper.\nUp to this point, we have only explored \u0026ldquo;atomic\u0026rdquo; data points. That is, all of the information about a particular sample is encapsulated into one vector. Sequential data is easily represented by graphical models.","tags":["machine learning","graphical models"],"title":"Hidden Markov Models","type":"notes"},{"authors":null,"categories":null,"content":" Introduction Gaussian Class Conditional Densities Maximum Likelihood Estimation Example Introduction This section covers classification from a probabilistic perspective. The discriminative approach involves a parameterized function which assigns each input vector \\(\\mathbf{x}\\) to a specific class. We will see that modeling the conditional probability distribution \\(p(C_k|\\mathbf{x})\\) grants us additional benefits while still fulfilling our original classification task.\nLet\u0026rsquo;s begin with a 2 class problem. To classify this with a generative model, we use the class-conditional densities \\(p(\\mathbf{x}|C_i)\\) and class priors \\(p(C_i)\\). The posterior probability for \\(C_1\\) can be written in the form of a sigmoid function:\n\\begin{align*} p(C_1|\\mathbf{x}) \u0026amp;= \\frac{p(\\mathbf{x}|C_1)p(C_1)}{p(\\mathbf{x}|C_1)p(C_1) + p(\\mathbf{x}|C_2)p(C_2)} \\end{align*}\nThen multiply the numerator and denominator by\n\\begin{equation*} \\frac{(p(\\mathbf{x}|C_1))^{-1}}{(p(\\mathbf{x}|C_1))^{-1}}, \\end{equation*}\nwhich yields\n\\begin{equation*} \\frac{1}{1 + \\frac{p(\\mathbf{x}|C_2)p(C_2)}{p(\\mathbf{x}|C_1)p(C_1)}}. \\end{equation*}\nNoting that \\(a = \\exp(\\ln(a))\\), we can rewrite further\n\\begin{equation*} \\frac{1}{1 + \\exp(-a)}, \\end{equation*}\nwhere \\(a = \\ln \\frac{p(\\mathbf{x}|C_1)p(C_1)}{p(\\mathbf{x}|C_2)p(C_2)}\\).\nWriting this distribution in the form of the sigmoid function is convenient as it is a natural choice for many other classification models. It also has a very simple derivative which is convenient for models optimized using gradient descent.\nGiven certain choices for the class conditional densities, the posterior probabilty distribution will be a linear function of the input features:\n\\begin{equation*} \\ln p(C_k|\\mathbf{x};\\theta) = \\mathbf{w}^T \\mathbf{x} + c, \\end{equation*}\nwhere \\(\\mathbf{w}\\) is a parameter vector based on the parameters of the chosen probability distribution, and \\(c\\) is a constant term that is not dependent on the parameters. As we will see, the resulting model will take an equivalent form to the discriminative approach.\nGaussian Class Conditional Densities Let\u0026rsquo;s assume that our class conditional densities \\(p(\\mathbf{x}|C_k)\\) are Gaussian. We will additionally assume that the covariance matrices between classes are shared. This will result in linear decision boundaries. Since the conditional densities are chosen to be Gaussian, the posterior is given by\n\\begin{equation*} p(C_k|\\mathbf{x};\\theta) \\propto \\pi_k\\mathcal{N}(\\mathbf{x}|\\mathbf{\\mu}_c,\\Sigma), \\end{equation*}\nwhere \\(\\pi_k\\) is the prior probability of class \\(k\\). We choose to ignore the normalizing constant since it is not dependent on the class.\nThe class conditional density function for class \\(k\\) is given by\n\\begin{equation*} p(\\mathbf{x}|C_k;\\theta) = \\frac{1}{2\\pi^{D/2}}\\frac{1}{|\\Sigma|^{1/2}}\\exp\\Big(-\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu}_k)^T \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu}_k)\\Big). \\end{equation*}\nNow that we have a concrete function to work with, let\u0026rsquo;s go back to the simple case of two classes and define \\(a = \\ln \\frac{p(\\mathbf{x}|C_1)p(C_1)}{p(\\mathbf{x}|C_2)p(C_2)}\\). First, we rewrite \\(a\\):\n\\begin{equation*} a = \\ln p(\\mathbf{x}|C_1) - \\ln p(\\mathbf{x}|C_2) + \\ln \\frac{p(C_1)}{p(C_2)}. \\end{equation*}\nThe log of the class conditional density for a Gaussian is\n\\begin{equation*} \\ln p(\\mathbf{x}|C_k;\\mathbf{\\mu}_k,\\Sigma) = -\\frac{D}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\Sigma|-\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu}_k)^T \\Sigma^{-1} (\\mathbf{x}-\\mathbf{\\mu}_k). \\end{equation*}\nTo simplify the above result, we will group the terms that are not dependent on the class parameters since they are consant:\n\\begin{equation*} \\ln p(\\mathbf{x}|C_k;\\mathbf{\\mu}_k,\\Sigma) = -\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu}_k)^T \\Sigma^{-1} (\\mathbf{x}-\\mathbf{\\mu}_k) + c. \\end{equation*}\nObserving that this quantity takes on a quadratic form, we can rewrite the above as\n\\begin{equation*} \\ln p(\\mathbf{x}|C_k;\\mathbf{\\mu}_k,\\Sigma) = -\\frac{1}{2}\\mathbf{\\mu}_k\\Sigma^{-1}\\mathbf{\\mu}_k + \\mathbf{x}^T \\Sigma^{-1} \\mathbf{\\mu}_k -\\frac{1}{2}\\mathbf{x}^T \\Sigma^{-1}\\mathbf{x} + c. \\end{equation*}\nUsing this, we complete the definition of \\(a\\):\n\\begin{align*} a \u0026amp;= \\ln p(\\mathbf{x}|C_1) - \\ln p(\\mathbf{x}|C_2) + \\ln \\frac{p(C_1)}{p(C_2)}\\\\ \u0026amp;= -\\frac{1}{2}\\mathbf{\\mu}_1\\Sigma^{-1}\\mathbf{\\mu}_1 + \\mathbf{x}^T \\Sigma^{-1} \\mathbf{\\mu}_1 + \\frac{1}{2}\\mathbf{\\mu}_2\\Sigma^{-1}\\mathbf{\\mu}_2 - \\mathbf{x}^T \\Sigma^{-1} \\mathbf{\\mu}_2 + \\ln \\frac{p(C_1)}{p(C_2)}\\\\ \u0026amp;= \\mathbf{x}^T(\\Sigma^{-1}(\\mathbf{\\mu}_1 - \\mathbf{\\mu}_2)) - \\frac{1}{2}\\mathbf{\\mu}_1\\Sigma^{-1}\\mathbf{\\mu}_1 + \\frac{1}{2}\\mathbf{\\mu}_2\\Sigma^{-1}\\mathbf{\\mu}_2 + \\ln \\frac{p(C_1)}{p(C_2)}\\\\ \u0026amp;= (\\Sigma^{-1}(\\mathbf{\\mu}_1 - \\mathbf{\\mu}_2))^T \\mathbf{x} - \\frac{1}{2}\\mathbf{\\mu}_1\\Sigma^{-1}\\mathbf{\\mu}_1 + \\frac{1}{2}\\mathbf{\\mu}_2\\Sigma^{-1}\\mathbf{\\mu}_2 + \\ln \\frac{p(C_1)}{p(C_2)}. \\end{align*}\nFinally, we define\n\\begin{equation*} \\mathbf{w} = \\Sigma^{-1}(\\mathbf{\\mu}_1 - \\mathbf{\\mu}_2) \\end{equation*}\nand\n\\begin{equation*} w_0 = - \\frac{1}{2}\\mathbf{\\mu}_1\\Sigma^{-1}\\mathbf{\\mu}_1 - \\frac{1}{2}\\mathbf{\\mu}_2\\Sigma^{-1}\\mathbf{\\mu}_2 + \\ln \\frac{p(C_1)}{p(C_2)}. \\end{equation*}\nThus, our posterior takes on the form\n\\begin{equation*} p(C_1|\\mathbf{x};\\theta) = \\sigma(\\mathbf{w}^T \\mathbf{x} + w_0). \\end{equation*}\nMultiple Classes What if we have more than 2 classes? Recall that a generative classifier is modeled as\n\\[ p(C_k|\\mathbf{x};\\mathbf{\\theta}) = \\frac{p(C_k|\\mathbf{\\theta})p(\\mathbf{x}|C_k, \\mathbf{\\theta})}{\\sum_{k\u0026rsquo;}p(C_{k\u0026rsquo;}|\\mathbf{\\theta})p(\\mathbf{x}|C_{k\u0026rsquo;}, \\mathbf{\\theta})}. \\]\nAs stated above, \\(\\mathbf{\\pi}_k = p(C_k|\\mathbf{\\theta})\\) and \\(p(\\mathbf{x}|C_k,\\mathbf{\\theta}) = \\mathcal{N}(\\mathbf{x}|\\mathbf{\\mu}_c,\\Sigma)\\).\nFor LDA, the covariance matrices are shared across all classes. This permits a simplification of the class posterior distribution \\(p(C_k|\\mathbf{x};\\mathbf{\\theta})\\):\n\\begin{align*} p(C_k|\\mathbf{x};\\mathbf{\\theta}) \u0026amp;\\propto \\mathbf{\\pi}_k \\exp\\big(\\mathbf{\\mu}_k^T \\mathbf{\\Sigma}^{-1}\\mathbf{x} - \\frac{1}{2}\\mathbf{x}^T\\mathbf{\\Sigma}^{-1}\\mathbf{x} - \\frac{1}{2}\\mathbf{\\mu}_k\\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}_k\\big)\\\\ \u0026amp;= \\exp\\big(\\mathbf{\\mu}_k^T \\mathbf{\\Sigma}^{-1}\\mathbf{x} - \\frac{1}{2}\\mathbf{\\mu}_k\\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}_k + \\log \\mathbf{\\pi}_k \\big) \\exp\\big(- \\frac{1}{2}\\mathbf{x}^T\\mathbf{\\Sigma}^{-1}\\mathbf{x}\\big). \\end{align*}\nThe term \\(\\exp\\big(- \\frac{1}{2}\\mathbf{x}^T\\mathbf{\\Sigma}^{-1}\\mathbf{x}\\big)\\) is placed aside since it is not dependent on the class \\(k\\). When divided by the sum per the definition of \\(p(C_k|\\mathbf{x};\\mathbf{\\theta})\\), it will equal to 1.\nUnder this formulation, we let\n\\begin{align*} \\mathbf{w}_k \u0026amp;= \\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}_k\\\\ \\mathbf{b}_k \u0026amp;= -\\frac{1}{2}\\mathbf{\\mu}_k^T \\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}_k + \\log \\mathbf{\\pi}_k. \\end{align*}\nThis lets us express \\(p(C_k|\\mathbf{x};\\mathbf{\\theta})\\) as the softmax function:\n\\(p(C_k|\\mathbf{x};\\mathbf{\\theta}) = \\frac{\\exp(\\mathbf{w}_k^T\\mathbf{x}+\\mathbf{b}_k)}{\\sum_{k\u0026rsquo;}\\exp(\\mathbf{w}_{k\u0026rsquo;}^T\\mathbf{x}+\\mathbf{b}_{k\u0026rsquo;})}\\).\nMaximum Likelihood Estimation Given our formulation in the previous section, we can estimate the parameters of the model via maximum likelihood estimation. Assuming \\(K\\) classes with Gaussian class conditional densities, the likelihood function is\n\\begin{equation*} p(\\mathbf{X}|\\mathbf{\\theta}) = \\prod_{i=1}^n \\mathcal{M}(y_i|\\mathbf{\\pi})\\prod_{k=1}^K \\mathcal{N}(\\mathbf{x}_i|\\mathbf{\\mu}_k, \\mathbf{\\Sigma}_k)^{\\mathbb{1}(y_i=k)}. \\end{equation*}\nTaking the log of this function yields\n\\begin{equation*} \\ln p(\\mathbf{X}|\\mathbf{\\theta}) = \\Big[\\sum_{i=1}^n \\sum_{k=1}^K \\mathbb{1}(y_i=k)\\ln \\pi_k\\Big] + \\sum_{k=1}^K\\Big[\\sum_{i:y_i=c} \\ln \\mathcal{N}(\\mathbf{x}_n|\\mathbf{\\mu}_k, \\mathbf{\\Sigma}_k)\\Big]. \\end{equation*}\nGiven that this is a sum of two different components, we can optimize the multinomial parameter \\(\\mathbf{\\pi}\\) and the class Gaussian parameters \\((\\mathbf{\\mu}_k, \\mathbf{\\Sigma}_k)\\) separately.\nClass Prior For multinomial distributions, the class prior parameter estimation \\(\\hat{\\pi}_k\\) is easily calculated by counting the number of samples belonging to class \\(k\\) and dividing it by the total number of samples.\n\\[ \\hat{\\pi}_k = \\frac{n_k}{n} \\]\nClass Gaussians The Gaussian parameters can be calculated as discussed during the probability review. The parameter estimates are\n\\begin{align*} \\hat{\\mathbf{u}}_k \u0026amp;= \\frac{1}{n_k}\\sum_{i:y_i=k}\\mathbf{x}_i\\\\ \\hat{\\Sigma}_k \u0026amp;= \\frac{1}{n_k}\\sum_{i:y_i=k}(\\mathbf{x}_i - \\hat{\\mathbf{\\mu}}_k)(\\mathbf{x}_i - \\hat{\\mathbf{\\mu}}_k)^T \\end{align*}\nThe Decision Boundary The decision boundary between two classes can be visualized at the point when \\(p(C_k|\\mathbf{x};\\theta) = 0.5\\).\nExample See here for an example using scikit-learn.\n","date":1642831200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642831200,"objectID":"7b3b17d07ded3a7fc40ad7031aca0872","permalink":"https://ajdillhoff.github.io/notes/linear_discriminant_analysis/","publishdate":"2022-01-22T00:00:00-06:00","relpermalink":"/notes/linear_discriminant_analysis/","section":"notes","summary":"Introduction Gaussian Class Conditional Densities Maximum Likelihood Estimation Example Introduction This section covers classification from a probabilistic perspective. The discriminative approach involves a parameterized function which assigns each input vector \\(\\mathbf{x}\\) to a specific class. We will see that modeling the conditional probability distribution \\(p(C_k|\\mathbf{x})\\) grants us additional benefits while still fulfilling our original classification task.\nLet\u0026rsquo;s begin with a 2 class problem. To classify this with a generative model, we use the class-conditional densities \\(p(\\mathbf{x}|C_i)\\) and class priors \\(p(C_i)\\).","tags":null,"title":"Linear Discriminant Analysis","type":"notes"},{"authors":null,"categories":null,"content":" Introduction Picking a Model Binary Classification Multiple Classes Introduction With Linear Regression we were able to fit a model to our data in order to make inferences on unseen data points. In the examples, both the input features and observation were continuous. With logistic regression, we will use similar models to classify the data points based on their input features. We start out with the simplest approach: we assume that the data is linearly separable and can be assigned one of \\(K\\) discrete classes.\nIn the binary case, the target variable will takes on either a 0 or 1. For \\(K \u0026gt; 2\\), we will use a \\(K\\) dimensional vector that has a 1 corresponding to the class encoding for that input and a 0 for all other positions. For example, if our possible target classes were \\(\\{\\text{car, truck, person}\\}\\), then a target vector for \\(\\text{person}\\) would be \\(\\mathbf{y} = [0, 0, 1]^T\\).\nThis article will stick to a discriminative approach to logistic regression. That is, we define a discriminant function which assigns each data input \\(\\mathbf{x}\\) to a class. For a probabilistic perspective, see Linear Discriminant Analysis.\nPicking a Model We will again start with a linear model \\(y = f(\\mathbf{x}; \\mathbf{w})\\). Unlike the model used with Linear Regression, ours will need to predict a discrete class label. The logistic model is often approached by introducing the odds of an event occurring:\n\\[ \\frac{p}{1-p}, \\]\nwhere \\(p\\) is the probability of the event happening. As \\(p\\) increases, the odds of it happening increase exponentially.\nOur input \\(p\\) represents the probability in range \\((0, 1)\\) which we want to map to the real number space. To approximate this, we apply the natural logarithm to the odds.\nThe logistic model assumes a linear relationship between the linear model \\(\\mathbf{w}^T\\mathbf{x}\\) and the logit function\n\\[ \\text{logit}(p) = \\ln \\frac{p}{1-p}. \\]\nThis function maps a value in range \\((0, 1)\\) to the space of real numbers. Under this assumption, we can write\n\\[ \\text{logit}(p) = \\mathbf{w}^T\\mathbf{x}. \\]\nThis assumption is reasonable because we ultimately want to predict the probability that an event occurs. The output should then be in the range of \\((0, 1)\\). If the logit function produces output in the range of real numbers, as does our linear model \\(\\mathbf{w}^T\\mathbf{x}\\), then we ultimately want a function that maps from the range of real numbers to to \\((0, 1)\\).\nWe can achieve this using the inverse of the logit function, the logistic sigmoid function. It is defined as\n\\begin{equation*} \\sigma(z) = \\frac{1}{1 + \\exp(-z)}, \\end{equation*}\nwhere \\(z = \\mathbf{w}^T\\mathbf{x}\\).\nThe reason for this choice becomes more clear when plotting the function, as seen below.\nFigure 1: The logistic sigmoid function. Source: Wikipedia The inputs on the \\(x\\) axis are clamped to values between 0 and 1. It is also called a squashing function because of this property. This form is also convenient and arises naturally in many probabilistic settings. With this nonlinear activation function, the form of our model becomes\n\\begin{equation*} f(\\mathbf{x};\\mathbf{w}) = h(\\mathbf{w}^T\\mathbf{x}), \\end{equation*}\nwhere \\(h\\) is our choice of activation function.\nThe logistic sigmoid function also has a convenient derivative, which is useful when solving for the model parameters via gradient descent.\n\\[ \\frac{d}{dx} = \\sigma(x)(1 - \\sigma(x)) \\]\nBinary Classification Consider a simple dataset with 2 features per data sample. Our goal is to classify the data as being one of two possible classes. For now, we\u0026rsquo;ll drop the activation function so that our model represents a line that separates both groups of data.\nFigure 2: Two groups of data that are very clearly linearly separable. In the binary case, we are approximating \\(p(C_1|\\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x})\\). Then \\(p(C_2|\\mathbf{x}) = 1 - p(C_1| \\mathbf{x})\\).\nThe parameter vector \\(\\mathbf{w}\\) is orthogonal to the decision boundary that separates the two classes. The model output is such that \\(f(\\mathbf{x};\\mathbf{w}) = 0\\) when \\(\\mathbf{x}\\) lies on the decision boundary. If \\(f(\\mathbf{x};\\mathbf{w}) \\geq 0\\) then \\(\\mathbf{x}\\) is assigned to class 1. It is assigned to class 2 otherwise. Since we originally stated that the model should predict either a 0 or 1, we can use the model result as input to the Heaviside step function.\nFitting the Model via Maximum Likelihood Let \\(y_i \\in \\{0, 1\\}\\) be the target for binary classification and \\(\\hat{y}_i \\in (0, 1)\\) be the output of a logistic regression model. The likelihood function is\n\\[ p(\\mathbf{y}|\\mathbf{w}) = \\prod_{i=1}^n \\hat{y}_i^{y_i}(1 - \\hat{y}_i)^{1 - y_i}. \\]\nLet\u0026rsquo;s briefly take a look at \\(\\hat{y}_i^{y_i}(1 - \\hat{y}_i)^{1 - y_i}\\) to understand the output when the model correctly predicts the \\(i^{\\text{th}}\\) sample or not. Since the output is restricted within the range \\((0, 1)\\), the model will never produce 0 or 1.\nIf the target \\(y_i = 0\\), then we can evaluate the subexpression \\(1 - \\hat{y}_i\\). In this case, the likelihood increases as \\(\\hat{y}_i\\) decreases.\nIf the target \\(y_i = 1\\), then we evaluate the subexpression \\(\\hat{y}_i\\).\nWhen fitting this model, we want to define an error measure based on the above function. This is done by taking the negative logarithm of \\(p(\\mathbf{y}|\\mathbf{w})\\).\n\\[ E(\\mathbf{w}) = -\\ln p(\\mathbf{y}|\\mathbf{w}) = -\\sum_{i=1}^n y_i \\ln \\hat{y}_i + (1 - y_i) \\ln (1 - \\hat{y}_i) \\]\nThis function is commonly referred to as the cross-entropy function.\nIf we use this as an objective function for gradient descent with the understanding that \\(\\hat{y}_i = \\sigma(\\mathbf{w}^T \\mathbf{x})\\), then the gradient of the error function is\n\\[ \\nabla E(\\mathbf{w}) = \\sum_{i=1}^n (\\hat{y}_i - y_i)\\mathbf{x}_i. \\]\nThis results in a similar update rule as linear regression, even though the problem itself is different.\nMeasuring Classifier Performance How do we determine how well our model is performing?\nWe will use L1 loss because it works well with discrete outputs. L1 loss is defined as\n\\begin{equation*} L_1 = \\sum_{i}|\\hat{y}_i - y_i|, \\end{equation*}\nwhere \\(\\hat{y}_i\\) is the ground truth corresponding to \\(\\mathbf{x}_i\\) and \\(y_i\\) is the output of our model. We can further normalize this loss to bound it between 0 and 1. Either way, a loss of 0 will indicate 100% classification accuracy.\nMultiple Classes In multiclass logistic regression, we are dealing with target values that can take on one of \\(k\\) values \\(y \\in \\{1, 2, \\dots, k\\}\\). If our goal is to model the distribution over \\(K\\) classes, a multinomial distribution is the obvious choice. Let \\(p(y|\\mathbf{x};\\theta)\\) be a distribution over \\(K\\) numbers \\(w_1, \\dots, w_K\\) that sum to 1. Our parameterized model cannot be represented exactly by a multinomial distribution, so we will derive it so that it satisfies the same constraints.\nWe can start by introducing \\(K\\) parameter vectors \\(\\mathbf{w}_1, \\dots, \\mathbf{w}_K \\in \\mathbb{R}^{d}\\), where \\(d\\) is the number of input features. Then each vector \\(\\mathbf{w}_k^T \\mathbf{x}\\) represents \\(p(C_k | \\mathbf{x};\\mathbf{w}_k)\\). We need to squash each \\(\\mathbf{w}_k^T \\mathbf{x}\\) so that the output sums to 1.\nThis is accomplished via the softmax function:\n\\[ p(C_k|\\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_k^T \\mathbf{x})}{\\sum_{j} \\exp(\\mathbf{w}_j^T \\mathbf{x})}. \\]\nMaximum Likelihood The target vector for each sample is \\(\\mathbf{y}_i \\in \\mathbb{R}^{k}\\). Likewise, the output vector \\(\\hat{\\mathbf{y}}_i\\) also has \\(k\\) elements.\nThe maximum likelihood function for the multiclass setting is given by\n\\[ p(\\mathbf{Y}|\\mathbf{W}) = \\prod_{i=1}^n \\prod_{k=1}^K p(C_k|\\mathbf{x}_i)^{y_{ik}} = \\prod_{i=1}^n \\prod_{k=1}^K \\hat{y}_{ik}^{y_{ik}}. \\]\n\\(\\mathbf{Y} \\in \\mathbb{R}^{n \\times K}\\) is a matrix of all target vectors in the data set. As with the binary case, we can take the negative logarithm of this function to produce an error function.\n\\[ E(\\mathbf{W}) = -\\ln p(\\mathbf{Y}|\\mathbf{W}) = -\\sum_{i=1}^n \\sum_{k=1}^K y_{ik} \\ln \\hat{y}_{ik} \\]\nThis is the cross-entropy function for multiclass classification.\nThe gradient of this function is given as\n\\[ \\nabla_{\\mathbf{w}_j}E(\\mathbf{W}) = \\sum_{i=1}^n (\\hat{y}_{ij} - y_{ij}) \\mathbf{x}_i. \\]\nPart of your first assignment will be to work through the derivation of this function. It is standard practice at this point, but it is highly valuable to understand how the result was produced.\n","date":1642831200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642831200,"objectID":"91f03ca8739733727b9c6b475ec22353","permalink":"https://ajdillhoff.github.io/notes/logistic_regression/","publishdate":"2022-01-22T00:00:00-06:00","relpermalink":"/notes/logistic_regression/","section":"notes","summary":"Introduction Picking a Model Binary Classification Multiple Classes Introduction With Linear Regression we were able to fit a model to our data in order to make inferences on unseen data points. In the examples, both the input features and observation were continuous. With logistic regression, we will use similar models to classify the data points based on their input features. We start out with the simplest approach: we assume that the data is linearly separable and can be assigned one of \\(K\\) discrete classes.","tags":null,"title":"Logistic Regression","type":"notes"},{"authors":null,"categories":null,"content":" Resources Introduction Definition Forward Pass Activation Functions Multi-Class Classification Backpropagation Non-Convex Optimization Resources https://playground.tensorflow.org/ Introduction Previously, we studied the Perceptron and saw that while it made for a simple linear classifier, it is severely limited to problems that are already linearly separable. This limitation was resolved by introduding a hidden layer with multiple perceptron units, aptly named Multi-Layer Perceptrons.\nIn this series, we will explore the more general method of neural networks. We will see that even a network of only two layers can approximate any continuous functional mapping to arbitrary accuracy. Through a discussion about network architectures, activation functions, and backpropagation, we will understand and use neural networks to resolve a large number of both classification and regression tasks.\nDefinition We will take an abstract view of neural networks in which any formulation of a neural network defines a nonlinear mapping from an input space to some output space. This implies that our choice of activation function must be nonlinear. The function we create will be parameterized by some weight matrix \\(W\\). Thus, any neural network can be simply formulated as\n\\[ f(\\mathbf{x};W). \\]\nFigure 1: General neural network diagram. A neural network is in part defined by its layers, the number of nodes in each layer, the choice of activation function, and the choice of loss function.\nEach layer has a number of weights equal to the number of input nodes times the number of output nodes. This is commonly represented as a weight matrix \\(W\\).\nThe network produces output through the forward pass and computes the gradients with respect to that output in the backwards pass.\nForward Pass Computing the output is done in what is called the forward pass.\nOur neural network function takes in an input \\(\\mathbf{x} \\in \\mathbb{R}^D\\), where \\(D\\) is the number of features in our input space. Each output node \\(a_j\\) in a hidden layer \\(h_l\\) has a corresponding weight vector \\(\\mathbf{w}_j^{(l)}\\). The intermediate output of a hidden layer \\(h_l\\) is a linear combination of the weights and the input followed by some nonlinear function. Node \\(a_j\\) of a hidden layer is computed as\n\\[ a_j = \\sum_{i=1}^d w_{ji}^{(l)} x_{i} + w_{j0}^{(l)}. \\]\nAs with Linear Regression, we will prepend a constant 1 to our input so that the computation is simply\n\\[ a_{j} = \\sum_{i=0}^d w_{ji}^{(i)} x_i = \\mathbf{w}_j^T \\mathbf{x}. \\]\nThe final output of the hidden layer is \\(a_j\\) transformed by a nonlinear function \\(g\\) such that\n\\[ z_j = g(a_j). \\]\nWe can combine all weight vectors for each hidden layer node into a weight matrix \\(W \\in \\mathbb{R}^{n \\times d}\\), where \\(n\\) is the number of nodes in the layer and \\(d\\) is the number of input features such that\n\\begin{equation*} W = \\begin{bmatrix} \\mathbf{w}_1^T\\\\ \\vdots\\\\ \\mathbf{w}_n^T\\\\ \\end{bmatrix}. \\end{equation*}\nThen the output of the hidden layer can be computed as\n\\[ \\mathbf{a} = W\\mathbf{x}. \\]\nIf you instead wanted to separate the bias term, this would be\n\\[ \\mathbf{a} = W\\mathbf{x} + \\mathbf{b}. \\]\nUsing the notation to specify the individual layer, we can write the output of a full network. Let \\(W^{(l)} \\in \\mathbb{R}^{n_{l} \\times n_{l-1}}\\) be the weights for layer \\(l\\) which have \\(n_{l-1}\\) input connections and \\(n_{l}\\) output nodes. The activation function for layer \\(l\\) is given by \\(g^{(l)}\\).\nThe complete forward pass of the network is computed by repeating the following step for all layers:\n\\[ \\mathbf{z}^{(l)} = g^{(l)}(\\mathbf{a}^{(l-1)}), \\]\nwhere\n\\[ \\mathbf{a}^{(l-1)} = W^{(l-1)}\\mathbf{z}^{(l-1)} + \\mathbf{b}^{(l-1)}. \\]\nOnce all layers have been computed, then the output of the last layer, \\(\\hat{\\mathbf{y}}^{(L)}\\) is used as the final output of the model. For training, this is compared with some ground truth label \\(\\mathbf{y}\\) using a loss function \\(\\mathcal{L}\\):\n\\[ \\mathcal{L}(\\hat{\\mathbf{y}}, \\mathbf{y}). \\]\nXOR Example Consider the XOR problem. A single Perceptron was unable to solve that problem. However, adding a hidden layer and forming a multi-layer perceptron network allowed for a more complex decision boundary. Consider the network below and produce the output given all combinations of binary input: \\(\\{(0, 0), (0, 1), (1, 0), (1, 1)\\}\\).\nFigure 2: A network with 1 hidden layer that computes XOR. Source: https://athitsos.utasites.cloud/courses/cse4309_fall2021/lectures/09a_neural_networks.pdf Activation Functions Sigmoid Function \\[ g(x) = \\frac{1}{1 + e^{-x}} \\]\nThe logistic sigmoid function serves two purposes. First, it allows the output of the neuron to be interpreted as a posterior probability. Note that this is not actually a probability. Second, it is a continuous function for which the derivative can be computed:\n\\[ g\u0026rsquo;(x) = g(x)(1 - g(x)). \\]\nHyperbolic Tangent Function \\[ \\tanh x = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} \\]\nThe hyperbolic tangent function maps input to a range of \\((-1, 1)\\).\nThe derivative is calculated as\n\\[ \\frac{d}{dx} \\tanh x = 1 - \\tanh^2 x. \\]\nFigure 3: Hyperbolic Tangent Function. Source: Wolfram Key Terms\nbias activation function Neurons fire after input reaches some threshold. Differential activation functions necessary for backpropagation. Multi-class learning How long to train? Weight decay How many layers versus how many nodes per layer? Training Data split (train/test/val) Multi-Class Classification Consider an output layer of a network with \\(k\\) nodes. Each of these nodes represents a decision node for a one-versus-all classifier. For a classification task, we have to think about whether or not the sum of squares loss function works.\nAs far as activation functions go, the logistic sigmoid function is a good way to produce some interpretation of probability. If we treat every output node as its own one versus all classifier, then a logistic sigmoid at the end of each one would indicate the \u0026ldquo;probability\u0026rdquo; that node \\(k\\) assigns class \\(k\\).\nHow do we formulate this in a neural network?\nThe number of nodes in the output layer will be \\(K\\), the number of classes. Since the output of each node produces a value in range \\((0, 1)\\), we want to construct a target value that works with this. Instead of assigning an integer to each class label (e.g. 1 for class 2, 2 for class 3, etc.), we will encode the target label as a \\(K\\) dimensional vector. For example, if our class label is for the class 1, then the corresponding target vector will be\n\\begin{equation*} \\mathbf{t} = \\begin{bmatrix} 1\\\\ 0\\\\ \\vdots\\\\ 0 \\end{bmatrix}. \\end{equation*}\nSince the output of our final layer is also a \\(K\\) dimensional vector, we can compare the two using some loss function.\nBackpropagation Given a series of linear layers with nonlinear activation functions, how can we update the weights across the entire network?\nThe short answer is through the chain rule of differentiation. Let\u0026rsquo;s explore this through an example.\nAfter constructing some series of hidden layers with an arbitrary number of nodes, we will pick an error function that provides a metric of how our network performs on a given regression or classification task. This loss is given by \\(\\mathcal{L}\\).\nNeural networks are traditionally trained using gradient descent. The goal is to optimize the weights such that they result in the lowest loss, or error. This is also why our choice of loss function is important.\n\\[ \\mathbf{W}^* = \\text{argmin}\\frac{1}{n}\\sum_{i=1}^n \\mathcal{L}(f(\\mathbf{x}^{(i)}; \\mathbf{W}), \\mathbf{y}^{(i)}) \\]\nWe first compute the gradients of the network with respect to the weights and biases. Then, we use those gradients to update our previous values for the weights and biases.\nA Simple Example We will first look at computing these gradients on a smaller network for binary classification with 1 hidden layer and 1 output layer. The loss function is defined using the binary cross-entropy function:\n\\[ \\mathcal{L}(\\hat{\\mathbf{y}}, \\mathbf{y}) = -\\mathbf{y}\\log \\hat{\\mathbf{y}} - (1 - \\mathbf{y}) \\log (1 - \\hat{\\mathbf{y}}) \\]\nThe network\u0026rsquo;s output is computed in sequence following\n\\begin{align*} \\mathbf{a}^{(1)} \u0026amp;= W^{(1)}\\mathbf{x} + \\mathbf{b}^{(1)}\\\\ \\mathbf{z}^{(1)} \u0026amp;= g^{(1)}(\\mathbf{a}^{(1)})\\\\ \\mathbf{a}^{(2)} \u0026amp;= W^{(2)}\\mathbf{z}^{(1)} + \\mathbf{b}^{(2)}\\\\ \\mathbf{z}^{(2)} \u0026amp;= g^{(2)}(\\mathbf{a}^{(2)})\\\\ \\end{align*}\nThe goal is to compute the gradients for all weights and biases:\n\\[ \\frac{d\\mathcal{L}}{dW^{(1)}},\\quad \\frac{d\\mathcal{L}}{d\\mathbf{b}^{(1)}},\\quad \\frac{d\\mathcal{L}}{dW^{(2)}},\\quad \\frac{d\\mathcal{L}}{d\\mathbf{b}^{(2)}}. \\]\nStarting with the weights of the output layer:\n\\[ \\frac{d\\mathcal{L}}{dW^{(2)}} = \\frac{d\\mathcal{L}}{d\\mathbf{z}^{(2)}} \\frac{d\\mathbf{z}^{(2)}}{d\\mathbf{a}^{(2)}} \\frac{d\\mathbf{a}^{(2)}}{dW^{(2)}}. \\]\nThe first step is to compute the partial gradient of the loss function with respect to its input \\(\\hat{\\mathbf{y}} = \\mathbf{z}^{(2)}\\):\n\\[ \\frac{d\\mathcal{L}}{d\\mathbf{z}^{(2)}} = \\frac{\\mathbf{z}^{(2)} - \\mathbf{y}}{\\mathbf{z}^{(2)}(1 - \\mathbf{z}^{(2)})}. \\]\nNext, compute the gradient of the last layer\u0026rsquo;s activation function with respect to its input \\(\\mathbf{a}^{(2)}\\):\n\\[ \\frac{d\\mathbf{z}^{(2)}}{d\\mathbf{a}^{(2)}} = \\mathbf{z}^{(2)}(1 - \\mathbf{z}^{(2)}). \\]\nFinally, we compute \\(\\frac{d\\mathbf{a}^{(2)}}{dW^{(2)}}\\): \\[ \\frac{d\\mathbf{a}^{(2)}}{dW^{(2)}} = \\mathbf{z}^{(1)}. \\]\nPutting all of this together yields\n\\begin{align*} \\frac{d\\mathcal{L}}{dW^{(2)}} \u0026amp;= \\frac{\\mathbf{z}^{(2)} - \\mathbf{y}}{\\mathbf{z}^{(2)}(1 - \\mathbf{z}^{(2)})} * \\mathbf{z}^{(2)}(1 - \\mathbf{z}^{(2)}) * \\mathbf{z}^{(1)}\\\\ \u0026amp;= \\mathbf{z}^{(1)} (\\mathbf{z}^{(2)} - \\mathbf{y}). \\end{align*}\nNon-Convex Optimization Optimizing networks with non-linearities produces a non-convex landscape. Depending on our choice of optimization algorithm and initial starting point, the algorithm will most likely get \u0026ldquo;stuck\u0026rdquo; in some local minimum. Consider the figure below produced by (Li et al. 2017).\nFigure 4: Loss surface of ResNet-56 (Li et al.) References ","date":1642831200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642831200,"objectID":"16c8d84377f70f04087cbe417e84cd5f","permalink":"https://ajdillhoff.github.io/notes/neural_networks/","publishdate":"2022-01-22T00:00:00-06:00","relpermalink":"/notes/neural_networks/","section":"notes","summary":"Resources Introduction Definition Forward Pass Activation Functions Multi-Class Classification Backpropagation Non-Convex Optimization Resources https://playground.tensorflow.org/ Introduction Previously, we studied the Perceptron and saw that while it made for a simple linear classifier, it is severely limited to problems that are already linearly separable. This limitation was resolved by introduding a hidden layer with multiple perceptron units, aptly named Multi-Layer Perceptrons.\nIn this series, we will explore the more general method of neural networks.","tags":null,"title":"Neural Networks","type":"notes"},{"authors":null,"categories":null,"content":" Introduction The Perceptron Learning Algorithm Limitations of Single-Layer Perceptrons Introduction A popular example of a Logistic Regression model is the perceptron. Proposed by Frank Rosenblatt in 1962, the perceptron is defined as a generalized linear model:\n\\begin{equation*} f(\\mathbf{w}^T\\mathbf{\\phi}(\\mathbf{x})), \\end{equation*}\nwhere \\(\\phi\\) is a basis function and \\(f\\) is a stepwise function with the form\n\\begin{equation*} f(a) = \\begin{cases} 1, a \\geq 0\\\\ -1, a \u0026lt; 0 \\end{cases} \\end{equation*}\nTo match this, the targets will take on a value of either 1 or -1.\nThe Perceptron Learning Algorithm Based on the stepwise function, the parameters \\(\\mathbf{w}\\) should lead to outputs above 0 for one class and outputs below 0 for the other. There is 0 error with a correct classification.\nThe original formulation does not work well with gradient based optimization methods due to the fact that the derivative of the stepwise function is 0 almost everyone. To get around this, the perceptron criterion is used:\n\\begin{equation*} E(\\mathbf{w}) = -\\sum_i \\mathbf{w}^T\\phi(\\mathbf{x}_i)\\hat{y}_i, \\end{equation*}\nwhere \\(\\hat{y}_i\\) is the target class (either 1 or -1).\nAn incorrect classification will minimize \\(\\mathbf{w}^T\\phi_i y_i\\). We can consider this loss only for misclassified patterns.\nUpdate Steps\nFor each input, evaluate \\(f(\\mathbf{w}^T\\phi(\\mathbf{x}_i))\\). For incorrect classifications Add \\(\\phi(\\mathbf{x}_i)\\) to \\(\\mathbf{w}\\) estimate for class 1 Subtract \\(\\phi(\\mathbf{x}_i)\\) from \\(\\mathbf{w}\\) for class 2. Does not necessarily get better each step, but guaranteed to converge.\nLimitations of Single-Layer Perceptrons Single layer perceptrons are limited to solving linearly separable patterns. As we have seen with a few datasets now, expecting our data to be linearly separable is wishful thinking. Minsky and Papert exposed this limitation in their book Perceptrons: an introduction to computational geometry.\nConsider the example XOR problem. It is a binary classification problem consisting of 4 data points. It is not linearly separable as seen in the figure below.\nFigure 1: XOR cannot be solved with a linear classifier. This is the result of using only a single Perceptron. What if we added another perceptron? A single perceptron computes \\(\\mathbf{w}^T + b\\). It is important to transform the first perceptron\u0026rsquo;s output using a non-linear activation function, otherwise the output would be similar to that of a logistic regression model. The updated \u0026ldquo;network\u0026rdquo; is shown below.\nFigure 2: A 2 layer perceptron for which each layer has a single node. The result is the same! The original input in 2D is transformed to a single dimensional output. This is then used as input to the second perceptron. The result is a linear decision boundary followed by another linear decision boundary. What if we used 2 perceptrons in the first layer? The idea is that using two linear decision boundaries in a single space would allow our model to create a more complex boundary. The updated network is shown below.\nFigure 3: A 2 layer perceptron for which the first layer has 2 nodes. This effectively solves the XOR problem! Since each node computes a linear combination of the input, we can visualize two decision boundaries with respect to the input space.\nFigure 4: Visualization of input space. Similarly, we can visualize how the data points are transformed by visualizing the space of the output layer.\nFigure 5: Output space ","date":1642831200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642831200,"objectID":"05741d6538d42b28c94ed3a24f23ee36","permalink":"https://ajdillhoff.github.io/notes/perceptron/","publishdate":"2022-01-22T00:00:00-06:00","relpermalink":"/notes/perceptron/","section":"notes","summary":"Introduction The Perceptron Learning Algorithm Limitations of Single-Layer Perceptrons Introduction A popular example of a Logistic Regression model is the perceptron. Proposed by Frank Rosenblatt in 1962, the perceptron is defined as a generalized linear model:\n\\begin{equation*} f(\\mathbf{w}^T\\mathbf{\\phi}(\\mathbf{x})), \\end{equation*}\nwhere \\(\\phi\\) is a basis function and \\(f\\) is a stepwise function with the form\n\\begin{equation*} f(a) = \\begin{cases} 1, a \\geq 0\\\\ -1, a \u0026lt; 0 \\end{cases} \\end{equation*}\nTo match this, the targets will take on a value of either 1 or -1.","tags":null,"title":"Perceptron","type":"notes"},{"authors":null,"categories":null,"content":" Introduction Probabilistic Interpretation Solving with Normal Equations Another Approach to Normal Equations Fitting Polynomials Linear Basis Functions Introduction Given a dataset of observations \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}\\), where \\(n\\) is the number of samples and \\(d\\) represents the number of features per sample, and corresponding target values \\(\\mathbf{Y} \\in \\mathbb{R}^n\\), create a simple prediction model which predicts the target value \\(\\mathbf{y}\\) given a new observation \\(\\mathbf{x}\\). The classic example in this case is a linear model, a function that is a linear combination of the input features and some weights \\(\\mathbf{w}\\).\nFigure 1: Plot of univariate data where the (x) values are features and (y) are observations. The generated data is plotted above along with the underlying true function that was used to generate it. If we already know what the true function is, our job is done. Suppose that we only have the data points (in blue). How do we go about modelling it? It is reasonable to first visualize the data and observe that it does follow a linear pattern. Thus, a linear model would be a decent model to choose.\nIf the data followed a curve, we may decide to fit a polynomial. We will look at an example of that later on. For now, let\u0026rsquo;s formalize all of the information that we have.\n\\((\\mathbf{x}, \\mathbf{y})\\) - Data points from the original dataset. Generally, \\(\\mathbf{x}\\) is a vector of features and \\(\\mathbf{y}\\) is the target vector. In our simple dataset above, these are both scalar values. \\(\\mathbf{w} = (w_0, w_1)\\) - Our model parameters. Comparing to the equation \\(y = mx + b\\), \\(w_0\\) is our bias term and \\(w_1\\) is our slope parameter. Making Predictions Given \\(\\mathbf{w}\\), we can make a prediction for a new data sample \\(\\mathbf{x} = x_1\\).\n\\[ h(\\mathbf{x}; \\mathbf{w}) = w_0 + w_1 x_1 \\]\nNote that the bias term is always added to the result. We can simplify this into a more general form by appending a constant 1 (s.t. \\(x_0 = 1\\)) to each of our samples such that \\(\\mathbf{x} = (1, x_1, \u0026hellip;, x_d)\\). Then, the general linear model becomes\n\\[ h(\\mathbf{x}; \\mathbf{w}) = \\sum_{i=0}^{d} w_i x_i = \\mathbf{w}^T \\mathbf{x}. \\]\nIf our data happened to have more than 1 feature, it would be easy enough to model it appropriately using this notation.\nDetermining Fitness If we really wanted to, we could fit our model by plotting it and manually adjusting the weights until our model looked acceptable by some qualitative standard. Fortunately we won\u0026rsquo;t be doing that. Instead, we will use a quantitative measurement that provides a metric of how well our current parameters fit the data.\nFor this, we use a cost function or loss function. The most common one to use for this type of model is the least-squares function:\n\\[ J(\\mathbf{w}) = \\frac{1}{2}\\sum_{i=1}^{n}(h(\\mathbf{x}_{i};\\mathbf{w}) - \\mathbf{y}_{i})^2. \\]\nStochastic Gradient Descent Depending on the random initialization of parameters, our error varies greatly. We can observe that no matter what the chose parameters are, there is no possible way we can achieve an error of 0. The best we can do is minimize this error:\n\\[ \\min_{\\mathbf{w}} J(\\mathbf{w}). \\]\nFor this, we rely on stochastic gradient descent. The basic idea is as follows:\nBegin with an initial guess for \\(\\mathbf{w}\\). Compare the prediction for sample \\(\\mathbf{x}^{(i)}\\) with its target \\(\\mathbf{y}^{(i)}\\). Update \\(\\mathbf{w}\\) based on the comparison in part 2. Repeat steps 2 and 3 on the dataset until the loss has converged. Steps 1, 3, and 4 are easy enough. What about step 2? How can we possibly know how to modify \\(\\mathbf{w}\\) such that \\(J(\\mathbf{w})\\) will decrease? By computing the gradient \\(\\frac{d}{d\\mathbf{w}}J(\\mathbf{w})\\)! How will we know when we have arrived at a minima? When \\(\\nabla J(\\mathbf{w}) = 0\\).\n\\begin{align*} \\frac{d}{d\\mathbf{w}}J(\\mathbf{w}) \u0026amp;= \\frac{d}{d\\mathbf{w}}\\frac{1}{2}(h(\\mathbf{x}_{i};\\mathbf{w}) - \\mathbf{y}_{i})^2\\\\ \u0026amp;= 2 \\cdot \\frac{1}{2}(h(\\mathbf{x}_{i};\\mathbf{w}) - \\mathbf{y}_{i}) \\cdot \\frac{d}{d\\mathbf{w}} (h(\\mathbf{x}_{i};\\mathbf{w}) - \\mathbf{y}_{i})\\\\ \u0026amp;= (h(\\mathbf{x}_{i};\\mathbf{w}) - \\mathbf{y}_{i}) \\cdot \\frac{d}{d\\mathbf{w}} (\\mathbf{w}^T \\mathbf{x}_{i} - \\mathbf{y}_{i})\\\\ \u0026amp;= (h(\\mathbf{x}_{i};\\mathbf{w}) - \\mathbf{y}_{i}) \\mathbf{x}_{i} \\end{align*}\nThe gradient represents the direction of greatest change for a function evaluated With this gradient, we can use an update rule to modify the previous parameter vector \\(\\mathbf{w}\\):\n\\[ \\mathbf{w}_{t+1} = \\mathbf{w}_{t} - \\alpha \\sum_{i=1}^{n} (h(\\mathbf{x}_{i};\\mathbf{w}_{t}) - \\mathbf{y}_{i}) \\mathbf{x}_{i}. \\]\nHere, \\(\\alpha\\) is an update hyperparameter that allows us to control how big or small of a step our weights can take with each update. In general, a smaller value will be more likely to get stuck in local minima. However, too large of a value may never converge to any minima.\nAnother convenience of this approach is that it is possible to update the weights based on a single sample, batch of samples, or the entire dataset. This sequential process makes optimization using very large dataset feasible.\nProbabilistic Interpretation \u0026ldquo;Probability theory is nothing but common sense reduced to calculation.\u0026rdquo; - Pierre-Simon Laplace\nRecall Bayes\u0026rsquo; theorem:\n\\[ p(\\mathbf{w}|\\mathbf{X}) = \\frac{p(\\mathbf{X}|\\mathbf{w})p(\\mathbf{w})}{p(\\mathbf{X})}. \\]\nThat is, the posterior probability of the weights conditioned on the observered data \\(\\mathbf{X}\\) is equal to the likelihood of the observed data given the times the prior distribution. This base notation doesn\u0026rsquo;t line up well with our problem. For our problem, we have observations \\(\\mathbf{Y}\\) which are dependent on the input features \\(\\mathbf{X}\\):\n\\[ p(\\mathbf{w}|\\mathbf{X}, \\mathbf{Y}) = \\frac{p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}) p(\\mathbf{w}|\\mathbf{X})}{p(\\mathbf{Y}|\\mathbf{X})}, \\]\nwhere \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}\\) and \\(\\mathbf{Y} \\in \\mathbb{R}^n\\).\nThe choice of least squares also has statistical motivations. As discussed previously, we are making a reasonable assumption that there is some relationship between the features of the data and the observed output. This is typically modeled assume\n\\[ \\hat{\\mathbf{Y}} = f(\\mathbf{X}) + \\epsilon. \\]\nHere, \\(\\epsilon\\) is a random error term that is independent of \\(\\mathbf{X}\\) and has 0 mean. This term represents any random noise that occurs either naturally or from sampling. It also includes any effects that are not properly captured by \\(f\\). Rearranging the terms of this equation to solve for \\(\\epsilon\\) allows us to define the discrepencies in the model:\n\\[ \\mathbf{\\epsilon}_i = h(\\mathbf{x}_{i}; \\mathbf{w}) - \\mathbf{y}_{i}. \\]\nIf we assume that these discrepancies are independent and identically distributed with variance \\(\\sigma^2\\) and Gaussian PDF \\(f\\), the likelihood of observations \\(\\mathbf{y}^{(i)}\\) given parameters \\(\\mathbf{w}\\) is\n\\[ p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma) = \\prod_{i=1}^{n} f(\\epsilon_i; \\sigma), \\]\nwhere\n\\[ f(\\epsilon_i; \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big(-\\frac{\\epsilon^2}{2\\sigma^2}\\Big). \\]\nThis new parameter changes our original distribution function to\n\\[ p(\\mathbf{w}|\\mathbf{X}, \\mathbf{Y}, \\sigma) = \\frac{p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma) p(\\mathbf{w}|\\mathbf{X}, \\sigma)}{p(\\mathbf{Y}|\\mathbf{X}, \\sigma)}. \\]\nTwo things to note before moving on. First, the prior \\(p(\\mathbf{Y}|\\mathbf{X}, \\sigma)\\) is a normalizing constant to ensure that the posterior is a valid probability distribution. Second, if we assume that all value for \\(\\mathbf{w}\\) are equally likely, then \\(p(\\mathbf{w}|\\mathbf{x}, \\sigma)\\) also becomes constant. This is a convenient assumption which implies that maximizing the posterior is equivalent to maximizing the likelihood function.\nWith that out of the way, we can focus solely on the likelihood function. Expanding out the gaussian PDF \\(f\\) yields\n\\[ p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma) = -\\frac{n}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(h(\\mathbf{x}_{i};\\mathbf{w}) - \\mathbf{y}_{i})^2\\Big). \\]\nWe can see that maximizing \\(p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma)\\) is the same as minimizing the sum of squares. In practice, we use the negative log of the likelihood function since the negative logarithm is monotonically decreasing.\nSolving with Normal Equations You may have studied the normal equations when you took Linear Algebra. The normal equations are motivated by finding approximate solutions to \\(A\\mathbf{x} = \\mathbf{b}\\). Most of the earlier part of linear algebra courses focus on finding exact solutions by solving systems of equations using Gaussian elimination (row reduction). Approximate solutions can be found by projecting the observed data points \\(\\mathbf{b}\\) onto the column space of \\(A\\) and solving \\(A \\mathbf{x} = \\hat{\\mathbf{b}}\\), where \\(\\hat{\\mathbf{b}} = \\text{proj}_{\\text{Col} A}\\mathbf{b}\\). Then, \\(\\mathbf{b} - \\hat{\\mathbf{b}}\\) represents a vector orthogonal to \\(\\text{Col}A\\).\nSince each column vector of \\(A\\) is orthogonal to \\(\\mathbf{b} - \\hat{\\mathbf{b}}\\), the dot product between them should be 0. Rewriting this, we get\n\\begin{aligned} A^T(\\mathbf{b} - A\\mathbf{x}) \u0026amp;= \\mathbf{0}\\\\ A^T \\mathbf{b} - A^T A \\mathbf{x} \u0026amp;= \\mathbf{0}. \\end{aligned}\nThis means that each least-squares solution of \\(A\\mathbf{x} = \\mathbf{b}\\) satisfies\n\\[ A^T A \\mathbf{x} = A^T \\mathbf{b}. \\]\nExample Let\u0026rsquo;s take our univariate problem of \\((\\mathbf{x}, \\mathbf{y})\\) pairs. To use the normal equations to solve the least squares problem, we first change the notation just a bit as not confuse our data points and our parameters:\n\\[ \\mathbf{X}^T \\mathbf{X} \\beta = \\mathbf{X}^T \\mathbf{y} \\]\nCreate the design matrix \\(\\mathbf{X}\\) where each row represents the the \\(\\mathbf{x}\\) values. Recall that even though we only have 1 feature for \\(\\mathbf{x}\\), we append the bias constant as \\(x_0 = 1\\) to account for the bias parameter. \\(\\mathbf{X}\\) is then\n\\begin{equation*} \\mathbf{X} = \\begin{bmatrix} x_0^{(0)} \u0026amp; x_1^{(0)}\\\\ x_0^{(1)} \u0026amp; x_1^{(1)}\\\\ \\vdots \u0026amp; \\vdots \\\\ x_0^{(n)} \u0026amp; x_1^{(n)} \\end{bmatrix}. \\end{equation*}\nThe parameter vector is\n\\begin{equation*} \\beta = \\begin{bmatrix} \\beta_0\\\\ \\beta_1 \\end{bmatrix}. \\end{equation*}\nThe observed values are packed into \\(\\mathbf{y}\\). We can then solve for \\(\\beta\\) using any standard solver:\n\\[ \\beta = (\\mathbf{X}^T \\mathbf{X})^{-1}X^T \\mathbf{y}. \\]\nRank-Deficient matrices In the event that the matrix \\(\\mathbf{X}^T \\mathbf{X}\\) is singular, then its inverse cannot be computed. This implies that one or more of the features is a linear combination of the others.\nThis can be detected by checking the rank of \\(\\mathbf{X}^T \\mathbf{X}\\) before attempting to compute the inverse. You can also determine which features are redundant via Gaussian elimination. The columns in the reduced matrix that do not have a pivot entry are redundant.\nAnother Approach to Normal Equations We can arrive at the normal equations by starting at the probabilistic perspective. Recall the likelihood function\n\\[ p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma) = -\\frac{n}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(h(\\mathbf{x}_{i};\\mathbf{w}) - \\mathbf{y}_{i})^2\\Big). \\]\nTaking the natural log of this function yields\n\\[ \\ln p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma) = - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(h(\\mathbf{x}_{i}; \\mathbf{w}) - \\mathbf{y}_{i})^2 - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{n}{2}\\ln(2\\pi). \\]\nAs mentioned before, maximizing the likelihood function is equivalent to minimizing the sum-of-squares function. Thus, we must find the critical point of the likelihood function by computing the gradient (w.r.t. \\(\\mathbf{w}\\)) and solving for 0:\n\\begin{align*} \\nabla \\ln p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma) \u0026amp;= \\sum_{i=1}^{n}(\\mathbf{w}^T\\mathbf{x}_{i} - \\mathbf{y}_{i})\\mathbf{x}_{i}^{T}\\\\ \u0026amp;= \\mathbf{w}^T \\sum_{i=1}^{n}\\mathbf{x}_i\\mathbf{x}_i^T - \\sum_{i=1}^{n}\\mathbf{y}_{i}\\mathbf{x}_{i}^{T}\\\\ \\end{align*}\nNoting that \\(\\sum_{i=1}^{n}\\mathbf{x}_i \\mathbf{x}_i^T\\) is simply matrix multiplication, we can use\n\\begin{equation*} \\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_1^T\\\\ \\vdots\\\\ \\mathbf{x}_n^T\\\\ \\end{bmatrix}. \\end{equation*}\nThen, \\(\\sum_{i=1}^{n}\\mathbf{x}_i \\mathbf{x}_i^T = \\mathbf{X}^T \\mathbf{X}\\), \\(\\sum_{i=1}^{n}\\mathbf{y}_i \\mathbf{x}_i^T = \\mathbf{Y}^T \\mathbf{X}\\), and\n\\[ \\nabla \\ln p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma) = \\mathbf{w}^T \\mathbf{X}^T \\mathbf{X} - \\mathbf{Y}^T \\mathbf{X}. \\]\nSince we are finding the maximum likelihood, we set \\(\\nabla \\ln p(\\mathbf{Y}|\\mathbf{X}, \\mathbf{w}, \\sigma) = 0\\) and solve for \\(\\mathbf{w}\\):\n\\[ \\mathbf{w} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{Y}. \\]\nThus, we arrive again at the normal equations and can solve this using a linear solver.\nFitting Polynomials Not every dataset can be modeled using a simple line. Data can be exponential or logarithmic in nature. We may also look to use splines to model more complex data.\nFigure 2: Data generated from a nonlinear function with added noise. The dataset above was generated from the function as seen in red. Using a simple linear model (blue) does not fit the data well. For cases such as this, we can fit a polynomial to the data by changing our input data.\nThe simple dataset above has 100 paired samples \\((x_i, y_i)\\). There is only a single feature \\(x_i\\) for each sample. It is trivial to determine that the shape of the data follows a cubic function. One solution would be to raise each input to the power of 3. This results in the function (blue) below.\nFigure 3: Solution from raising each input to the power of 3. To fit this data, we need to add more features to our input. Along with the original \\(x_i\\) features, we will also add \\(x_i^2\\) and \\(x_i^3\\). Our data is then 3 dimensional. The figure below shows the least squares fit using the modified data (blue).\nFigure 4: Least squares fit using a polynomial model (blue). A demo of this can be found here.\nLinear Basis Functions Linear models are linear in their inputs. This formulation is simple, producing models with limited representation. Linear models can be extended as a linear combination of fixed nonlinear functions of the original features. In the previous section, was saw that they could easily be extended to fit polynomial functions.\nWe now consider creating a model that transforms the original input using one or more nonlinear functions. This type of model is called a linear basis function model.\n\\[ h(\\mathbf{x};\\mathbf{w}) = \\sum_{j=1}^{m} w_j\\phi_j(\\mathbf{x}) \\]\nCommon basis functions are the sigmoid, Gaussian, or exponential function. If we choose the \\(\\sin\\) function as a basis function, we can more closely fit our dataset using the least squares approach.\nFigure 5: A linear basis function model using the sin function as the choice of basis. ","date":1641967200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641967200,"objectID":"267d7f34a9ee73d8fc77237de6f23b2a","permalink":"https://ajdillhoff.github.io/notes/linear_regression/","publishdate":"2022-01-12T00:00:00-06:00","relpermalink":"/notes/linear_regression/","section":"notes","summary":"Introduction Probabilistic Interpretation Solving with Normal Equations Another Approach to Normal Equations Fitting Polynomials Linear Basis Functions Introduction Given a dataset of observations \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}\\), where \\(n\\) is the number of samples and \\(d\\) represents the number of features per sample, and corresponding target values \\(\\mathbf{Y} \\in \\mathbb{R}^n\\), create a simple prediction model which predicts the target value \\(\\mathbf{y}\\) given a new observation \\(\\mathbf{x}\\). The classic example in this case is a linear model, a function that is a linear combination of the input features and some weights \\(\\mathbf{w}\\).","tags":null,"title":"Linear Regression","type":"notes"},{"authors":[],"categories":[],"content":"Welcome to Slides academia\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nA fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://ajdillhoff.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using academia's Slides feature.","tags":[],"title":"Slides","type":"slides"}]